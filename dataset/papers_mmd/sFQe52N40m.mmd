# Online Feature Updates Improve Online (generalized) Label Shift Adaptation

Anonymous authors

Paper under double-blind review

###### Abstract

This paper addresses the prevalent issue of label shift in an online setting with missing labels, where data distributions change over time and obtaining timely labels is challenging. While existing methods primarily focus on adjusting or updating the final layer of a pre-trained classifier, we delve into the untapped potential of enhancing feature representations using unlabeled data at test-time. Our novel Online Label Shift adaptation with Online Feature Updates (OLS-OFU) method harnesses self-supervised learning to refine the feature extraction process, thus improving the prediction model. Theoretical analyses confirm that OLS-OFU reduces algorithmic regret by capitalizing on self-supervised learning for feature refinement. Empirical tests on CIFAR-10 and CIFAR-10C datasets, under both online label shift and generalized label shift conditions, underscore OLS-OFU's effectiveness and robustness, especially in cases of domain shifts.

## 1 Introduction

The effectiveness of most supervised learning models relies on a key assumption that the train data and test data share the same distribution. However, this assumption rarely holds in real-world scenarios, giving rise to _distribution shift_. Previous research has primarily focused on understanding distribution shifts in offline or batch settings, where a single shift occurs between the train and test distributions. In contrast, real-world applications often involve test data arriving in an _online_ fashion, and the distribution shift can continuously evolve over time. Additionally, there is another challenging issue of _missing and delayed_ feedback labels, stemming from the online setup, where gathering labels for the streaming data in a timely manner becomes a challenging task.

To tackle the distribution shift problem, prior work makes further assumptions on the nature of the shift, such as label shift or covariate shift. In this paper, we focus on the common _(generalized) label shift_ problem in an online fashion with missing labels. Specifically, the learner is given a fixed set of labeled training data \(D_{0}\sim\mathcal{P}^{\mathrm{train}}\) in advance and trains a model \(f_{0}\). At test-time, only a small batch of unlabelled test data \(S_{t}\sim\mathcal{P}^{\mathrm{test}}_{t}\) arrives in an online fashion (\(t=1,2,\cdots\)). For online label shift, we assume the label distribution \(\mathcal{P}^{\mathrm{test}}_{t}(y)\) may change over time \(t\) while the conditional distribution stays the same, i.e. \(\mathcal{P}^{\mathrm{test}}_{t}(x|y)=\mathcal{P}^{\mathrm{train}}(x|y)\). MRI image classifiers for concussion detection can be challenging due to label shift caused by seasonal changes in the image distribution. A classifier trained during skiing season may perform poorly when tested afterward, as the image distribution changes continuously between skiing and non-skiing seasons. The _generalized_ label shift relaxes this assumption by assuming there exists a transformation \(h\) of the covariate, such that the conditional distribution \(\mathcal{P}^{\mathrm{test}}_{t}(h(x)|y)=\mathcal{P}^{\mathrm{train}}(h(x)|y)\) stays the same. Reiterating our example, a classifier on MRI images can be used in different clinics during training and testing, where the MRI machines might have different versions at both hardware and software levels. Then, the images may have some variations such as brightness, resolution, etc. However, a feature extractor \(h\) exists, capable of mapping these variations to the same point in the latent space. The goal of the learner is to adapt to the (generalized) label shift within the non-stationary environment, continually adjusting the model's predictions in real time.

Existing online label shift adaptation algorithms (OLS) primarily adopt one of two strategies: either directly reweighting of the pretrained classifier \(f_{0}\), or re-training only the final linear layer of \(f_{0}\) -- typically keeping the feature extractor frozen. Recent work has demonstrated that feature extractors can still be improved, even during test-time and in the absence of labels. We hypothesize that asimilar effect can be leveraged in the (generalized) label shift setting and propose to improve the feature representation during testing. In online label shift, updating the feature extractor offers two possible advantages. First, it enables the utilization of additional unlabeled samples to enhance the sample efficiency of the feature extractor. Second, it allows the adaptation of the feature extractor to label shift. Latter is important because the optimal feature extractor is not necessarily independent of the label distribution. In particular, in generalized label shift, the feature transformation \(h\) is typically unknown, and additional unlabeled test samples can ease the learning of \(h\).

Building upon this insight, this paper introduces the _Online Label Shift adaptation with Online Feature Updates_ (OLS-OFU) framework, aimed at enhancing feature representation learning in the context of online label shift adaptation. Specifically, each instantiation of OLS-OFU incorporates a self-supervised learning method associated with a loss function denoted as \(l_{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{ \text{\text{\text{\text{\texttext{\texttext{\texttexttext{\texttext \text{ \texttexttexttexttexttexttext}}}}}}}{\text{ \text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\texttext}}}}}}}}}}}}}}}}}}}} }}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}\,,, \, \the online test stage, we define the average loss for any online algorithm \(\mathcal{A}\) through the loss of the sequence of models \(f_{t}\), \(t\in[T]\) that are produced from \(\mathcal{A}\), i.e.,

\[L(\mathcal{A};\mathcal{P}^{\mathrm{test}}_{1},\cdots,\mathcal{P}^{\mathrm{test} }_{T})=\frac{1}{T}\sum_{t=1}^{T}\ell(f_{t};\mathcal{P}^{\mathrm{test}}_{t}), \tag{1}\]

where \(\ell(f;\mathcal{P})=\mathbb{E}_{(x,y)\sim\mathcal{P}}\ell_{\mathrm{sup}}(f(x),y)\) and \(\ell_{\mathrm{sup}}\) is the loss function, for example, 0-1 loss or cross-entropy loss for classification tasks.

If we have knowledge of \(\mathcal{P}^{\mathrm{test}}_{t}\) or have enough samples from \(\mathcal{P}^{\mathrm{test}}_{t}\), then the problem reduces to offline distribution shift for each single time step, or if we have a few labeled samples, the problem can be treated as classical online learning, and we can run stochastic gradient descent at the end of every time step \(t\) to meet certain theoretical guarantees. However, it is more realistic but technically highly non-trivial when we only have very few unlabeled samples, or even a single sample \(x_{t}\). An effective algorithm under this scenario has to utilize information from all historical data (both train data \(D_{0}\), validation data \(D^{\prime}_{0}\) and test data up to time \(t\)), as well as previously deployed models \(f_{0,1,\cdots,t-1}\). In this paper, we consider this challenging case where at each time step \(t\), only _a small batch of unlabeled samples_\(S_{t}=\{x^{1}_{t},\cdots,x^{B}_{t}\}\) is received. We formalize the algorithm \(\mathcal{A}\) as:

\[f_{t}:=\mathcal{A}\left(\{S_{1},\cdots,S_{t-1}\},\{f_{0},f_{1},\cdots,f_{t-1} \},D_{0},D^{\prime}_{0}\right)\quad\forall t\in[T]. \tag{2}\]

In contrast to the classical online learning setup, this scenario presents a significant challenge as classical online learning literature usually relies on having access to either full or partial knowledge of the loss at each time step, i.e., \(\ell_{\mathrm{sup}}(f(x_{t}),y_{t})\). In this setting, however, only a batch of unlabeled samples is provided at each time step. This lack of both label information and loss values significantly amplifies the difficulty of accurately estimating the true loss in Equation 1.

Related work have studied the online distribution shift adaptation under various assumptions. Zhang et al. (2023) assumes the test distributions are covariate shifted from the training distribution, i.e. \(\mathcal{P}^{\mathrm{test}}_{t}(y|x)=\mathcal{P}^{\mathrm{train}}_{t}(y|x)\) while \(\mathcal{P}^{\mathrm{test}}_{t}(x)\neq\mathcal{P}^{\mathrm{train}}(x)\) may shift over time. Wu et al. (2021); Bai et al. (2022); Baby et al. (2023) study online label shift adaptation, where \(\mathcal{P}^{\mathrm{test}}_{t}(x|y)=\mathcal{P}^{\mathrm{train}}(x|y)\) and \(\mathcal{P}^{\mathrm{test}}_{t}(y)\neq\mathcal{P}^{\mathrm{train}}(y)\) can shift over time. In this paper, we focus on the online (generalized) label shift adaptation. Generalized label shift, first introduced by Tachet des Combes et al. (2020), assumes that there exists an unknown transformation \(h\) of the feature \(x\), such that the conditional distribution \(\mathcal{P}(h(x)|y)\) remains invariant between the training and test time. Discussed in Section 5, our methodology applies beyond label shift scenarios, extending to distribution shift more broadly.

**Online label shift adaptation.** In online label shift, the conditional distribution \(\mathcal{P}^{\mathrm{test}}_{t}(x|y)\) is invariant and equivalent to \(\mathcal{P}^{\mathrm{train}}(x|y)\) for all \(t\in[T]\), while the marginal distribution of the label \(\mathcal{P}^{\mathrm{test}}_{t}(y)\) changes over time. This assumption is most typical when the label \(y\) is the causal variable and the feature \(x\) is the observation (Scholkopf et al., 2012) and the example of concussion detection from MRI images lies in the case. Most previous methods tackle this problem by a non-trivial reduction to the classical online learning problem. Given this, most of the online label shift algorithms (Wu et al., 2021; Bai et al., 2022; Baby et al., 2023) study the theoretical guarantee of the algorithm via the convergence of the regret function, either static regret or dynamic regret. In prior studies, the hypothesis class \(\mathcal{F}\) of the prediction function \(f\) is typically chosen in one of two ways. The first approach involves defining \(\mathcal{F}\) as a family of post-hoc reweightings of \(f_{0}\), with the parameter space comprising potential reweight vectors. Notable examples within this category include ROGD (Wu et al., 2021), FTH (Wu et al., 2021), and FLHFTL (Baby et al., 2023). The second approach defines \(\mathcal{F}\) as a family of functions that share the same parameters in \(f_{0}\) except the last linear layer, for example, UOGD (Bai et al., 2022) and ATLAS (Bai et al., 2022).

**Online generalized label shift adaptation.** In the context of MRI image classification, where head MRI images serve as the feature \(x\), MRI machines in different clinics may use different versions of software or hardware. The resulting images may exhibit differences in terms of brightness, contrast, resolution, and other characteristics. In such scenarios, the conditional probability distribution \(\mathcal{P}(x|y)\) is no longer invariant. However, when a feature extractor \(h\) is robust enough, it can map the images into a feature space where the images from different machines have the same distributions \(\mathcal{P}(h(x)|y)\) in this transformed feature space. The concept of generalized label shift, as introduced in Tachet des Combes et al. (2020), formalizes this situation by postulating the existence of an unknown function \(h\), such that the conditional probability distribution \(\mathcal{P}(h(x)|y)\) remains invariant. The primary challenge in this context is to find the underlying transformation \(h\). Building upon this,online generalized label shift assumes that, for every time step \(t\), the test distribution \(\mathcal{P}_{t}^{\mathrm{test}}\) exhibits a form of generalized label shift from the training distribution \(\mathcal{P}^{\mathrm{train}}\), and this shift is governed by the same underlying transformation \(h\).

**Self-supervised learning.** Inspired by the body of work in semi-supervised learning (Grandvalet and Bengio, 2004b; Lee et al., 2013; Laine and Aila, 2016; Gidaris et al., 2018; Miyato et al., 2018) and unsupervised representation learning (Chen et al., 2020a; He et al., 2019; Grill et al., 2020; He et al., 2022), self-supervised learning (SSL) techniques emerge as promising tools for enhancing feature extraction from unlabeled data, e.g. for image classification. Likewise, when dealing with online label shift adaptation, it is crucial to leverage the unlabeled test samples \(S_{1}\cup\cdots\cup S_{t-1}\) obtained from previous time steps. Ideally, these unlabeled samples could improve the feature representation learning and ultimately lead to better prediction for the test samples \(S_{t}\) at a time step \(t\).

## 3 Method

We introduce a novel online label shift adaptation algorithm that uses self-supervised learning (SSL) to improve representation learning. This approach is general and can be used with any existing OLS algorithm. We show theoretically and empirically the performance improvement in OLS algorithms and their effectiveness for the more challenging online generalized label shift adaptation problem.

### Online Feature Updates with Self-Supervised Learning

In this section, we discuss how to utilize various SSL techniques to improve the feature representation learning of existing online label shift algorithms. To illustrate the concept, we narrow our focus to three particular SSL techniques for classification tasks: rotation degree prediction (Gidaris et al., 2018; Sun et al., 2020), entropy minimization (Grandvalet and Bengio, 2004b; Wang et al., 2020) and MoCo (He et al., 2019; Chen et al., 2020b; Chen et al., 2021). It is important to note that this concept extends beyond these three SSL techniques, and the incorporation of more advanced SSL techniques has the potential to further elevate the performance. Specifically, rotation degree prediction involves initially rotating a given image by a specific degree from the set \(\{0,90,180,270\}\) and the classifier is required to determine the degree by which the image has been rotated. Entropy minimization utilizes a minimum entropy regularizer, with the motivation that unlabeled examples are mostly beneficial when classes have a small overlap. MoCo is a more advanced representation learning technique, using a query and momentum encoder to learn representations from unlabeled data by maximizing the similarity of positive pairs and minimizing the similarity of negative pairs. The details of these SSL are introduced in Appendix D.8.

Now we formally introduce _Online Label Shift adaptation with Online Feature Updates_ (OLS-OFU; Algorithm 1), which requires a self-supervised learning loss \(\ell_{\mathrm{sal}}\) and an online label shift adaptation algorithm (OLS) that either reweights the offline pretrained model \(f_{0}\) or updates the last linear layer1. In the train stage, we train \(f_{0}\) by minimizing the supervised and self-supervised loss together defined on train data. In the test stage, OLS-OFU comprises three steps at each time step \(t\): (1) running the refined version of OLS, which we refer to as OLS-R, (2) updating the feature extractor, (3) re-training the last linear layer. The details of these three steps are elaborated below.

Footnote 1: As pointed out in Section 2, this is relatively general as most previous online label shift algorithms belong to these two categories.

**(1) Running the Revised OLS.** First, we review common OLS methods (FLHFTL, FTH, ROGD, UOGD, and ATLAS) and identify two specific points in the algorithm where we can employ the updated prediction model \(f_{t}^{\prime\prime}\) (with the improved feature extractor2) to supplant the pretrained model \(f_{0}\), hence enhancing the original OLS algorithm. Denote \(C_{f,D}\in[0,1]^{K\times K}\) the confusion matrix evaluated on dataset \(D\) for the model \(f\) with \(C_{f,D}[i,j]=\mathbb{P}_{(x,y)\sim D}\big{(}\arg\max(f(x))=j|y=i\big{)}\). At the outset, all OLS methods rely on an unbiased estimator \(s_{t}\) of the label distribution \(q_{t}\) with \(q_{t}[y]=\mathcal{P}_{t}^{\mathrm{test}}(y)\), where \(s_{t}:=\frac{1}{|S_{t}|}\sum_{x_{t}\in S_{t}}C_{f_{0},D_{t}}^{-1}f_{0}(x_{t})\). This is the first point that we can replace \(f_{0}\) with the improved prediction model \(f_{t}^{\prime\prime}\) to enhance the estimation of label marginal distribution. For the second point,* FLHFTL and FTH subsequently employ a vector \(\tilde{q}_{t}\)3 to reweight the initial pretrained model \(f_{0}\). Now, instead of reweighting the original pretrained model \(f_{0}\), the algorithm reweights the improved model \(f^{\prime\prime}_{t}\), utilizing its enhanced predictive performance. Footnote 3: The reweighting factor \(\tilde{q}_{t}\) is a function of unbiased estimators \(s_{1},\cdots,s_{t}\) in FLHFTL and FTH.
* ROGD, UOGD, and ATLAS initially update the model through an unbiased gradient estimator within a hypothesis space that either includes a linear model after a fixed feature extractor in \(f_{0}\) or a reweighted version of \(f_{0}\). Now, we have the flexibility to shift to a comparable hypothesis space, replacing \(f_{0}\) with the improved model \(f^{\prime\prime}_{t}\), and continue applying updates using the same unbiased gradient estimator.

Algorithm 2 provides a formal illustration of the revision specific to FLHFTL. Further details regarding the revisions for ROGD, FTH, UOGD, and ATLAS can be found in Appendix B. We use \(f^{\prime}_{t+1}\) to denote the model after running the revised OLS.

**(2) Updating the Feature Extractor.** We now introduce how to utilize an SSL loss \(\ell_{\text{sal}}\) to update the feature extractor for any incoming unlabeled test data batch \(S_{t}\) at timestep \(t\). Specifically, let \(\theta^{\text{feat}}_{t}\) denote the parameters of the feature extractor in \(f^{\prime}_{t+1}\). The update of \(\theta^{\text{feat}}_{t+1}\) at time \(t\) is given by:

\[\theta^{\text{feat}}_{t+1}:=\theta^{\text{feat}}_{t}-\eta\cdot\nabla_{\theta^{ \text{feat}}}\ell_{\text{sal}}(S_{t};f^{\prime}_{t+1}).\]

We replace the feature extractor in \(f^{\prime}_{t+1}\) by \(\theta^{\text{feat}}_{t+1}\).

**(3) Re-training Last Linear Layer.** Given the updated feature extractor \(\theta^{\text{feat}}_{t+1}\), it is necessary to re-train the last linear layer \(\theta^{\text{linear}}_{t+1}\) to adapt to the new feature extractor. We start the re-raining from random initialization, while keeping the feature extractor frozen. The train objective of \(\theta^{\text{linear}}_{t+1}\) is to minimize the average cross-entropy loss under train data \(D_{0}\). We denote the model with the frozen feature extractor \(\theta^{\text{feat}}_{t+1}\) as \(f(\cdot|\theta^{\text{feat}}_{t+1},\theta^{\text{linear}})\). The objective for re-training last linear layer can be written as follows:

\[\theta^{\text{linear}}_{t+1}:=\arg\min_{\theta^{\text{linear}}_{t=1}}\sum_{(x,y)\in D_{0}}\ell_{\text{ce}}\bigg{(}f(x|\theta^{\text{feat}}_{t+1},\theta^{ \text{linear}}),y\bigg{)}.\]

We calibrate the model \(f(\cdot|\theta^{\text{feat}}_{t+1},\theta^{\text{linear}}_{t+1})\) by temperature calibration (Guo et al., 2017) using the validation set \(D^{\prime}_{0}\) and denote the model after calibration as \(f^{\prime\prime}_{t+1}\). This re-training step is needed to ensure the model is a calibrated model of estimating \(\mathcal{P}^{\text{train}}(y|x)\) for any given input \(x\).

In the end, we are going to define \(f_{t+1}\) for the next time step. If the parameter space of the original OLS is a reweighting version of the prediction model (ROGD, FTH, FLHFTL), suppose the reweighting vector in \(f^{\prime}_{t+1}\) is \(p_{t+1}\) and we define \(f_{t+1}:=g(\cdot;f^{\prime\prime}_{t+1},p_{t+1})\); else (UOGD, ATLAS), we define \(f_{t+1}:=f^{\prime}_{t+1}\).

### Performance Guarantee

The original Online Label Shift (OLS) methods exhibit theoretical guarantees in terms of regret convergence for online label shift setting, where \(\mathcal{P}^{\text{test}}_{t}(x|y)=\mathcal{P}^{\text{train}}(x|y)\) is invariant. With the incorporation of the additional online feature update step, OLS-OFU demonstrates analogous theoretical results. By comparing the theoretical results between OLS and OLS-OFU, we can gain insights into potential enhancements from OLS to OLS-OFU. Due to limited space, we provide the theoretical results pertaining to FLHFTL-OFU here, and present the theoretical results for ROGD-OFU, FTH-OFU, UOGD-OFU, and ATLAS-OFU in Appendix C.

**Theorem 1**: _[Regret convergence for FLHFTL-OFU] Suppose we choose the OLS subroutine in Algorithm 2 to be FLH-FTL from Baby et al. (2023). Let \(f^{\text{hhfh1-ofu}}_{t}\) be the output at time step \(t-1\) from Algorithm 1, that is \(g(\cdot;f^{\prime\prime}_{t},\tilde{q}_{t}/q_{0})\). Let \(\sigma\) be the smallest among the the minimum singular values of invertible confusion matrices \(\{C_{f^{\prime\prime}_{t},D^{\prime}_{0}},\cdots C_{f^{\prime\prime}_{T},D^{ \prime}_{0}}\}\). Then under Assumptions 1 and 2 in Baby et al. (2023), FLHFTL-OFU has the guarantee for online label shift below:_

\[\mathbb{E}\left[\frac{1}{T}\sum_{t=1}^{T}\ell(f^{\text{hhfh1-ofu}}_{t}; \mathcal{P}^{\text{test}}_{t})-\frac{1}{T}\sum_{t=1}^{T}\ell(g(\cdot;f^{\prime \prime}_{t},q_{t}/q_{0});\mathcal{P}^{\text{test}}_{t})\right]\leq O\left( \frac{K^{1/6}V^{1/3}_{T}}{\sigma^{2/3}T^{1/3}}+\frac{K}{\sigma\sqrt{T}} \right), \tag{3}\]

_where \(V_{T}:=\sum_{t=1}^{T}\|q_{t}-q_{t-1}\|_{1}\), \(K\) is the number of classes, and the expectation is taken w.r.t. randomness in the revealed co-variates. This result is attained without prior knowledge of \(V_{T}\)._

To ease comparison, we state the theorem for the original OLS algorithm FLHFTL

**Theorem 2**: _[Regret convergence for FLHFTL (Baby et al., 2023)] Under Assumptions 1 and 2 in Baby et al. (2023), FLHFTL has the guarantee for online label shift below:_

\[\mathbb{E}\left[\frac{1}{T}\sum_{t=1}^{T}\ell(f^{\text{hhfh1}}_{t};\mathcal{P} ^{\text{test}}_{t})\right]-\frac{1}{T}\sum_{t=1}^{T}\ell(g(\cdot;f_{0},q_{t}/ q_{0});\mathcal{P}^{\text{test}}_{t})\leq O\left(\frac{K^{1/6}V^{1/3}_{T}}{ \sigma^{2/3}T^{1/3}}+\frac{K}{\sigma\sqrt{T}}\right), \tag{4}\]

_where \(V_{T}:=\sum_{t=1}^{T}\|q_{t}-q_{t-1}\|_{1}\), \(\sigma\) denotes the minimum singular value of invertible confusion matrices \(C_{f_{0},D^{\prime}_{0}}\). K is the number of classes, and the expectation is taken with respect to randomness in the revealed co-variates. Further, this result is attained without prior knowledge of \(V_{T}\)._Recall that the objective function for the online label shift problem is defined as the average loss in Equation 1. Both theorems establish the convergence of this average loss. In the event that \(f_{t}^{\prime\prime}\) (\(t\in[T]\)) from the online feature updates yield improvements:

\[\mathbb{E}\left[\frac{1}{T}\sum_{t=1}^{T}\ell(g(\cdot;f_{t}^{\prime\prime},q_{t }/q_{0});\mathcal{P}_{t}^{\mathrm{test}})\right]<\frac{1}{T}\sum_{t=1}^{T} \ell(g(\cdot;f_{0},q_{t}/q_{0});\mathcal{P}_{t}^{\mathrm{test}}), \tag{5}\]

then it guarantees that the loss of FLHFTL-OFU will converge to a smaller value, resulting in enhanced performance compared to FLHFTL. We substantiate this improvement through empirical evaluation in Section 4. For other OLS algorithms such as ROGD-OFU, FTH-OFU, UOGD-OFU, and ATLAS-OFU, a similar analysis can be derived and we present them in Appendix C.

### Online Feature Updates Improve Online Generalized Label Shift Adaptation

When we have knowledge of the feature map \(h\) under generalized label shift, the problem simplifies to the classical online label shift scenario. However, the more challenging situation arises when \(h\) remains unknown. Due to the violation of the label shift assumption, standard OLS algorithms can perform arbitrarily bad. Fortunately, existing research in test-time training (TTT) (Sun et al., 2020; Wang et al., 2020; Liu et al., 2021; Niu et al., 2022) demonstrates that feature updates driven by SSL align the source and target domains in feature space. When the source and target domains achieve perfect alignment, such feature extractor effectively serves as the feature map \(h\) as assumed in generalized label shift. Therefore, the sequence of feature extractors in \(f_{1},\cdots,f_{T}\) generated by Algorithm 1 progressively approximates the underlying \(h\). This suggests that, compared to the original OLS, OLS with online feature updates (Algorithm 1) experiences a milder violation of the label shift assumption within the feature space and is actually expected to have better performance in the setting of online generalized label shift. Indeed, as demonstrated in Section 4, we can observe significant improvements in OLS-OFU compared to standard OLS for online generalized label shift.

## 4 Experiment

In this section, we empirically evaluate how OLS-OFU improves the original OLS methods on both online label shift and online generalized label shift4. The experiment is performed on CIFAR-10 (Krizhevsky et al., 2009) and CIFAR-10C (Hendrycks and Dietterich, 2019), where we vary the shift processes and SSL techniques to evaluate the efficacy of the method.

Footnote 4: Code released at [https://anonymous.depa.sciences/r/online_label_shift_with_online_feature_update-3kly/](https://anonymous.depa.sciences/r/online_label_shift_with_online_feature_update-3kly/).

### Experiment set-up

**Dataset and shift process set-up.** For online label shift, we evaluate the efficacy of our algorithm on CIFAR-10, which has 10 categories of images. We split the original train set of CIFAR-10 into the offline train and validation sets, which have 40,000 and 10,000 images respectively. At the online test stage, the unlabeled batches are sampled from the test set of CIFAR-10. For online generalized label shift, the offline train and validation sets are the same CIFAR-10 images, but the test unlabeled batches are sampled from CIFAR-10C. CIFAR-10C is the benchmark that has the same objects in CIFAR-10 but with multiple types of corruption. We experiment with three types of corruptions (i.e., domain shifts): Gaussian noise, Fog and Pixelate. Besides CIFAR-10 and CIFAR-10C, we also experiment with three additional datasets for the setting of online label shift and present the results in Appendix D.2 due to the space limits. See more details of dataset set-up in Appendix D.1.

We follow Bai et al. (2022) and Baby et al. (2023) to simulate the online label distribution shift in two online shift patterns: Sinusoidal shift and Bernoulli shift. Given two label distribution vectors \(q\) and \(q^{\prime}\), the label marginal distributions at time \(t\) is \(q_{t}:=\alpha_{t}q+(1-\alpha_{t})q^{\prime}\). In Sinusoidal shift, \(\alpha_{t}=\sin\frac{\mathrm{i}\pi}{L}\) (periodic length \(L=\sqrt{T}\), \(i=t\bmod L\)) while in Bernoulli shift, \(\alpha_{t}\) is a random bit (either 0 or 1), where the bit switches \(\alpha_{t}=\alpha_{t}-1\) if the coinflip probability exceeds \(p=\frac{1}{\sqrt{T}}\). The \(q\) and \(q^{\prime}\) are \(\frac{1}{T}(1,\cdots,1)\) and \((1,0,\cdots,0)\) in the experiment. To sample the batch test data at time \(t\), we first sample a batch of labels (not revealed to the learner) according to \(q_{t}\). Then given each label we can sample an image from the test set, and collect this batch of images without labels as \(S_{t}\). We experiment with \(T=1000\) and batch size \(B=10\) at each time step, following Baby et al. (2023).

**Evaluation metric.** We report the average error \(\frac{1}{TB}\sum_{t=1}^{T}\sum_{x_{t}\in S_{t}}\mathbb{1}\left(f_{t}(x_{t})\neq y _{t}\right)\), where \(y_{t}\sim\mathcal{P}_{t}^{\text{test}}(y|x_{t})\), to approximate \(\frac{1}{T}\sum_{t=1}^{T}\ell(f_{t};\mathcal{P}_{t}^{\text{test}})\) for the evaluation efficiency. This approximation is valid for large \(T\) due to its exponential concentration rate by the Azuma-Hoeffding inequality.

**Online algorithms set-up.** We perform an extensive evaluation of 6 OLS algorithms in the literature: FTFWH, FTH, ROGD, UOGD, ATLAS, and FLH-FTL. FTFWH is an empirical OLS proposed in Wu et al. (2021). We further report the performance of OLS-OFU (Algorithm 1) on top of each OLS. OLS-OFU is implemented with 3 common SSL methods: rotation degree prediction, entropy minimization, and MoCo. Additionally, we report two baseline scores. The first, denoted as Base, uses the fixed pretrained model \(f_{0}\) to predict the labels at all test time steps. The second is online feature updates (OFU) only, where at time step \(t\) we only update the features (Step 2 in Algorithm 1) without utilizing OLS algorithms.

### Results

**How does OLS-OFU perform compared with original OLS methods?** Figure 2(a) compares the performance of various OLS-OFU algorithms with their respective OLS counterparts, under classical online label shift. The experiment is performed on CIFAR10 with Sinusoidal shift. Appendix D.3 shows similar conclusions for the Bernoulli shift. First of all, both OLS and OLS-OFU show significantly better performance than Base and OFU. This demonstrates the inherent advantages of OLS methods in effectively addressing the online label shift problem. Additionally, it's worth noting that OLS-OFU, when integrated with three distinct SSL methods, consistently outperforms OLS across all six OLS methods. This underscores the importance of improving feature representation learning within label shift adaptation in OLS-OFU.

Furthermore, we report the performance of OLS-OFU in the context of online generalized label shift. In this scenario, the test images exhibit three types of domain shifts in CIFAR-10C -- Gaussian noise, Fog, and Pixelation--with mild severity. We present the result under Sinusoidal shift with the SSL method as rotation degree prediction. Results for other SSL methods and online shift patterns show a similar pattern in Appendix D.4. As shown in Figure 2(b), OFU has huge improvements from Base, showing the necessity of updating feature extractors to facilitate the learning of \(h\). Moreover, some OLS methods perform worse than OFU. This is expected as the underlying assumption of label shift no longer holds in this generalized label shift setting. Lastly, it is worth highlighting that OLS-OFU consistently outperforms the original OLS methods by a larger gap than the one occurring at the classic label shift setting. We hypothesize that the SSL methods within OLS-OFU aid the

Figure 2: Comparison of OLS-OFU and OLS in CIFAR-10 and CIFAR-10C.

feature extractor in learning the unknown mapping \(h\) within the generalized label shift assumption. Intuitively, the label shift assumption in the feature space of \(\theta_{t}^{\text{feat}}\) is violated lighter than the one in the feature space of \(\theta_{0}^{\text{feat}}\). Given the relatively mild violation, the OLS module within OLS-OFU continues to help adapt the online label shift, explaining OLS-OFU's advantage over OFU.

**How does OLS-OFU perform under high severity of domain shift in the setting of generalized online label shift?** In Figure 3, it is clear that as the domain shift severity increases, OLS-OFU significantly enlarges the gap compared with OLS. However, it might be worth pointing out that neither OLS nor OLS-OFU are better than OFU. This is because the label shift assumption is violated so severely -- even OFU cannot reduce the violation under an acceptable level, especially when the OLS module exists in OLS-OFU, as the adaptation to distribution shift is far off. For results involving higher levels of severity, different corruption types, and SSL techniques, please refer to Appendix D.5.

**Does Equation 5 hold empirically?** In Section 3.2, we argued that when the inequality in Equation 5 holds, the loss of FLHFTL-OFU exhibits a tighter upper bound compared to FLHFTL. Figure 4 presents the RHS (corresponds to OLS) and LHS (corresponds to OLS-OFU with SSL loss as rotation degree prediction) of Equation 5. We perform the study over cross eight different settings, varying types of domain shift and online shift pattern, which empirically validates that OLS-OFU yields improvements on the _baseline_ of the regret as shown in Equation 5. Appendix D.6 validates this inequality for other SSL techniques.

**Does the order of prediction and update matter?** In the default online distribution shift framework (Figure 1), model updates occur after making predictions for samples at timestep \(t\). This raises the question of whether the model should be updated before making predictions. We conducted empirical evaluations for both the "predict first" and "update first" approaches and found no compelling evidence to favor one over the other (additional results in Appendix D.7). However, it's noteworthy that within the "predict first" framework, OLS and OLS-OFU benefit from robust theoretical guarantees, hence we recommend the "predict first" approach in practical applications.

## 5 Conclusion

We focus on online (generalized) label shift adaptation and introduce a novel algorithm _Online Label Shift adaptation with Online Feature Updates_ (OLS-OFU), which harnesses the power of self-supervised learning to enhance feature representations dynamically during testing, leading to improved predictive models and better test time performance. Our theoretical analyses show that OLS-OFU successfully achieves the improved theoretical guarantees under online label shift. We also validate the performance of OLS-OFU on both online label shift and generalized label shift scenarios, demonstrating OLS-OFU's superiority over prior online label shift algorithms. This underscores its efficacy and robustness, particularly when confronted with domain shifts.

**Discussion and future work.** In this paper, we have shown how online feature updates help with online (generalized) label shift adaptation. One promising direction is to extend this idea to online covariate shift -- the algorithm in Zhang et al. (2023) freezes the feature extractor and only updates the linear layer. Another possible extension is to consider a more realistic domain shift within the generalized label shift setting -- domain shift types may vary over time or they can be more challenging, such as shifting from cartoon images to realistic images. More advanced SSL techniques in the deep learning literature might be needed to handle these more intricate domain shifts.

Figure 4: Empirical examination for the holdness of Equation 5. Clean denotes the experiment on CIFAR-10. Gaussian, Fog and Pixelate denote various domain shifts in CIFAR-10C. They are paired with two online shift patterns: Sinusoidal and Bernoulli.

Figure 3: Results on CIFAR-10C for a high level of domain shift severity.

## References

* Alexandari et al. (2020) Amr Alexandari, Anshul Kundaje, and Avanti Shrikumar. Maximum likelihood with bias-corrected calibration is hard-to-beat at label shift adaptation. In _International Conference on Machine Learning_, pp. 222-232. PMLR, 2020.
* Arazo et al. (2020) Eric Arazo, Diego Ortego, Paul Albert, Noel E O'Connor, and Kevin McGuinness. Pseudo-labeling and confirmation bias in deep semi-supervised learning. In _2020 International Joint Conference on Neural Networks (IJCNN)_. IEEE, 2020.
* Azizzadenesheli et al. (2019) Kamyar Azizzadenesheli, Anqi Liu, Fanny Yang, and Animashree Anandkumar. Regularized learning for domain adaptation under label shifts. In _International Conference on Learning Representations_, 2019.
* Baby & Wang (2022) Dheeraj Baby and Yu-Xiang Wang. Optimal dynamic regret in proper online learning with strongly convex losses and beyond. In _International Conference on Artificial Intelligence and Statistics_, pp. 1805-1845. PMLR, 2022.
* Baby et al. (2023) Dheeraj Baby, Saurabh Garg, Tzu-Ching Yen, Sivaraman Balakrishnan, Zachary Chase Lipton, and Yu-Xiang Wang. Online label shift: Optimal dynamic regret meets practical algorithms. _To appear at Advances in Neural Information Processing Systems_, 2023.
* Bai et al. (2022) Yong Bai, Yu-Jie Zhang, Peng Zhao, Masashi Sugiyama, and Zhi-Hua Zhou. Adapting to online label shift with provable guarantees. _Advances in Neural Information Processing Systems_, 35:29960-29974, 2022.
* Besbes et al. (2015) Omar Besbes, Yonatan Gur, and Assaf Zeevi. Non-stationary stochastic optimization. _Operations research_, 63(5):1227-1244, 2015.
* Chen et al. (2020a) Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. In _International conference on machine learning_, pp. 1597-1607. PMLR, 2020a.
* Chen et al. (2021) X. Chen, S. Xie, and K. He. An empirical study of training self-supervised vision transformers. In _2021 IEEE/CVF International Conference on Computer Vision (ICCV)_, pp. 9620-9629, Los Alamitos, CA, USA, oct 2021. IEEE Computer Society. doi: 10.1109/ICCV48922.2021.00950. URL [https://doi.ieeecomputersociety.org/10.1109/ICCV48922.2021.00950](https://doi.ieeecomputersociety.org/10.1109/ICCV48922.2021.00950).
* Chen et al. (2020b) Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He. Improved baselines with momentum contrastive learning. _arXiv preprint arXiv:2003.04297_, 2020b.
* Coates et al. (2011) Adam Coates, Andrew Ng, and Honglak Lee. An Analysis of Single Layer Networks in Unsupervised Feature Learning. In _AISTATS_, 2011. [https://cs.stanford.edu/~acoates/papers/coatesleeng_aistats_2011.pdf](https://cs.stanford.edu/~acoates/papers/coatesleeng_aistats_2011.pdf).
* Darlow et al. (2018) Luke N. Darlow, Elliot J. Crowley, Antreas Antoniou, and Amos J. Storkey. Cinic-10 is not imagenet or cifar-10, 2018.
* Garg et al. (2020) Saurabh Garg, Yifan Wu, Sivaraman Balakrishnan, and Zachary C Lipton. A unified view of label shift estimation. _arXiv preprint arXiv:2003.07554_, 2020.
* Gidaris et al. (2018) Spyros Gidaris, Praveer Singh, and Nikos Komodakis. Unsupervised representation learning by predicting image rotations. In _International Conference on Learning Representations_, 2018. URL [https://openreview.net/forum?id=Slv4N210-](https://openreview.net/forum?id=Slv4N210-).
* Grandvalet & Bengio (2004) Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In L. Saul, Y. Weiss, and L. Bottou (eds.), _Advances in Neural Information Processing Systems_, volume 17. MIT Press, 2004a. URL [https://proceedings.neurips.cc/paper_files/paper/2004/file/96f2b50b5d3613adf9c27049b2a888c7-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2004/file/96f2b50b5d3613adf9c27049b2a888c7-Paper.pdf).
* Grandvalet & Bengio (2004) Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. _Advances in neural information processing systems_, 17, 2004b.

* Gretton et al. (2009) Arthur Gretton, Alex Smola, Jiayuan Huang, Marcel Schmittfull, Karsten Borgwardt, and Bernhard Scholkopf. Covariate shift by kernel mean matching. _Dataset shift in machine learning_, 3(4):5, 2009.
* Grill et al. (2020) Jean-Bastien Grill, Florian Strub, Florent Altche, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, et al. Bootstrap your own latent-a new approach to self-supervised learning. _Advances in neural information processing systems_, 33:21271-21284, 2020.
* Guo et al. (2017) Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In _International conference on machine learning_, pp. 1321-1330. PMLR, 2017.
* He et al. (2019) Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual representation learning. _arXiv preprint arXiv:1911.05722_, 2019.
* He et al. (2022) Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollar, and Ross Girshick. Masked autoencoders are scalable vision learners. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pp. 16000-16009, 2022.
* Helber et al. (2019) Patrick Helber, Benjamin Bischke, Andreas Dengel, and Damian Borth. Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification. _IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing_, 12(7):2217-2226, 2019. doi: 10.1109/JSTARS.2019.2918242.
* Hendrycks and Dietterich (2019) Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. _arXiv preprint arXiv:1903.12261_, 2019.
* Hoffman et al. (2014) Judy Hoffman, Trevor Darrell, and Kate Saenko. Continuous manifold based adaptation for evolving visual domains. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_, pp. 867-874, 2014.
* Huang et al. (2006) Jiayuan Huang, Arthur Gretton, Karsten Borgwardt, Bernhard Scholkopf, and Alex Smola. Correcting sample selection bias by unlabeled data. In _Advances in neural information processing systems_, volume 19, pp. 601-608. Citeseer, 2006.
* Krizhevsky et al. (2009) Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
* Laine & Aila (2016) Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. _arXiv preprint arXiv:1610.02242_, 2016.
* Lee (2013) Dong-Hyun Lee. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. _ICML 2013 Workshop: Challenges in Representation Learning_, 2013.
* Lee et al. (2013) Dong-Hyun Lee et al. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. In _Workshop on challenges in representation learning, ICML_, volume 3, pp. 896. Atlanta, 2013.
* Lin et al. (2002) Yi Lin, Yoonkyung Lee, and Grace Wahba. Support vector machines for classification in nonstandard situations. _Machine learning_, 46(1):191-202, 2002.
* Lipton et al. (2018) Zachary Lipton, Yu-Xiang Wang, and Alexander Smola. Detecting and correcting for label shift with black box predictors. In _International conference on machine learning_, pp. 3122-3130. PMLR, 2018.
* Liu et al. (2021) Yuejiang Liu, Parth Kothari, Bastien Van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++: When does self-supervised test-time training fail or thrive? _Advances in Neural Information Processing Systems_, 34:21808-21820, 2021.
* Miyato et al. (2018) Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. _IEEE transactions on pattern analysis and machine intelligence_, 41(8):1979-1993, 2018.

* Mullapudi et al. (2019) Ravi Teja Mullapudi, Steven Chen, Keyi Zhang, Deva Ramanan, and Kayvon Fatahalian. Online model distillation for efficient video inference. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pp. 3573-3582, 2019.
* Niu et al. (2022) Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test-time model adaptation without forgetting. In _International conference on machine learning_, pp. 16888-16905. PMLR, 2022.
* Saerens et al. (2002) Marco Saerens, Patrice Latinne, and Christine Decaestecker. Adjusting the outputs of a classifier to new a priori probabilities: a simple procedure. _Neural Computation_, 14(1):21-41, 2002.
* Scholkopf et al. (2012) Bernhard Scholkopf, Dominik Janzing, Jonas Peters, Eleni Sgouritsa, Kun Zhang, and Joris Mooij. On causal and anticausal learning. _arXiv preprint arXiv:1206.6471_, 2012.
* Shalev-Shwartz (2012) Shai Shalev-Shwartz. 2012.
* Shimodaira (2000) Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-likelihood function. _Journal of statistical planning and inference_, 90(2):227-244, 2000.
* Sun et al. (2020) Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In _International conference on machine learning_, pp. 9229-9248. PMLR, 2020.
* Tachet des Combes et al. (2020) Remi Tachet des Combes, Han Zhao, Yu-Xiang Wang, and Geoffrey J Gordon. Domain adaptation with conditional distribution matching and generalized label shift. _Advances in Neural Information Processing Systems_, 33:19276-19289, 2020.
* Wang et al. (2020) Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. _arXiv preprint arXiv:2006.10726_, 2020.
* Wu et al. (2021) Ruihan Wu, Chuan Guo, Yi Su, and Kilian Q Weinberger. Online adaptation to label distribution shift. _Advances in Neural Information Processing Systems_, 34:11340-11351, 2021.
* Xie et al. (2020) Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V. Le. Self-training with noisy student improves imagenet classification. In _2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pp. 10684-10695, 2020. doi: 10.1109/CVPR42600.2020.01070.
* Zadrozny (2004) Bianca Zadrozny. Learning and evaluating classifiers under sample selection bias. In _Proceedings of the Twenty-First International Conference on Machine Learning_, pp. 114, 2004.
* Zhang et al. (2023) Yu-Jie Zhang, Zhen-Yu Zhang, Peng Zhao, and Masashi Sugiyama. Adapting to continuous covariate shift via online density ratio estimation. _arXiv preprint arXiv:2302.02552_, 2023.

Further Related Work

**Offline distribution shift and domain shift.** Offline label shift and covariate shift have been studied for many years. Some early work (Saerens et al., 2002; Lin et al., 2002) assumes the knowledge of how the distribution is shifted. Later work (Shimodaira, 2000; Zadrozny, 2004; Huang et al., 2006; Gretton et al., 2009; Lipton et al., 2018; Alexandari et al., 2020; Azizzadenesheli et al., 2019; Garg et al., 2020) relaxes this assumption and estimates this knowledge from unlabeled test data.

**Online distribution shift with provable guarantees.** There has been several work modeling online distribution shift as the classic online learning problem (Wu et al., 2021; Bai et al., 2022; Baby et al., 2023; Zhang et al., 2023), which leverage the classical online learning algorithms (Shalev-Shwartz, 2012; Besbes et al., 2015; Baby and Wang, 2022) to bound the static or dynamic regret. However, none of them updates the feature extractor in a deep learning model but only the last linear layer or the post-hoc linear reweighting vectors. Our proposed method OLS-OFU utilizes the deep learning SSL to improve the feature extractor, which brings better performance.

**Domain shift adaptation within online streaming data.** When we consider the most authentic online learning setup where the learner only receives the unlabeled samples, the most representative idea is test-time training (Sun et al., 2020; Wang et al., 2020; Liu et al., 2021; Niu et al., 2022), which utilizes a (deep learning) self-supervised loss to online update the model. However, it focuses on how to adapt to a _fixed_ domain shifted distribution from online streaming data and is not designed for how to adapt to continuous distribution changes during the test stage, while our algorithm concentrates the later problem. Besides test-time training, Hoffman et al. (2014) and Mullapudi et al. (2019) study the online domain shift for specific visual applications.

```
Require: Learning rate \(\eta\). for\(t=1,\cdots,T\)do Input at time \(t\): Samples \(S_{1}\cup\cdots\cup S_{t}\), models \(\{f_{1},\cdots,f_{t}\}\), and intermediate model \(\{f^{\prime\prime}_{1},\cdots,f^{\prime\prime}_{t}\}\) from step 3 in Algorithm 1, the validation set \(D^{\prime}_{0}\), the training label marginal \(q_{0}:=\mathcal{P}^{\text{train}}(y)\).  1. Compute the unbiased estimator for label marginal distribution: \(s_{t}=\frac{1}{|S_{t}|}\sum_{x_{t}\in S_{t}}C_{f^{\prime\prime}_{t},D^{\prime }_{0}}^{-1}f^{\prime\prime}_{t}(x_{t})\). \(\rhd\) In the original ROGD, it is \(f_{0}\) rather than \(f^{\prime\prime}_{t}\).  2. Grab the weight \(p_{t}\) from \(f_{t}\).  3. Update \(p_{t+1}:=\text{Proj}_{\Delta^{K-1}}\left[p_{t}-\eta\cdot J_{p}(p_{t})^{\top}s_{ t}\right]\),  where \(J_{p,f^{\prime\prime}_{t}}(p_{t})=\frac{\partial}{\partial p}(1-\text{diag}(C_{f^ {\prime\prime}_{t},D_{0},p}))|_{p=p_{t}}\), and let \(f_{t+1}\) be a reweighting version of \(f^{\prime\prime}_{t}\) by the weight \(\left(\frac{p_{t+1}|R}{q_{0}[R]}:k=1,\cdots K\right)\)\(\rhd\) In the original ROGD, it is \(f_{0}\) rather than \(f^{\prime\prime}_{t}\). Output at time \(t\): \(f^{\prime}_{t+1}\). endfor
```

**Algorithm 3** Revised ROGD for online feature updates ROGD-R. See the original version in Equation 7 and Equation 8 in Wu et al. (2021).

```
for\(t=1,\cdots,T\)do Input at time \(t\): Samples \(S_{1}\cup\cdots\cup S_{t}\), models \(\{f_{1},\cdots,f_{t}\}\), and intermediate model \(\{f^{\prime\prime}_{1},\cdots,f^{\prime\prime}_{t}\}\) from step 3 in Algorithm 1, the validation set \(D^{\prime}_{0}\), the train label marginal \(q_{0}:=\mathcal{P}^{\text{train}}(y)\).  1. Compute the unbiased estimator for label marginal distribution: \(s_{t}=\frac{1}{|S_{t}|}\sum_{x_{t}\in S_{t}}C_{f^{\prime}_{t},D^{\prime}_{0}} ^{-1}f^{\prime\prime}_{t}(x_{t})\). \(\rhd\) In the original FTL, it is \(f_{0}\) rather than \(f^{\prime\prime}_{t}\).  2. Compute \(p_{t+1}=\frac{1}{t}\sum_{\tau=1}^{t}s_{\tau}\).  3. Let \(f_{t+1}\) be a reweighting version of \(f^{\prime\prime}_{t}\) by  the weight \(\left(\frac{p_{t+1}[R]}{q_{0}[R]}:k=1,\cdots K\right)\)\(\rhd\) In the original FTL, it is \(f_{0}\) rather than \(f^{\prime\prime}_{t}\). Output at time \(t\): \(f^{\prime}_{t+1}\). endfor
```

**Algorithm 4** Revised FTH for online feature updates (FTH-R). See the original version in Equation 9 in Wu et al. (2021).

```
Require: The learning rate \(\eta\). for\(t=1,\cdots,T\)do Input at time \(t\): Samples \(S_{1}\cup\cdots\cup S_{t}\), models \(\{f_{1},\cdots,f_{t}\}\), and intermediate model \(\{f^{\prime\prime}_{1},\cdots,f^{\prime\prime}_{t}\}\) from step 3 in Algorithm 1, the validation set \(D^{\prime}_{0}\), the train label marginal \(q_{0}:=\mathcal{P}^{\text{train}}(y)\).
1. Compute the unbiased estimator for label marginal distribution: \(s_{t}=\frac{1}{|S_{t}|}\sum_{x_{t}\in S_{t}}C_{f^{\prime}_{t},D^{\prime}_{0}}f ^{\prime\prime}_{t}(x_{t})\). \(\rhd\) In the original UOGD, it is \(f_{0}\) rather than \(f^{\prime\prime}_{t}\).
2. Grab the weight \(w_{t}\) from the last linear layer of \(f_{t}\).
3. Update \(w_{t+1}:=w_{t}-\eta\cdot\frac{\partial}{\partial w}J_{w}(w_{t})^{\top}s_{t}\), where \(J_{w}(w_{t})=\frac{\partial}{\partial w}(\hat{R}^{1}_{t}(w),\cdots,\hat{R}^{K }_{t}(w))|_{w=w_{t}}\), \(\hat{R}^{k}_{t}(w)=\frac{1}{|D^{k}_{0}|}\sum_{(x,y)\in D^{k}_{0}}\ell_{\text{ ce}}(f(x|\theta^{\text{test}}_{t},\theta^{\text{linear}}=w),y)\), \(D^{k}_{0}\) denotes the set of data with label \(k\) in \(D_{0}\). \(\rhd\) In the original UOGD, it is \(\theta^{\text{test}}_{0}\) rather than \(\theta^{\text{test}}_{t}\).
4. Let \(f_{t+1}\) be \(f(\cdot|\theta^{\text{test}}_{t},w_{t+1})\). Output at time \(t\):\(\hat{f}^{\prime}_{t+1}\). endfor
```

**Algorithm 6** Revised ATLAS for online feature updates (ATLAS-R). See the original version in Equation 9 in Bai et al. (2022).

```
Require: The learning rate pool \(\mathcal{H}\) with size N; Meta learning rate \(\varepsilon\); \(\forall i\in[N]\), \(p_{1,i}=1/N\) and \(w_{1,i}=\theta^{\text{linear}}_{0}\) for\(t=1,\cdots,T\)do Input at time \(t\): Samples \(S_{1}\cup\cdots\cup S_{t}\), models \(\{f_{1},\cdots,f_{t}\}\), and intermediate model \(\{f^{\prime\prime}_{1},\cdots,f^{\prime\prime}_{t}\}\) from step 3 in Algorithm 1, the validation set \(D^{\prime}_{0}\), the train label marginal \(q_{0}:=\mathcal{P}^{\text{train}}(y)\).
1. Compute the unbiased estimator for label marginal distribution: \(s_{t}=\frac{1}{|S_{t}|}\sum_{x_{t}\in S_{t}}C_{f_{t},D^{\prime}_{0}}f^{\prime \prime}_{t}(x_{t})\). \(\rhd\) In the original ATLAS, it is \(f_{0}\) rather than \(f^{\prime\prime}_{t}\). for\(i\in[N]\)do
2. Update \(w_{t+1,i}:=w_{t}-\eta_{i}\cdot\frac{\partial}{\partial w_{t}}J_{w}(w_{t,i})^{ \top}s_{t}\), where \(J_{w}(w_{t,i})=\frac{\partial}{\partial w}(\hat{R}^{1}_{t}(w),\cdots,\hat{R}^ {K}_{t}(w))|_{w=w_{t},i}\), \(\hat{R}^{k}_{t}(w)=\frac{1}{|D^{k}_{0}|}\sum_{(x,y)\in D^{k}_{0}}\ell_{\text{ ce}}(f(x|\theta^{\text{test}}_{t},w),y)\), \(D^{k}_{0}\) denotes the set of data with label \(k\) in \(D_{0}\). endfor
3. Update weight \(p_{t+1}\) according to \(p_{p_{t+1}}\propto\exp(-\varepsilon\sum_{\tau=1}^{t-1}\hat{R}_{\tau}(\mathbf{ w}_{\tau,i}))\)
3. Compute \(w_{t+1}=\sum_{i=1}^{N}p_{t+1,i}w_{t+1,i}\). Let \(f_{t+1}\) be \(f(\cdot|\theta^{\text{test}}_{t},w_{t+1})\). Output at time \(t\):\(f^{\prime}_{t+1}\). endfor
```

**Algorithm 7** The learning rate pool \(\mathcal{H}\) with size N; Meta learning rate \(\varepsilon\); \(\forall i\in[N]\), \(p_{1,i}=1/N\) and \(w_{1,i}=\theta^{\text{linear}}_{0}\) for\(t=1,\cdots,T\)do

## Appendix B The Revision for Previous Online Label Shift Adaptation Algorithms

The revised algorithms to be used in the main algorithm OLS-OFU (Algorithm 1) are FTH-R (Algorithm 4), UOGD-R (Algorithm 5), ROGD-R (Algorithm 3), ATLAS-R (Algorithm 6).

## Appendix C Theorems for OLS and Proofs

In this section, we present the theoretical results of FLHFTL-OFU, ROGD-OFU, FTH-OFU, UOGD-OFU, ATLAS-OFU and their proofs. The proofs are mostly the same as the proofs for the original algorithms with small adjustments. As our results are not straight corollaries for the original theorems, we write the full proofs here for the completeness.

### Theorem for FLHFTL-OFU

Before proving Theorem 1 (in Section 3.2 ) we recall the assumption from Baby et al. (2023) for convenience. We refer the reader to Baby et al. (2023) for justifications and further details of the assumptions.

**Assumption 1**: _Assume access to the true label marginals \(q_{0}\in\Delta_{K}\) of the offline train data and the true confusion matrix \(C\in\mathbb{R}^{K\times K}\). Further the minimum singular value \(\sigma_{min}(C)=\Omega(1)\) is bounded away from zero._

**Assumption 2** (Lipschitzness of loss functions): _Let \(\mathcal{D}\) be a compact and convex domain. Let \(r_{t}\) be any probabilistic classifier. Assume that \(L_{t}(p):=E\left[\ell(g(\cdot;r_{t},p/q_{0})|x_{t}|\right]\) is \(G\) Lipschitz with \(p\in\mathcal{D}\subseteq\Delta_{K}\), i.e, \(L_{t}(p_{1})-L_{t}(p_{2})\leq G\|p_{1}-p_{2}\|_{2}\) for any \(p_{1},p_{2}\in\mathcal{D}\). The constant \(G\) need not be known ahead of time._

**Theorem 1**: _[Regret convergence for FLHFTL-OFU] Suppose we choose the OLS subroutine in Algorithm 2 to be FLH-FTL from Baby et al. (2023). Let \(f_{t}^{\rm{thft1-ofu}}\) be the output at time step \(t-1\) from Algorithm 1, that is \(g(\cdot;f_{t}^{\prime\prime},\tilde{q}_{t}/q_{0})\). Let \(\sigma\) be the smallest among the the minimum singular values of invertible confusion matrices \(\{C_{f_{t}^{\prime\prime},D_{0}^{\prime}},\cdots C_{f_{T}^{\prime\prime},D_{0}^ {\prime}}\}\). Then under Assumptions 1 and 2 in Baby et al. (2023), FLHFTL-OFU has the guarantee for online label shift below:_

\[\mathbb{E}\left[\frac{1}{T}\sum_{t=1}^{T}\ell(f_{t}^{\rm{thft1-ofu}};\mathcal{ P}_{t}^{\rm{test}})-\frac{1}{T}\sum_{t=1}^{T}\ell(g(\cdot;f_{t}^{\prime\prime},q_{ t}/q_{0});\mathcal{P}_{t}^{\rm{test}})\right]\leq O\left(\frac{K^{1/6}V_{T}^{1/3}}{ \sigma^{2/3}T^{1/3}}+\frac{K}{\sigma\sqrt{T}}\right), \tag{3}\]

_where \(V_{T}:=\sum_{t=1}^{T}\|q_{t}-q_{t-1}\|_{1}\), \(K\) is the number of classes, and the expectation is taken w.r.t. randomness in the revealed co-variates. This result is attained without prior knowledge of \(V_{T}\)._

**Proof:**

The algorithm in Baby et al. (2023) requires that the estimate \(s_{t}\) in Line 1 of Algorithm 2 is unbiased estimate of the label marginal \(q_{t}\). Since \(f_{t}^{\prime\prime}\) in Algorithm 2 is independent of the sample \(S_{t}\), and since we are working under the standard label shift assumption, due to Lipton et al. (2018) we have that \(C_{f_{t}^{\prime\prime},D_{0}^{\prime}}^{-1}\cdot|\mathbb{E}_{t}|\sum_{x_{t}\in S _{t}}f_{t}^{\prime\prime}(x_{t})\) forms an unbiased estimate of \(E_{x\sim\mathcal{P}_{t}^{\rm{test}}}[f_{t}^{\prime\prime}(x)]\). Further, from Lipton et al. (2018), the reciprocal of standard deviation of this estimate is bounded below by minimum of the singular values of confusion matrices \(\{C_{f_{t}^{\prime\prime},D_{0}^{\prime}},\cdots C_{f_{T}^{\prime\prime},D_{0}^ {\prime}}\}\).

Let \(\tilde{q_{t}}\) be the estimate of the label marginal maintained by FLHFTL. By Lipschitzness, we have that

\[E[\ell(f_{t}^{\rm{thft1-ofu}};\mathcal{P}_{t}^{\rm{test}})-\ell(g( \cdot;f_{t}^{\prime\prime},p/q_{0})] =E[L_{t}(\tilde{q}_{t})]-E[L_{t}(q_{t})] \tag{6}\] \[\leq G\cdot E[\|\tilde{q}_{t}-q_{t}\|_{2}], \tag{7}\]

where the last line is via Assumption 2. Rest of the proof is identical to that of Baby et al. (2023). We reproduce it below for completeness.

\[\sum_{t=1}^{T}E[\ell(f_{t}^{\rm{thft1-ofu}};\mathcal{P}_{t}^{\rm{ test}})-\ell(g(\cdot;f_{t}^{\prime\prime},p/q_{0})] \leq\sum_{t=1}^{T}G\cdot E[\|\tilde{q}_{t}-q_{t}\|_{2}] \tag{8}\] \[\leq\sum_{t=1}^{T}G\sqrt{E\|\tilde{q}_{t}-q_{t}\|_{2}^{2}}\] (9) \[\leq G\sqrt{T\sum_{t=1}^{T}E[\|\tilde{q}_{t}-q_{t}\|_{2}^{2}]}\] (10) \[=\tilde{O}\Bigg{(}K^{1/6}T^{2/3}V_{T}^{1/3}(1/\sigma_{min}^{2/3} (C))+\sqrt{KT}/\sigma_{min}(C)\Bigg{)}, \tag{11}\]where the second line is due to Jensen's inequality, third line by Cauchy-Schwartz and last line by Proposition 16 in Baby et al. (2023). This finishes the proof.

**Proof of Theorem 2**: The proof is similar to the arguments in the proof of Theorem 1. The only point of deviation is that we choose \(r_{t}=f_{0}\) instead of \(f^{\prime\prime}_{t}\) in Assumption 2. The rest of the arguments follow via Lipschitzness.

### Theorem for ROGD-OFU

We state the assumptions first for the later theorems. These assumptions are similar to Assumption 1-3 in Wu et al. (2021).

**Assumption 3**: \(\forall\mathcal{P}\in\{\mathcal{P}^{\rm train},\mathcal{P}^{\rm test}_{1}, \cdots,\mathcal{P}^{\rm test}_{T}\}\)_, \({\rm diag}(C_{f,\mathcal{P}})\) is differentiable with respect to \(f\)._

**Assumption 4**: \(\forall t\in[T]\)_, \(\ell(g(\cdot;f^{\prime\prime}_{t},p/q_{0});\mathcal{P}^{\rm test}_{t})\) is convex in \(p\), where \(f^{\prime\prime}_{t}\) is defined in Algorithm 1._

**Assumption 5**: \(\sup_{p\in\Delta^{K-1},i\in[K],t\in[T]}\|\nabla_{p}\ell(g(\cdot;f^{\prime\prime }_{t},p/q_{0});\mathcal{P}^{\rm test}_{t})\|_{2}\) _is finite and bounded by \(L\)._

**Theorem 3** (Regret convergence for ROGD-OFU): _If we run Algorithm 1 with ROGD-R (Algorithm 3) and \(\eta=\sqrt{\frac{2}{T}}\frac{1}{L}\), under Assumption 3, 4, 5, ROGD-OFU satisfies the guarantee_

\[\mathbb{E}\left[\frac{1}{T}\sum_{t=1}^{T}\ell(f^{\rm orgd-ofu}_{t};\mathcal{P }^{\rm test}_{t})\right]-\min_{p\in\Delta_{K}}\mathbb{E}\left[\frac{1}{T}\sum_{ t=1}^{T}\ell(g(\cdot;f^{\prime\prime}_{t},p/q_{0});\mathcal{P}^{\rm test}_{t}) \right]\leq\sqrt{\frac{2}{T}}L. \tag{12}\]

\[\mathbb{E}\left[\frac{1}{T}\sum_{t=1}^{T}\ell(f^{\rm orgd}_{t};\mathcal{Q}_{t}) \right]-\min_{p\in\Delta_{K}}\mathbb{E}\left[\frac{1}{T}\sum_{t=1}^{T}\ell(g( \cdot;p,f_{0},q_{0});\mathcal{Q}_{t})\right]\leq\sqrt{\frac{2}{T}}L. \tag{13}\]

**Proof:** For any fixed \(p\),

\[\ell(f^{\rm orgd-ofu}_{t};\mathcal{P}^{\rm test}_{t})-\ell(g(\cdot; f^{\prime\prime}_{t},p/q_{0});\mathcal{P}^{\rm test}_{t}) =\ell(g(\cdot;f^{\prime\prime}_{t},p_{t}/q_{0});\mathcal{P}^{\rm test }_{t})-\ell(g(\cdot;f^{\prime\prime}_{t},p/q_{0});\mathcal{P}^{\rm test}_{t})\] \[\leq(p_{t}-p)\cdot\nabla_{p}\ell(g(\cdot;f^{\prime\prime}_{t},p_{ t}/q_{0});\mathcal{P}^{\rm test}_{t})\] \[=(p_{t}-p)\cdot J_{p,f^{\prime\prime}_{t}}(p_{t})^{\top}\mathbb{ E}_{S_{t}}[s_{t}|S_{1},\cdots,S_{t-1}]\] \[=\mathbb{E}_{S_{t}}[(p_{t}-p)\cdot J_{p,f^{\prime\prime}_{t}}(p_ {t})^{\top}s_{t}|S_{1},\cdots,S_{t-1}],\]

where the last inequality holds by the fact that \((p_{t}-p)\cdot J_{p,f^{\prime\prime}_{t}}(p_{t})^{\top}\) is independent of \(\{S_{1},\cdots,S_{t-1}\}\).

To bound \((p_{t}-p)\cdot J_{p,f^{\prime\prime}_{t}}(p_{t})^{\top}s_{t}\),

\[\|p_{t+1}-p\|_{2}^{2} =\|{\rm Prof}_{\Delta^{K-1}}(p_{t}-\eta\cdot J_{p,f^{\prime\prime }_{t}}(p_{t})^{\top}s_{t})-p\|_{2}^{2}\] \[\leq\|p_{t}-\eta\cdot J_{p,f^{\prime\prime}_{t}}(p_{t})^{\top}s_ {t}-p\|_{2}^{2}\] \[=\|p_{t}-p\|_{2}^{2}+\eta^{2}\|J_{p,f^{\prime\prime}_{t}}(p_{t})^{ \top}s_{t}\|_{2}^{2}-2\eta(p_{t}-p)\cdot(J_{p,f^{\prime\prime}_{t}}(p_{t})^{ \top}s_{t}).\]

This implies

\[(p_{t}-p)\cdot(J_{p,f^{\prime\prime}_{t}}(p_{t})^{\top}s_{t})\leq\frac{1}{2\eta }(\|p_{t}-p\|_{2}^{2}-\|p_{t+1}-p\|_{2}^{2})+\frac{\eta}{2}\|J_{p,f^{\prime \prime}_{t}}(p_{t})^{\top}s_{t}\|_{2}^{2}\]

Thus

\[\mathbb{E}_{S_{1},\cdots,S_{T}}\left[\frac{1}{T}\sum_{t=1}^{T}\ell (f^{\rm orgd-ofu}_{t};\mathcal{P}^{\rm test}_{t})-\frac{1}{T}\sum_{t=1}^{T} \ell(g(\cdot;f^{\prime\prime}_{t},p/q_{0});\mathcal{P}^{\rm test}_{t})\right]\] \[\leq\mathbb{E}_{S_{1},\cdots,S_{T}}\left[\frac{1}{T}\sum_{t=1}^{T} \frac{1}{2\eta}(\|p_{t}-p\|_{2}^{2}-\|p_{t+1}-p\|_{2}^{2})+\frac{\eta}{2}\|J_{p,f^{\prime\prime}_{t}}(p_{t})^{\top}s_{t}\|_{2}^{2}\right]\] \[\leq\frac{1}{2\eta T}\|p_{1}-p\|_{2}^{2}+\frac{\eta}{2T}\sum_{t=1 }^{T}\mathbb{E}_{S_{1},\cdots,S_{t}}[\|J_{p,f^{\prime\prime}_{t}}(p_{t})^{\top}s _{t}\|_{2}^{2}]\] \[\leq\frac{1}{\eta T}+\frac{\eta L^{2}}{2}=\sqrt{\frac{2}{T}}L.\]This bound holds for any p. Thus,

\[\mathbb{E}_{S_{1},\cdots,S_{T}}\left[\frac{1}{T}\sum_{t=1}^{T}\ell(f_{t}^{\rm{ro}d -ofu};\mathcal{P}_{t}^{\rm{test}})\right]-\min_{p\in\Delta^{K-1}}\mathbb{E}_{S_ {1},\cdots,S_{T}}\left[\frac{1}{T}\sum_{t=1}^{T}\ell(g(\cdot;f_{t}^{\prime\prime },p/q_{0});\mathcal{P}_{t}^{\rm{test}})\right]\leq\sqrt{\frac{2}{T}}L.\]

### Theorem for Fth-Oeu

We begin with two assumptions.

**Assumption 6**: _For any \(\mathcal{P}^{\rm{test}}\) s.t. \(\mathcal{P}^{\rm{test}}(x|y)=\mathcal{P}^{\rm{train}}(x|y)\), denote \(q_{t}:=(\mathcal{P}_{t}^{\rm{test}}(y=k):k\in[K])\) and then_

\[\|q_{t}-\arg\min_{p\in\Delta^{K-1}}\ell(g(\cdot;f_{t}^{\prime\prime},p/q_{0}); \mathcal{P}^{\rm{test}})\|\leq\delta.\]

**Assumption 7**: \(\forall\mathcal{P}^{\rm{test}}\) s.t. \(\mathcal{P}^{\rm{test}}(x|y)=\mathcal{P}^{\rm{train}}(x|y)\), \(\sup_{p}\|\nabla_{p}\ell(g(\cdot;f_{t}^{\prime\prime},p/q_{0});\mathcal{P}^{ \rm{test}})\|\leq L\)__

**Theorem 4** (Regret convergence for Fth-Oeu): _If we run Algorithm 1 with FTH-R (Algorithm 4) and assume \(\sigma\) is no larger than the minimum singular value of invertible confusion matrices \(\{C_{f_{t}^{\prime\prime},D_{t}^{\prime}},\cdots C_{f_{t}^{\prime\prime},D_{t} ^{\prime}}^{\prime\prime}\}\), under Assumption 6 and 7 with \(\delta=0\), FTH-OFU satisfies the guarantee that with probability at least \(1-2KT^{-7}\) over samples \(S_{1}\cup\cdots\cup S_{T}\),_

\[\frac{1}{T}\sum_{t=1}^{T}\ell(f_{t}^{\rm{th}-ofu};\mathcal{P}_{t}^{\rm{test}})- \min_{p\in\Lambda_{k}}\frac{1}{T}\sum_{t=1}^{T}\ell(g(\cdot;f_{t}^{\prime\prime },p/q_{0});\mathcal{P}_{t}^{\rm{test}})\leq O\left(\frac{\log T}{T}+\frac{1}{ \sigma}\sqrt{\frac{K\log T}{T}}\right), \tag{14}\]

_where \(K\) is the number of classes._

**Proof:** Denote \(q_{t}:=(\mathcal{P}_{t}^{\rm{test}}(y=k):k\in[K])\). By the Hoeffding and union bound, we have

\[\mathbb{P}\left(\forall t\leq T,\|p_{t+1}-\frac{1}{t}\sum_{\tau=1}^{t}q_{\tau} \|\leq\sqrt{K}\varepsilon_{t}\right)\geq 1-\sum_{t=1}^{T}2M\exp\left(-2 \varepsilon_{t}^{2}t/\sigma^{2}\right).\]

This implies that with probability at least \(1-\sum_{t=1}^{T}2M\exp\left(-2\varepsilon_{t}^{2}t/\sigma^{2}\right)\), \(\forall p\),

\[\sum_{t=1}^{T}\ell(p_{t};\mathcal{P}_{t}^{\rm{test}})-\sum_{t=1}^ {T}\ell(g(\cdot;f_{t}^{\prime\prime},p/q_{0});\mathcal{P}_{t}^{\rm{test}})\] \[\leq\sum_{t=1}^{T}\ell(g(\cdot;f_{t}^{\prime\prime},\frac{1}{t} \sum_{\tau=1}^{t}q_{\tau}/q_{0});\mathcal{P}_{t}^{\rm{test}})-\sum_{t=1}^{T} \ell(g(\cdot;f_{t}^{\prime\prime},p/q_{0});\mathcal{P}_{t}^{\rm{test}})+L\sqrt {M}\cdot\sum_{t=1}^{T}\varepsilon_{t}\] \[\leq\sum_{t=1}^{T}\ell(g(\cdot;f_{t}^{\prime\prime},\frac{1}{t} \sum_{\tau=1}^{t-1}q_{\tau}/q_{0});\mathcal{P}_{t}^{\rm{test}})-\sum_{t=1}^{T} \ell(g(\cdot;f_{t}^{\prime\prime},\frac{1}{t}\sum_{\tau=1}^{t}q_{\tau}/q_{0}); \mathcal{P}_{t}^{\rm{test}})+L\sqrt{M}\cdot\sum_{t=1}^{T}\varepsilon_{t}\] \[\leq\sum_{t=1}^{T}L\left\|\frac{1}{t-1}\sum_{\tau=1}^{t-1}q_{\tau} -\frac{1}{t}\sum_{\tau=1}^{t}q_{\tau}\right\|+L\sqrt{M}\cdot\sum_{t=1}^{T} \varepsilon_{t}\] \[\leq\sum_{t=1}^{T}\frac{L}{t}\left\|\frac{1}{t-1}\sum_{\tau=1}^{t -1}q_{\tau}-q_{t}\right\|+L\sqrt{M}\cdot\sum_{t=1}^{T}\varepsilon_{t}\] \[\leq\sum_{t=1}^{T}\frac{2L}{t}+L\sqrt{M}\cdot\sum_{t=1}^{T} \varepsilon_{t}.\]

If we take \(\varepsilon_{t}=2\sigma\sqrt{\frac{\ln T}{T}}\), the above is equivalent to: with probability at least \(1-2KT^{-7}\)

\[\frac{1}{T}\sum_{t=1}^{T}\ell(p_{t};\mathcal{P}_{t}^{\rm{test}})-\min_{p}\frac{ 1}{T}\sum_{t=1}^{T}\ell(g(\cdot;f_{t}^{\prime\prime},p/q_{0});\mathcal{P}_{t}^ {\rm{test}})\leq 2L\frac{\ln T}{T}+4L\sigma\sqrt{\frac{K\ln T}{T}}\]

### Theorems for UOGD-OFU and ATLAS-OFU

**Theorem 5**: _[Regret convergence for UOGD-OFU] Let \(f(\cdot;\theta^{\rm feat}_{f^{\prime}_{t}},w)\) denote a network with the same feature extractor as that of \(f^{\prime\prime}_{t}\) and a last linear layer with weight \(w\). Let \(f^{\rm wogd-ofu}=f(\cdot;\theta^{\rm feat}_{f^{\prime\prime}},w_{t})\), where \(w_{t}\) is the weight maintained at round \(t\) by Algorithm 5. If we run Algorithm 1 with UOGD in Bai et al. (2022) and let step size be \(\eta\), then under the same assumptions as Lemma 1 in Bai et al. (2022), UOGD-OFU satisfies that_

\[\mathbb{E}\left[\frac{1}{T}\sum_{t=1}^{T}\ell(f^{\rm wogd-ofu};\mathcal{P}^{ \rm test}_{t})-\frac{1}{T}\sum_{t=1}^{T}\min_{w\in\mathcal{W}}\ell(f(\cdot; \theta^{\rm feat}_{f^{\prime}_{t}},w);\mathcal{P}^{\rm test}_{t})\right]\leq O \left(\frac{K\eta}{\sigma^{2}}+\frac{1}{\eta T}+\sqrt{\frac{Y_{T,\ell}}{T\eta}} \right), \tag{15}\]

_where \(V_{T,\ell}:=\sum_{t=2}^{T}\sup_{w\in\mathcal{W}}|\ell(f(\cdot;\theta^{\rm feat }_{f^{\prime\prime}_{t}},w);\mathcal{P}^{\rm test}_{t})-\ell(f(\cdot;\theta^{ \rm feat}_{f^{\prime}_{t-1}},w);\mathcal{P}^{\rm test}_{t-1})|\), \(\sigma\) denotes the minimum singular value of the invertible confusion matrices \(\{C_{f^{\prime\prime}_{t},D^{\prime}_{t}},\cdots C_{f^{\prime\prime}_{T},D^{ \prime}_{t}}\}\) and \(K\) is the number of classes and the expectation is taken with respect to randomness in the revealed co-variates._

**Proof Sketch:** Recall that \(\ell(f(\cdot;\theta^{\rm feat}_{f^{\prime}_{t}},w);\mathcal{P}^{\rm test}_{t}) :=E_{(x,y)\succ\mathcal{P}^{\rm test}_{t}}\ell_{\rm ce}\left(f(x|\theta^{\rm feat }_{f^{\prime\prime}_{t}},w),y\right)\).

This guarantee follows from the arguments in Bai et al. (2022) from two basic facts below:

1. The risk \(\ell(f(\cdot;\theta^{\rm feat}_{f^{\prime\prime}_{t}},w);\mathcal{P}^{\rm test }_{t})\) is convex in \(w\) over a convex and compact domain \(\mathcal{W}\).
2. It is possible to form unbiased estimates \(\hat{G}_{t}(w)\in\mathbb{R}^{K}\) such that \(E[\hat{G}_{t}(w)|S_{1:t-1}]=E_{((x,y)\succ\mathcal{P}^{\rm test}_{t})}\nabla_{w }\ell_{\rm ce}\left(f(x|\theta^{\rm feat}_{f^{\prime}_{t}},w),y\right)\).

Hence we proceed to verify these two facts in our setup. Fact 1 is true because the cross-entropy loss is convex in any subset of the simplex and the last linear layer weights only defines an affine transformation which preserves convexity.

For fact 2, note that the \(f^{\prime\prime}_{t}\) only uses the data until round \(t-1\). So by the same arguments in Bai et al. (2022), using the BBSE estimator defined from the classifier \(f^{\prime\prime}_{t}\), the unbiased estimate of risk gradient can be defined.

Let \(w_{t}\) be the weight of the last layer maintained by UOGD at round t. Let \(u_{1:T}\) be any sequence in \(\mathcal{W}\). Consequently we have for any round,

\[\ell(f^{\rm wogd-ofu};\mathcal{P}^{\rm test}_{t})-\ell(f(\cdot; \theta^{\rm feat}_{f^{\prime}},u_{t})) =\ell(f(\cdot;\theta^{\rm feat}_{f^{\prime\prime}},w_{t})-\ell( f(\cdot;\theta^{\rm feat}_{f^{\prime\prime}_{t}},u_{t})) \tag{16}\] \[\leq\langle\nabla_{w}\ell(f(\cdot;\theta^{\rm feat}_{f^{\prime \prime}_{t}},w_{t}-u_{t})\] (17) \[=\langle E[\hat{G}_{t}(u_{t})|S_{1:t-1}],w_{t}-u_{t}\rangle. \tag{18}\]

Rest of the proof is identical to Bai et al. (2022).

**Theorem 6** (Regret convergence for ATLAS-OFU): _Let \(f(\cdot;\theta^{\rm feat}_{f^{\prime}_{t}},w)\) denote a network with the same feature extractor as that of \(f^{\prime\prime}_{t}\) and a last linear layer with weight \(w\). Let \(f^{\rm atlas-ofu}=f(\cdot;\theta^{\rm feat}_{f^{\prime}_{t}},w_{t})\), where \(w_{t}\) is the weight maintained at round \(t\) by Algorithm 6. If we run Algorithm 1 with ATLAS in Bai et al. (2022) and set up the step size pool \(\mathcal{H}=\{\eta_{i}=O\left(\frac{\sqrt{KT}}{KT}\right)\cdot 2^{i-1}|i\in[N]\}\) (\(N=1+\lceil\frac{1}{2}\log_{2}(1+2T)\rceil\)), then under the same assumptions as Lemma 1 in Bai et al. (2022), UOGD-OFU satisfies that_

\[\mathbb{E}\left[\frac{1}{T}\sum_{t=1}^{T}\ell(f^{\rm atlas-ofu};\mathcal{P}^{ \rm test}_{t})-\frac{1}{T}\sum_{t=1}^{T}\min_{w\in\mathcal{W}}\ell(f(\cdot; \theta^{\rm feat}_{f^{\prime\prime}_{t+1}},w);\mathcal{P}^{\rm test}_{t}) \right]\leq O\left(\left(\frac{K^{1/3}}{\sigma^{2/3}}+1\right)\frac{V_{T,\ell}^ {1/3}}{T^{1/3}}+\sqrt{\frac{K}{\sigma^{2}T}}\right), \tag{19}\]

_where \(V_{T,\ell}:=\sum_{t=2}^{T}\sup_{w\in\mathcal{W}}|\ell(f(\cdot;\theta^{\rm feat }_{f^{\prime\prime}_{t}},w);\mathcal{P}^{\rm test}_{t})-\ell(f(\cdot;\theta^{ \rm feat}_{f^{\prime\prime}_{t-1}},w);\mathcal{P}^{\rm test}_{t-1})|\), \(\sigma\) denotes the minimum singular value of the invertible confusion matrices \(\{C_{f^{\prime\prime}_{t},D^{\prime}_{t}},\cdots C_{f^{\prime\prime}_{T},D^{ \prime}_{t}}\}\) and \(K\) is the number of classes and the expectation is taken with respect to randomness in the revealed co-variates._

The proof is similar to that of Theorem 5 and hence omitted.

Discussion about the assumption.In the theorems for UOGD and ATLAS, the definition of \(V_{T,\ell}\) is shift severity from \(\mathcal{P}_{t}^{\mathrm{test}}\). However, in the theorems for UOGD-OFU and ATLAS-OFU above, \(V_{T,\ell}\) is shift severity from both \(\mathcal{P}_{t}^{\mathrm{test}}\) and \(\theta_{f_{i^{\prime}}^{\mathrm{test}}}^{\mathrm{test}}\), which can be much larger. This might lead to harder convergence of the regret.

## Appendix D Additional experiments

### Additional details of datasets

Severity of CIFAR-10C in the experiment.For each type of corruption in CIFAR-10C, we select a mild level and a high level of severity in the experiment section. Here we introduce the exact parameters of mild and high levels of severity for those corruptions. For Gaussian Noise, the severity levels for [mild, high] are [0.03, 0.07]. For Fog, the severity levels for [mild, high] are [0.75,2.5], [1.5,1.75]). For Pixelate, the severity levels for [mild, high] are [0.75, 0.65].

Details of additional datasets.In addition to CIFAR-10 and CIFAR-10C, we evaluate on three more datasets: STL10 (Coates et al., 2011), CINIC (Darlow et al., 2018), and EuroSAT (Helber et al., 2019). Similar to CIFAR-10, we split the original train sets of these datasets into the train set and the validation set by the ratio \(4:1\) and use the original test sets for sampling test images in the online test stage.

### Results on Additional Datasets

Figure 5 shows the results for three additional datasets: STL10, CINIC, and EuroSAT, also with OLS-OFU (rotation degree prediction) under sinusoidal shift setting. In-line with CIFAR-10, we observe that OLS and OLS-OFU can perform better than Base and OFU, and OLS-OFU can outperform OLS. We find this pattern to be more consistent for EuroSAT and STL10 than CINIC.

### More Results on CIFAR-10

Figure 6 shows the results on CIFAR-10 for Bernoulli shift cross three SSL methods in OLS-OFU. Similar to Figure 2(a), OLS-OFU within all three SSL methods outperforms all baseline methods.

Figure 5: Results for additional datasets STL10, CINIC and EuroSAT.

### More Results on CIFAR-10C

We evaluate three SSL methods in OLS-OFU on CIFAR-10C for two online shift patterns. We pick moderately high severity levels for evaluating CIFAR-10C. In Figure 7 we can observe the consistent improvement from OLS to OLS-OFU and the SOTA performance of OLS-OFU.

### More Results on CIFAR-10C with High Severity

We evaluate three SSL methods in OLS-OFU on CIFAR-10C with _high severity_ for two online shift patterns. In Figure 8, we can observe when SSL in OLS-OFU is rotation degree prediction or MoCo, the improvement from OLS to OLS-OFU is very significant but OLS-OFU cannot outperform OFU. The conclusion is similar to the discussion for Figure 3 in Section 4. However, OLS-OFU with SSL entropy minimization has different behavior. When the corruption of CIFAR-10C becomes more severe, OLS-OFU entropy minimization shows less improvement from OLS, if we compare the transition: Figure 7 (clean CIFAR-10), Figure 7 (CIFAR-10C with mild severity), Figure 8 (CIFAR-10C with high severity). This suggests that rotation degree prediction and MoCo are more appropriate SSL to address the domain shift from CIFAR-10 to CIFAR-10C.

### Empirical evaluation for Equation 5

Figure 9 shows the comparison between LHS (OLS-OFU) and RHS (OLS) of the inequality in Equation 5 when the SSL in OLS-OFU is entropy minimization or MoCo. Similar to what we observe in Figure 4, the inequality in Equation 5 holds cross 4 data settings and two online shift patterns when OLS-OFU is implemented with entropy minimization or MoCo.

### Ablation for the order of updates and predictions

In the default framework of online distribution shift as shown in Figure 1, the model updates happen after the predictions for the samples at time step \(t\). We would like to see if the model updated before the predictions would bring benefit. Figure 10 shows the comparison between "predict first" and "update first". We can observe that there is no strong evidence to demonstrate the advantage of "predict first" or "update first" - the difference is indeed insignificant. However, because in the framework of "predict first" OLS and OLS-OFU enjoy strong theoretical guarantees, we recommend "predict first" in practice.

### Details of SSL Methods

When the SSL loss is rotation degree prediction, it requires another network \(f^{\rm deg}\) to predict the rotation degree, sharing the same feature extractor \(\theta^{\rm feat}\) as \(f_{0}\) but with a different set of downstream layers. Its SSL loss \(\ell_{\rm ssl}(S;f)\) is defined as \(\sum_{x\in S}\ell_{cc}(f^{\rm deg}(R(x,i)),i)\), where \(i\) is an integer uniformly sampled from \([4]\), and \(R(x,i)\) is to rotate \(x\) with degree \({\rm DL}[i]\) from a list of degrees \({\rm DL}=[0,90,180,270]\). Alternatively, if the SSL loss is entropy minimization, \(\ell_{\rm ssl}(S;f)\) would be the entropy \(\sum_{x\in S}\sum_{k=1}^{K}f(x)_{k}\log f(x)_{k}\). Moreover, the SSL loss would be a contrastive loss (InfoNCE) where the positive example \(x^{\prime}\) is an augmented version of \(x\) and other samples in the same

Figure 6: Results of Bernoulli shifts on CIFAR-10. OLS-OFU is evaluated with three SSL methods.

Figure 7: Results of two online shift patterns on CIFAR-10C and three SSL methods in OLS-OFU.

Figure 8: Results of two online shift patterns on CIFAR-10C (high severity) and three SSL methods in OLS-OFU.

Figure 10: Ablation for the order of updates and predictions.

time step can be the negative examples. However, the batch size for a time step is small, e.g. \(10\) in our experiment. MoCo updates with such a small batch won't work. Thus, we experiment with MoCo by applying a batch accumulation strategy, which we introduce next.

#### d.8.1 Batch accumulation for MoCo

Prior test-time training (rotation degree prediction, entropy minimization) methods operate with the OFU framework easily, with feature extractor updates taking place in each time step. Rotation degree prediction originates as a self-supervised training method (Gidaris et al., 2018), thus naturally we evaluate more recent self-supervised training methods, namely MoCo (He et al., 2019; Chen et al., 2020; 2021). No prior work shows how to use MoCo (or self-supervised learning in general) in a test-time training setting. Given that self-supervised training is sensitive to batch size, the intuition is that a larger batch size (much larger than the number of online samples available per time step) is required to perform a valid gradient update for a MoCo checkpoint. As such, we evaluated a _batch accumulation_ strategy OLS-OFU (BA=\(\tau\)), where we continue evaluating online samples per time step, but only perform the online feature update at every \(\tau\) steps (having accumulated the online samples throughout the \(\tau\) steps in one batch). In particular, we perform feature extractor update every \(\tau=50\) steps (for 1000 steps, feature update occurs 20 times, online samples evaluation occurs 1000 times), evaluating with 10 online samples per time step, using a smaller learning rate (0.0005) but test-time train with 10 epochs. Notice that \(\tau=1\) is the default setting in Algorithm 1. OLS-OFU with MoCo presented in Figure 2, Figure 6 and Figure 7 is equivalent to OLS-OFU (BA=\(50\)).

To show the necessity of large \(\tau\), we evaluate both OLS-OFU (BA=1) and OLS-OFU (BA=50) on CIFAR-10 (Figure 11) and CIFAR-10C (Figure 12). Firstly, we can observe that OLS-OFU (BA=1) is even worse than OLS. We hypothesize this is because small batch size of MoCo will hurt the performance and larger batch size in MoCo is necessary. Hence, we increase \(\tau\) from \(1\) to \(50\) and then we can observe the significant improvement from OLS-OFU (BA=1) to OLS-OFU (BA=50). Now, OLS-OFU (BA=50) can outperform OLS.

in the first OLS paper) and FLHFTL (SOTA in the literature). We also calculate \(\Delta_{\rm error}\) between FLHFTL and FLHFTL-OFU.

Figure 13 shows the \(\Delta_{\rm error}\) for FTH\(\rightarrow\)FLHFTL and FLHFTL\(\rightarrow\)FLHFTL-OFU across all data settings (dataset and online shift pattern) when the SSL in \(OFU\) is set as rotation degree prediction. The improvement of FLHFTL\(\rightarrow\)FLHFTL-OFU is as significant as the improvement of FTH\(\rightarrow\)FLHFTL. Moreover, the improvement of FLHFTL\(\rightarrow\)FLHFTL-OFU is more consistent. This consistency demonstrates the potential that OLS-OFU can have improvement for any future OLS algorithm.

### Self-training

Pseudo labelling (Lee, 2013), a common self-training technique, generates pseudo labels for unlabelled data and uses them to update the model. Though we are not able to use ground-truth labels to compute feature extractor updates, we can use the model at time \(t\) to make predictions with respect to the online samples at time \(t\), and train on the inputs with their assigned (pseudo) labels. An issue that arises in self-training is confirmation bias, where the model repeatedly overfits to incorrect pseudo-labels. As such, different methods can be used to select which samples will be pseudo-labelled and used in updating the model, e.g. using data augmentation (Arazo et al., 2020), using

Figure 12: Evaluating OLS-OFU with different batch accummulations for MoCo on CIFAR-10C.

Figure 13: Improvements from FTH to FLHFTL and improvements from FLHFTL to FLHFTL-OFU across all datasets and online shift patterns.

regularization to induce confident low-entropy pseudo-labelling (Grandvalet & Bengio, 2004a), using softmax thresholds to filter out noisy low-confidence predictions (Xie et al., 2020). We make use of ensembles to identify noisy low-confidence/entropy pseudo-label predictions, though other various alternatives can also be used. In addition to OLS and OLS-OFU, we highlight the methods under comparison:

* _OLS-OFU_ (\(\ell_{\rm sup}(\cdot,y_{\text{ground-truth}})\)): Instead of computing pseudo-labels, we make use of the correct ground-truth labels \(y_{\text{ground-truth}}\). Recall \(\ell_{\rm sup}\) is the supervised learning loss. We update the feature extractor with the supervised loss w.r.t. ground-truth labels \(\ell_{\rm sup}(\cdot,y_{\text{ground-truth}})\).
* _OLS-OFU_ (\(\ell_{\text{ssl}}+\ell_{\rm sup}(\cdot,y_{\text{ground-truth}})\)): Instead of computing pseudo-labels, we make use of the correct ground-truth labels \(y_{\text{ground-truth}}\). Recall \(\ell_{\rm ssl}\) and \(\ell_{\rm sup}\) are the self-supervised and supervised learning losses respectively. We update the feature extractor with both the self-supervised loss \(\ell_{\rm ssl}\) as well as the supervised loss w.r.t. ground-truth labels \(\ell_{\rm sup}(\cdot,y_{\text{ground-truth}})\).
* _OLS-OFU_ (\(\ell_{\text{ssl}}+\ell_{\rm sup}(\cdot,y_{\text{pseudo-label}(\text{ssamples },\text{\#FU-samples})})\)): Recall \(\ell_{\text{ssl}}\) and \(\ell_{\rm sup}\) are the self-supervised and supervised learning losses respectively. We compute pseudo-labels \(y_{\text{pseudo-label}}\)), and update the feature extractor with both the self-supervised loss \(\ell_{\rm ssl}\) as well as the supervised loss w.r.t. pseudo-labels \(\ell_{\rm sup}(\cdot,y_{\text{pseudo-label}})\).

How to compute pseudo-labels?We now describe the procedure to compute pseudo-labels for \(\ell_{\rm sup}(\cdot,y_{\text{pseudo-label}(\text{ssamples},\text{\#FU-samples})})\). The seed used to train our model is 4242, and we train an additional 4 models on seeds 4343, 4545, 4646, 4747. With this ensemble of 5 models, we keep sampling inputs at each online time step until we have #FU-samples samples, or we reach a limit of #samples samples. We accept an input when the agreement between the ensembles exceeds a threshold \(e=1.0\) (i.e. we only accept samples where all 5 ensembles agree on the label of the online sample). In the default online learning setting, there are only #samples=10, and therefore there may not be enough accepted samples to perform feature update with, thus we evaluate with a continuous sampling setup, where we sample #samples=50 (and evaluate on all these samples), but only use the first 10 samples (#FU-samples=10) to perform the feature extractor update.

Results on pseudo-labellingFirst, we find that _OLS-OFU_ (\(\ell_{\text{ssl}}+\ell_{\rm sup}(\cdot,y_{\text{ground-truth}})\)) attains the lowest error and is the lower bound we are attaining towards. Evaluating _OLS-OFU_ (\(\ell_{\text{ssl}}+\ell_{\rm sup}(\cdot,y_{\text{pseudo-label}(\text{ssamples }=10,\text{\#FU-samples}=10)})\)), we find that the performance does not outperform OLS-OFU, and is not near _OLS-OFU_ (\(\ell_{\text{ssl}}+\ell_{\rm sup}(\cdot,y_{\text{ground-truth}})\)). If we set the threshold \(e\) too high, there may not be enough online samples to update the feature extractor. If we set the threshold \(e\) too low, there may be too many incorrect labels and we incorrectly update our feature extractor. As such, we would like to sample more inputs at each online time step such that we can balance this tradeoff. We sample #samples=50 at each online time step, and update with #FU-samples \(\leq\) 10. For fair comparison, we also show the comparable methods in both #samples=10, #FU-samples=10 and #samples=50, #FU-samples=50 settings.

With this sampling setup, we find that _OLS-OFU_ (\(\ell_{\text{ssl}}+\ell_{\rm sup}(\cdot,y_{\text{pseudo-label}(\text{sSamples }=50,\text{\#FU-samples}=10)})\) can outperform both _OLS-OFU_ (#samples=10) and _OLS-OFU_ (#samples=50). Though it does not exceed neither _OLS-OFU_ (\(\ell_{\text{ssl}}+\ell_{\rm sup}(\cdot,y_{\text{ground-truth}})\)) for #samples=10 nor #samples=50, it lowers the gap considerably.

Figure 14: Results on pseudo-labelling.