# Transport meets Variational Inference:

Controlled Monte Carlo Diffusions

Anonymous authors

Paper under double-blind review

###### Abstract

Connecting optimal transport and variational inference, we present a principled and systematic framework for sampling and generative modelling centred around divergences on path space. Our work culminates in the development of _Controlled Monte Carlo Diffusions_ for sampling and inference, a score-based annealing technique that crucially adapts both forward and backward dynamics in a diffusion model. On the way, we clarify the relationship between the EM-algorithm and iterative proportional fitting (IPF) for Schrodinger bridges, providing a conceptual link between fields. Finally, we show that CMCD has a strong foundation in the Jarzinsky and Crooks identities from statistical physics, and that it convincingly outperforms competing approaches across a wide array of experiments.

## 1 Introduction

Optimal transport (Villani et al., 2009) and variational inference (Blei et al., 2017) have for a long time been separate fields of research. In recent years, many fruitful connections have been established (Liu et al., 2019), in particular based on dynamical formulations (Tzen and Raginsky, 2019), and in conjunction with time reversals (Huang et al., 2021; Song et al., 2021). The goal of this paper is twofold: In the first part, we enhance those relationships based on forward and reverse time diffusions, and associated Girsanov transformations, arriving at a unifying framework for generative modeling and sampling. In the second part, we build on this and develop a novel score-based scheme for sampling from unnormalised densities. To set the stage, we recall a classical approach (Kingma and Welling, 2014; Rezende and Mohamed, 2015) towards generating samples from a target distribution \(\mu(\mathbf{x})\), which is the goal both in generative modelling and sampling:

**Generative processes, encoders and decoders.** We consider methodologies which can be implemented via the following generative process,

\[\mathbf{z}\sim\nu(\mathbf{z}),\qquad\mathbf{x}|\mathbf{z}\sim p^{\theta}(\mathbf{x}|\mathbf{z}), \tag{1}\]

transforming a sample \(\mathbf{z}\sim\nu(\mathbf{z})\) into a sample \(\mathbf{x}\sim\int p^{\theta}(\mathbf{x}|\mathbf{z})\nu(\mathrm{d}\mathbf{z})\). Traditionally, \(\nu(\mathbf{z})\) is a simple auxiliary distribution, and the family of transitions \(p^{\theta}(\mathbf{x}|\mathbf{z})\) is parameterised flexibly and in such a way that sampling according to (1) is tractable. Then we can frame the tasks of generative modelling and sampling as finding transition densities such that the marginal in \(\mathbf{x}\) matches the target distribution,

\[\mu(\mathbf{x})=\int p^{\theta}(\mathbf{x}|\mathbf{z})\nu(\mathrm{d}\mathbf{z}). \tag{2}\]

To learn such a transition, it is helpful to introduce a reversed process

\[\mathbf{x}\sim\mu(\mathbf{x}),\qquad\mathbf{z}|\mathbf{x}\sim q^{\phi}(\mathbf{z}|\mathbf{x}), \tag{3}\]

relying on an appropriately parameterised backward transition \(q^{\phi}(\mathbf{z}|\mathbf{x})\). We will say that (1) and (3) are _reversals of each other_ in the case when their joint distributions coincide, that is, when

\[q^{\phi}(\mathbf{z}|\mathbf{x})\mu(\mathbf{x})=p^{\theta}(\mathbf{x}|\mathbf{z})\nu(\mathbf{z}). \tag{4}\]

To appreciate the significance of (3), notice that if (4) holds, then (2) is implied by integrating both sides with respect to \(\mathbf{z}\). Building on this observation, it is natural to define the loss function

\[\mathcal{L}_{D}(\phi,\theta):=D\left(q^{\phi}(\mathbf{z}|\mathbf{x})\mu(\mathbf{x})\big{|} \big{|}p^{\theta}(\mathbf{x}|\mathbf{z})\nu(\mathbf{z})\right), \tag{5}\]where \(D\) is a divergence1 between distributions yet to be specified. Along the lines of Bengio et al. (2021); Sohl-Dickstein et al. (2015); Wu et al. (2020); Liu et al. (b), we have now laid the foundations for algorithmic approaches that aim at sampling from \(\mu(\mathbf{x})\) by minimising \(\mathcal{L}_{D}(\phi,\theta)\):

Footnote 1: As usual, divergences are characterised by the requirement that \(D(\alpha||\beta)\geq 0\), with equality iff \(\alpha=\beta\).

**Framework 1**.: Let \(D\) be an arbitrary divergence, and assume that \(\mathcal{L}_{D}(\phi,\theta)=0\). Then we have

\[\mu(\mathbf{x})\!=\!\!\int\!\!p^{\theta}(\mathbf{x}|\mathbf{z})\nu(\mathrm{d}\mathbf{z})\quad \text{ and }\quad\nu(\mathbf{z})\!=\!\!\int\!\!q^{\phi}(\mathbf{z}|\mathbf{x})\mu(\mathrm{d} \mathbf{x}), \tag{6}\]

that is, \(\nu(\mathbf{z})\) is transformed into \(\mu(\mathbf{x})\) by \(p^{\theta}(\mathbf{x}|\mathbf{z})\), and \(\mu(\mathbf{x})\) is transformed into \(\nu(\mathbf{z})\) by \(q^{\phi}(\mathbf{z}|\mathbf{x})\).

**The sampling problem.** Let \(\nu\) denote a probability density function on \(\mathbb{R}^{d}\) of the form \(\nu(\mathbf{z})=\frac{\hat{\nu}(\mathbf{z})}{Z},\quad Z=\int_{\mathbb{R}^{d}}\hat{\nu} (\mathbf{z})\mathrm{d}\mathbf{z}\), where \(\hat{\nu}:\mathbb{R}^{d}\to\mathbb{R}^{+}\)can be differentiated and evaluated pointwise but the normalizing constant \(Z\) is intractable. We are interested in both estimating \(Z\) and obtaining approximate samples from \(\nu\) given we can sample from a more tractable density \(\mu\). Framework 1 provides us with an objective to tackle the sampling problem as once \(\mathcal{L}_{D}(\phi,\theta)=0\), we can generate samples from \(\nu(\mathbf{z})\) via the variational distribution \(q^{\phi}(\mathbf{z}|\mathbf{x})\). Through variational inference and optimal transport, we discuss relationships to classical methods as well as shortcomings:

**KL-divergence, ELBO and variational inference.** Choosing \(D=D_{\mathrm{KL}}\) in (5), variational inference (VI) and latent variable model based approaches (Dempster et al., 1977; Blei et al., 2017; Kingma and Welling, 2014) can elegantly be placed within Framework 1. Indeed, direct computation (see Appendix B) shows that \(\mathcal{L}_{D_{\mathrm{KL}}}(\phi,\theta)=-\mathbb{E}_{\mathbf{x}\sim\mu(\mathbf{x})} [\mathrm{ELBO}_{\mathbf{x}}(\phi,\theta)]+\mathbb{E}_{\mathbf{x}\sim\nu(\mathbf{z})}[\ln \mu(\mathbf{x})]\), so that minimising \(\mathcal{L}_{D_{\mathrm{KL}}}(\phi,\theta)\) is equivalent to maximising the expected evidence lower bound (ELBO), also known as the negative free energy (Blei et al., 2017). This derivation is alternative to the standard approach via maximum likelihood and convex duality (or Jensen's inequality) (Kingma et al., 2021, Section 2.2), and directly accommodates various modifications by replacing the \(D_{\mathrm{KL}}\)-divergence (see Appendix B).

**Couplings, (optimal) transport and nonuniqueness.** Assuming (4) holds, it is natural to define the joint distribution \(\pi(\mathbf{x},\mathbf{z}):=q^{\phi}(\mathbf{z}|\mathbf{x})\mu(\mathbf{x})=p^{\theta}(\mathbf{x}|\mathbf{ z})\nu(\mathbf{z})\), which is a coupling between \(\mu(\mathbf{x})\) and \(\nu(\mathbf{z})\). Viewed from this angle, the set of minimisers of \(\mathcal{L}(\phi,\theta)\) stands in one-to-one correspondence with the set of couplings between \(\mu(\mathbf{x})\) and \(\nu(\mathbf{z})\), provided that the parameterisations are chosen flexibly enough. Under the latter assumption, the objective in (5) admits an infinite number of minimisers, rendering algorithmic approaches solely based on Framework 1 potentially unstable and their output hard to interpret. In the language of _optimal transport_(Villani, 2003), minimising \(\mathcal{L}(\phi,\theta)\) enforces the marginal (_'transport'_) constraints in (6) without a selection principle based on an appropriate cost function (_'optimal'_).

Methods such as VAEs (Kingma and Welling, 2014) parameterise \(p^{\theta}(\mathbf{x}|\mathbf{z})\) and \(q^{\phi}(\mathbf{z}|\mathbf{x})\) with a restricted family of distributions (such as Gaussians), thus restricting the set of couplings. Expectation maximisation (EM) minimises \(\mathcal{L}(\phi,\theta)\) in a component-wise fashion, resolving nonuniqueness in a procedural manner (see Section 3.1). Common diffusion models fix either \(p^{\theta}(\mathbf{x}|\mathbf{z})\) or \(q^{\phi}(\mathbf{z}|\mathbf{x})\), and thus select a coupling (Section 2.2). In this paper, we argue that the full potential of diffusion models can be unleashed by training the forward and backward processes at the same time, but appropriate modifications that resolve the nonuniqueness inherent in Framework 1 need to be imposed. To develop principled approaches towards this, we proceed as follows:

**Outline and contributions.** In Section 2 we recall hierarchical VAEs (Rezende et al., 2014) and, following Tzen and Raginsky (2019), proceed to the infinite-depth limit described by the SDEs in (12). Readers more familiar with VI and discrete time might want to take the development in Section 2.1 as an explanation of (12); readers with background in stochastic analysis might take Framework 1\({}^{\prime}\) as their starting point. In Proposition 2.2 we provide a generalised form of the Girsanov theorem for forward-reverse time SDEs, crucially incorporating the choice of a reference process that allows us to reason about sampling and generation in a systematic and principled way. We demonstrate that a range of widely used approaches, such as score-based diffusions and path integral samplers, among others, are special cases of our unifying framework (Section 2.2). Similarly in Section 3.1 we unify optimal transport (OT) and VI under our framework by establishing a correspondence between expectation-maximisation (EM) and iterative proportional fitting (IPF). Going further, we show that this framework allows us to derive new methods:

In Section 3.2, we derive a novel score-based annealed flow technique, the Controlled Monte Carlo Diffusion (CMCD) sampler, and show that it may be viewed as an infinitesimal analogue of the method from Section 3.1. Finally, we connect CMCD to the foundational identities by Crooks and Jarzynski in statistical physics, and show that it empirically outperforms a range of state-of-the-art inference methods in sampling and estimating normalizing constants (Section 4).

## 2 From hierarchical VAEs to forward-reverse time diffusions

### Hierarchical VAEs (Rezende et al., 2014)

A particularly flexible choice of implicitly parameterising \(p^{\theta}(\mathbf{x}|\mathbf{z})\) and \(q^{\phi}(\mathbf{z}|\mathbf{x})\) can be achieved via a hierarchical model with intermediate latents: We identify \(\mathbf{x}=:\mathbf{y}_{0}\) and \(\mathbf{z}=:\mathbf{y}_{L}\) with the 'endpoints' of the layered augmentation \((\mathbf{y}_{0},\mathbf{y}_{1},\ldots,\mathbf{y}_{L-1},\mathbf{y}_{L})=:\mathbf{y}_{0:L}\), and define

\[q^{\phi}(\mathbf{y}_{L},\ldots,\mathbf{y}_{1}|\mathbf{y}_{0}):=\prod_{l=1}^{L}q^{\phi_{l-1 }}(\mathbf{y}_{l}|\mathbf{y}_{l-1}),\qquad p^{\theta}(\mathbf{y}_{0},\ldots,\mathbf{y}_{L-1}| \mathbf{y}_{L}):=\prod_{l=1}^{L}p^{\theta_{l}}(\mathbf{y}_{l-1}|\mathbf{y}_{l}), \tag{7}\]

so that \(q^{\phi}(\mathbf{z}|\mathbf{x})\) and \(p^{\theta}(\mathbf{x}|\mathbf{z})\) can be obtained from (7) by marginalising over the auxiliary variables \(\mathbf{y}_{1},\ldots,\mathbf{y}_{L-1}\). Here, \(\phi=(\phi_{0},\ldots,\phi_{L-1})\) and \(\theta=(\theta_{1},\ldots,\theta_{L})\) refer to sets of parameters to be specified in more detail below. Further introducing notation, we write \(q^{\mu,\phi}(\mathbf{y}_{0:L}):=q^{\phi}(\mathbf{y}_{1:L}|\mathbf{y}_{0})\mu(\mathbf{y}_{0})\) as well as \(p^{\nu,\theta}(\mathbf{y}_{0:L}):=p^{\theta}(\mathbf{y}_{0:L-1}|\mathbf{y}_{L})\nu(\mathbf{y} _{L})\) and think of those implied joint distributions as emanating from \(\mu(\mathbf{x})=\mu(\mathbf{y}_{0})\) and \(\nu(\mathbf{z})=\nu(\mathbf{y}_{L})\), respectively, moving 'forwards' or 'backwards' according to the specific choices for \(\phi\) and \(\theta\). In the regime when \(L\) is large, the models in (7) are very expressive, even if the intermediate transition kernels are parameterised in a simple manner. We hence proceed by assuming Gaussian distributions,

\[q^{\phi_{l-1}}(\mathbf{y}_{l}|\mathbf{y}_{l-1})=\mathcal{N}(\mathbf{y}_{l}|\mathbf{y}_{l-1}+ \delta a^{\phi}_{l-1}(\mathbf{y}_{l-1}),\delta\sigma^{2}I),\ \ p^{\theta_{l}}(\mathbf{y}_{l-1}|\mathbf{y})=\mathcal{N}(\mathbf{y}_{l-1}|\mathbf{y}_{l}+ \delta b^{\theta}_{l}(\mathbf{y}_{l}),\delta\sigma^{2}I), \tag{8}\]

where \(\sigma>0\) controls the standard deviation, and \(\delta>0\) is a small parameter, anticipating the limits \(L\to\infty\), \(\delta\to 0\) to be taken in Section 2.2 below. The vector fields \(a^{\theta}_{l}(\mathbf{y}_{l})\) and \(b^{\theta}_{l}(\mathbf{y}_{l})\) introduced in (8) should be thought of as parameterised by \(\phi\) and \(\theta\), but we will henceforth suppress this for brevity.

The models (7)-(8) could equivalently be defined via the Markov chains

\[\mathbf{y}_{l+1} =\mathbf{y}_{l}+\delta a_{l}(\mathbf{y}_{l})+\sqrt{\delta}\sigma\xi_{l}, \qquad\mathbf{y}_{0}\sim\mu\implies\mathbf{y}_{0:L}\sim q^{\mu,\phi}(\mathbf{y}_{0:L}), \tag{9a}\] \[\mathbf{y}_{l-1} =\mathbf{y}_{l}+\delta b_{l}(\mathbf{y}_{l})+\sqrt{\delta}\sigma\xi_{l}, \qquad\mathbf{y}_{L}\sim\nu\implies\mathbf{y}_{0:L}\sim p^{\nu,\theta}(\mathbf{y}_{0:L}), \tag{9b}\]

where \((\xi_{l})^{L}_{l=1}\) is an iid sequence of standard Gaussian random variables. As indicated, the forward process in (9a) may serve to define the distribution \(q^{\mu,\phi}(\mathbf{y}_{0:L})\), whilst the backward process in (9b) induces \(p^{\nu,\theta}(\mathbf{y}_{0:L})\). Note that the transition densities \(p^{\theta}(\mathbf{x}|\mathbf{z})\) and \(q^{\phi}(\mathbf{z}|\mathbf{x})\) obtained as the marginals of (7) will in general not be available in closed form. However, generalising slightly from Framework 1, we may set out to minimise the extended loss

\[\mathcal{L}^{\text{ext}}_{D}(\phi,\theta)=D(q^{\mu,\phi}(\mathbf{y}_{0:L})||p^{\nu, \theta}(\mathbf{y}_{0:L})), \tag{10}\]

where \(D\) refers to a divergence on the 'discrete path space' \(\{\mathbf{y}_{0:L}\}\). Clearly, \(\mathcal{L}^{\text{ext}}_{\mathcal{D}}(\phi,\theta)=0\) still implies (6), but is no longer equivalent. More specifically, in the case when \(D=D_{\text{KL}}\), the data processing inequality yields

\[D_{\text{KL}}(q^{\mu,\phi}(\mathbf{y}_{0:L})||p^{\nu,\theta}(\mathbf{y}_{0:L}))\geq D_{ \text{KL}}\left(q^{\phi}(\mathbf{z}|\mathbf{x})\mu(\mathbf{x})\big{|}p^{\theta}(\mathbf{x}| \mathbf{z})\nu(\mathbf{z})\right), \tag{11}\]

so that \(\mathcal{L}^{\text{ext}}_{D_{\text{KL}}}(\phi,\theta)\) provides an upper bound for \(\mathcal{L}_{D_{\text{KL}}}(\phi,\theta)\) as defined in (5).

### Diffusion models - hierarchical VAEs in the infinite depth limit

Here we take inspiration from Section 2.1 and Tzen and Raginsky (2019); Li et al. (2020); Huang et al. (2021) to investigate the \(L\to\infty\) limit, using stochastic differential equations (SDEs). To this end, we think of \(l=0,\ldots,L\) as discrete instances in a fixed time interval \([0,T]\), equidistant with time step \(\delta\), that is, we set \(\delta=TL^{-1}\). The discrete paths \(\mathbf{y}_{0:L}\) give rise to continuous paths \((\mathbf{Y}_{t})_{0\leq t\leq T}\in C([0,T];\mathbb{R}^{d})\) by setting \(\mathbf{Y}_{\delta l}=\mathbf{y}_{l}\) and linearly interpolating \(\mathbf{Y}_{\delta l}\) and \(\mathbf{Y}_{\delta(l+1)}\). To complete the set-up, we think of \(a^{\phi}=(a^{\phi}_{0},\ldots,a^{\phi}_{L-1})\) and \(b^{\theta}=(b^{\theta}_{1},\ldots,b^{\theta}_{L})\) in (8) as arising from time-dependent vector fields \(a,b\in C^{\infty}([0,T]\times\mathbb{R}^{d};\mathbb{R}^{d})\) via \(a^{\phi}_{l}(\mathbf{y}_{l})=a_{l\delta^{-1}}(\mathbf{Y}_{\delta l})\) and \(b^{\theta}_{l}(\mathbf{y}_{l})=b_{t\delta^{-1}}(\mathbf{Y}_{\delta l})\).

Taking the limit \(\delta\to 0\), while keeping \(T>0\) fixed, transforms the Markov chains in (9) into continuous-time dynamics described by the SDEs (Tzen and Raginsky, 2019)

\[\mathrm{d}\mathbf{Y}_{t}=a_{t}(\mathbf{Y}_{t})\,\mathrm{d}t+\sigma\overrightarrow{ \mathrm{d}}\mathbf{W}_{t},\quad\mathbf{Y}_{0}\sim\mu\implies(\mathbf{Y}_{t})_{0\leq t\leq T }\sim\mathbb{Q}^{\mu,a}\equiv\overrightarrow{\mathbb{P}}^{\mu,a}, \tag{12a}\]\[\mathrm{d}\mathbf{Y}_{t}=b_{t}(\mathbf{Y}_{t})\,\mathrm{d}t+\sigma\overleftarrow{\mathrm{d} }\mathbf{W}_{t},\quad\mathbf{Y}_{T}\sim\nu\implies(\mathbf{Y}_{t})_{0\leq t\leq T}\sim \mathbb{P}^{\nu,b}\equiv\overleftarrow{\mathbb{P}}^{\nu,b}, \tag{12b}\]

where \(\overrightarrow{\mathrm{d}}\) and \(\overleftarrow{\mathrm{d}}\) denote forward and backward Ito integration (see Appendix A for more details and remarks on the notation), and \((\mathbf{W}_{t})_{0\leq t\leq T}\) is a standard Brownian motion. In complete analogy with (9), the SDEs in (12) induce the distributions \(\mathbb{Q}^{\mu,a}\) and \(\mathbb{P}^{\nu,b}\) on the path space \(C([0,T];\mathbb{R}^{d})\). Relating back to the discussion in the introduction, note that we maintain the relations \(\mathbf{Y}_{0}=\mathbf{x}\) and \(\mathbf{Y}_{T}=\mathbf{z}\), and the transitions are parameterised by the vector fields \(a,b\), in the sense that \(p^{\theta}(\mathbf{x}|\mathbf{z})=\mathbb{P}_{0}^{\nu,b}(\mathbf{x}|\mathbf{Y}_{T}=\mathbf{z})= \mathbb{P}_{0}^{\delta_{\mathbf{x},b}\theta}(\mathbf{x})\) and \(q^{\phi}(\mathbf{z}|\mathbf{x})=\mathbb{Q}_{T}^{\mu,a^{\phi}}(\mathbf{z}|\mathbf{Y}_{0}=\mathbf{x })=\mathbb{Q}_{T}^{\delta_{\mathbf{x},a^{\phi}}}(\mathbf{z})\).

The following well-known result (Anderson, 1982; Nelson, 1967) allows us to relate forward and backward path measures via a local (score-matching) condition for the reversal relation in (4). 2

Footnote 2: The global condition \(\overrightarrow{\mathbb{P}}^{\mu,a}=\overleftarrow{\mathbb{P}}^{\nu,b}\) is captured by the local condition (13) due to (12)’s Markovian nature.

**Proposition 2.1** (Nelson's relation).: _For \(\mu\) and \(a\) of sufficient regularity, denote the time-marginals of the corresponding path measure by \(\overrightarrow{\mathbb{P}}_{t}^{\mu,a}=:\rho_{t}^{\mu,a}\). Then \(\overrightarrow{\mathbb{P}}^{\mu,a}=\overleftarrow{\mathbb{P}}^{\nu,b}\) if and only if_

\[\nu=\overrightarrow{\mathbb{P}}_{T}^{\mu,a}\qquad\text{and}\qquad b_{t}=a_{t} -\sigma^{2}\nabla\ln\rho_{t}^{\mu,a},\qquad\text{for all }t\in(0,T]. \tag{13}\]

**Remark 1**.: A similarly clean characterisation of equality between forward and backward path measures is not available for the discrete-time setting as presented in (9). In particular, Gaussianity of the intermediate transitions is not preserved under time-reversal.

A recurring theme in this work and related literature is the interplay between the score-matching condition in (13) and the global condition \(D(\overrightarrow{\mathbb{P}}^{\mu,a}|\overleftarrow{\mathbb{P}}^{\nu,b})=0\), invoking Framework 1. To enable calculations involving the latter, we will rely on the following result:

**Proposition 2.2** (forward-backward Radon-Nikodym derivatives).: _Let \(\overrightarrow{\mathbb{P}}^{\Gamma_{0},\gamma^{+}}=\overleftarrow{\mathbb{P }}^{\Gamma_{T},\gamma^{-}}\) be a reference path measure (that is, \(\Gamma_{0}\), \(\Gamma_{T}\) and \(\gamma^{\pm}\) define diffusions as in (12) and are related as in Proposition 2.1), absolutely continuous with respect to both \(\overrightarrow{\mathbb{P}}^{\mu,a}\) and \(\overrightarrow{\mathbb{P}}^{\nu,b}\). Then, \(\overrightarrow{\mathbb{P}}^{\mu,a}\)-almost surely, the corresponding Radon-Nikodym derivative (RND) can be expressed as follows,_

\[\ln\left(\frac{\mathrm{d}\overrightarrow{\mathbb{P}}^{\mu,a}}{ \mathrm{d}\overrightarrow{\mathbb{P}}^{\nu,b}}\right)(\mathbf{Y}) =\ln\left(\frac{\mathrm{d}\mu}{\mathrm{d}\Gamma_{0}}\right)(\mathbf{Y }_{0})-\ln\left(\frac{\mathrm{d}\nu}{\mathrm{d}\Gamma_{T}}\right)(\mathbf{Y}_{T}) \tag{14a}\] \[+\tfrac{1}{\sigma^{2}}\!\int_{0}^{T}\!\!\left(a_{t}-\gamma_{t}^{+ }\right)(\mathbf{Y}_{t})\!\cdot\!\left(\overrightarrow{\mathrm{d}}\mathbf{Y}_{t}- \tfrac{1}{2}\left(a_{t}+\gamma_{t}^{+}\right)(\mathbf{Y}_{t})\,\mathrm{d}t\right)\] (14b) \[-\tfrac{1}{\sigma^{2}}\!\int_{0}^{T}\!\!\left(b_{t}-\gamma_{t}^{- }\right)(\mathbf{Y}_{t})\!\cdot\!\left(\overleftarrow{\mathrm{d}}\mathbf{Y}_{t}- \tfrac{1}{2}\left(b_{t}+\gamma_{t}^{-}\right)(\mathbf{Y}_{t})\,\mathrm{d}t\right). \tag{14c}\]

Proof.: The proof relies on Girsanov's theorem (Ostunel & Zakai, 2013), using the reference to relate the forward and backward processes. For details, see Appendix E. 

**Remark 2** (Role of the reference process).: According to Proposition 2.2, the Radon-Nikodym derivative between \(\overrightarrow{\mathbb{P}}^{\mu,a}\) and \(\overleftarrow{\mathbb{P}}^{\nu,b}\) can be decomposed into boundary terms (14a), as well as forward and backward path integrals (14b) and (14c). Since the left-hand side of (14a) does not depend on the reference \(\Gamma_{0,T}\), \(\gamma^{\pm}\), the expressions in (14) are in principle equivalent for all choices of reference. The freedom in \(\Gamma_{0,T}\) and \(\gamma^{\pm}\) allows us to'reweight' between (14a), (14b) and (14c), or even cancel terms. A canonical choice is the Lebesgue measure for \(\Gamma_{0}\) and \(\Gamma_{T}\), and \(\gamma^{\pm}=0\), see Appendix C.1.

**Remark 3** (Discretisation and conversion formulae).: The distinction between forward and backward integration in (14) is related to the time points at which the integrands \(\left(a_{t}-\gamma_{t}^{+}\right)(\mathbf{Y}_{t})\) and \(\left(b_{t}-\gamma_{t}^{-}\right)(\mathbf{Y}_{t})\) would be evaluated in discrete-time approximations, e.g.,

\[\int_{0}^{T}\!\!a_{t}(\mathbf{Y}_{t})\!\cdot\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!Framework 1 can be translated into the setting of (12), noting that (11) continues to hold with appropriate modifications:

**Framework 1\({}^{\prime}\).** For a divergence \(D\) on path space, minimise \(D(\overrightarrow{\mathbb{P}}^{\mu,a}\big{|}\overleftarrow{\mathbb{P}}^{\nu,b})\). If \(D(\overrightarrow{\mathbb{P}}^{\mu,a}\big{|}\overleftarrow{\mathbb{P}}^{\nu,b })=0\), then (12a) transports \(\mu\) to \(\nu\), and (12b) transports \(\nu\) to \(\mu\).

At optimality, \(D(\overrightarrow{\mathbb{P}}^{\mu,a}\big{|}\overleftarrow{\mathbb{P}}^{\nu,b })=0\), Proposition 2.1 allows us to obtain the scores associated to the learned diffusion via \(\sigma^{2}\nabla\ln\rho_{t}^{\mu,a}=a_{t}-b_{t}\). In this way, Framework 1\({}^{\prime}\) is closely connected to (and in some ways extends) score-matching ideas (Song and Ermon, 2019; Song et al., 2021). Indeed, recent approaches towards generative modeling and sampling can be recovered from Framework 1\({}^{\prime}\) by making specific choices for the divergence \(D\), the parameterisations for \(a\) and \(b\), as well as for the reference diffusion \(\overrightarrow{\mathbb{P}}^{\Gamma_{0},\gamma^{+}}=\overleftarrow{\mathbb{P} }^{\Gamma_{T},\gamma^{-}}\) in Proposition 2.2:

**Score-based generative modeling:** Letting \(\mu\) be the target and fixing the forward drift \(a_{t}\), and, motivated by Proposition 2.1, parameterising the backward drift as \(b_{t}=a_{t}-s_{t}\), we recover the SGM objectives in Hyvarinen and Dayan (2005); Song and Ermon (2019); Song et al. (2021) from \(D=D_{\rm KL}\); when \(\overrightarrow{\mathbb{P}}^{\mu,a}=\overleftarrow{\mathbb{P}}^{\nu,b}\), the variable drift component \(s_{t}\) will represent the score \(\sigma^{2}\nabla\ln\rho_{t}^{\mu,a}\). Modifications can be obtained from the conversion formula (15), see Appendix C.2.

**Score-based sampling - ergodic drift:** In this setting, \(\nu\) becomes the target and we fix \(b_{t}\) to be the drift of an ergodic (backward) process. Then choosing \(\Gamma_{0,T}=\mu\), \(\gamma^{\pm}=b\) allows us to recover the approaches in Vargas et al. (2023a); Berner et al. (2022). Possible generalisations based on Framework 1\({}^{\prime}\) include IWAE-type objectives, see Appendix C.3.

**Score-based sampling - Follmer drift:** Finally choosing \(b_{t}(x)=x/t\) we recover Follmer sampling (Appendix C.3; Follmer, 1984; Vargas et al., 2023b; Zhang and Chen, 2022; Huang et al., 2021b).

## 3 Learning forward and backward transitions simultaneously

Recall from the introduction that complete flexibility in \(a\) and \(b\) will render the minima of \(D(\overrightarrow{\mathbb{P}}^{\mu,a}\big{|}\overleftarrow{\mathbb{P}}^{\nu,b})\) highly nonunique. Furthermore, the approaches surveyed at the end of the previous section circumvent this problem by fixing either \(\overrightarrow{\mathbb{P}}^{\mu,a}\) or \(\overleftarrow{\mathbb{P}}^{\nu,b}\). However, to leverage the full power of diffusion models, both \(\overrightarrow{\mathbb{P}}^{\mu,a}\) or \(\overleftarrow{\mathbb{P}}^{\nu,b}\) should be adapted to the problem at hand. In this section, we explore models of this kind, by imposing additional constraints on \(a\) and \(b\). We end this section by presenting our new CMCD sampler connecting it to prior methodology within VI (Doucet et al., 2022b; Geffner and Domke, 2023; Papamakarios et al., 2017) and OT where we can view CMCD as an instance of entropy regularised OT in the infinite constraint limit (Bernton et al., 2019).

### Connection to Entropic optimal transport

One way of selecting a particular transition between \(\mu\) and \(\nu\) is by imposing an entropic penalty, encouraging the dynamics to stay close to a prescribed, oftentimes physically or biologically motivated, reference process. Using the notation employed in Framework 1, the _static_ Schrodinger problem (Schrodinger, 1931; Leonard, 2014a) is given by

\[\pi^{*}(\mathbf{x},\mathbf{z})\in\operatorname*{arg\,min}_{\pi(\mathbf{x},\mathbf{z})}\Big{\{} D_{\rm KL}(\pi(\mathbf{x},\mathbf{z})||r(\mathbf{x},\mathbf{z})):\pi_{\mathbf{x}}(\mathbf{x})=\mu( \mathbf{x}),\pi_{\mathbf{z}}(\mathbf{z})=\nu(\mathbf{z})\Big{\}}, \tag{16}\]

where \(r(\mathbf{x},\mathbf{z})\) is the Schrodinger prior encoding additional domain-specific information. In an analogous way, we can introduce a regulariser to the path-space approach of Framework 1\({}^{\prime}\) to obtain the dynamic Schrodinger problem

\[\mathbb{P}^{*}\!\!\in\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!Iterative proportional fitting (IPF) and the EM algorithm.It is well known that approximate solutions for \(\pi^{*}(\mathbf{x},\mathbf{z})\) and \(\mathbb{P}^{*}\) can be obtained using alternating \(D_{\mathrm{KL}}\)-projections, keeping one of the marginals fixed in each iteration: Under mild conditions, the sequence defined by

\[\pi^{2n+1}(\mathbf{x},\mathbf{z}) =\operatorname*{arg\,min}_{\pi(\mathbf{x},\mathbf{z})}\left\{D_{\mathrm{ KL}}(\pi(\mathbf{x},\mathbf{z})||\pi^{2n}(\mathbf{x},\mathbf{z})):\ \pi_{\mathbf{x}}(\mathbf{x})=\mu(\mathbf{x}) \right\}, \tag{18a}\] \[\pi^{2n+2}(\mathbf{x},\mathbf{z}) =\operatorname*{arg\,min}_{\pi(\mathbf{x},\mathbf{z})}\left\{D_{\mathrm{ KL}}(\pi(\mathbf{x},\mathbf{z})||\pi^{2n+1}(\mathbf{x},\mathbf{z})):\ \pi_{\mathbf{z}}(\mathbf{z})=\nu( \mathbf{z})\right\},\qquad n\geq 0, \tag{18b}\]

with initialisation \(\pi^{0}(\mathbf{x},\mathbf{z})=r(\mathbf{x},\mathbf{z})\), converges to \(\pi^{*}(\mathbf{x},\mathbf{z})\) as \(n\to\infty\)(De Bortoli et al., 2021), and this procedure is commonly referred to as iterative proportional fitting (IPF) (Fortet, 1940; Kullback, 1968; Ruschendorf, 1995) of Sinkhorn updates (Cuturi, 2013). IPF can straightforwardly be modified to the path space setting of (17), and the resulting updates coincide with the Follmer drift updates discussed in Section C.3, see (Vargas et al., 2021a) and Appendix E.4.

To further demonstrate the coverage of our framework, we establish a connection between IPF and expectation-maximisation (EM) (Dempster et al., 1977), originally devised for finding maximum likelihood estimates in models with latent (or hidden) variables. According to Neal & Hinton (1998), the EM-algorithm can be described in the setting from the introduction, and written in the form

\[\theta_{n+1}=\operatorname*{arg\,min}_{\theta}\mathcal{L}_{D_{\mathrm{KL}}}( \phi_{n},\theta),\qquad\phi_{n+1}=\operatorname*{arg\,min}_{\phi}\mathcal{L}_{ D_{\mathrm{KL}}}(\phi,\theta_{n+1}), \tag{19}\]

with \(\mathcal{L}_{D_{\mathrm{KL}}}\) defined as in (5). If the initialisations are matched appropriately, the following result establishes an exact correspondence between the IPF updates in (18) and the EM updates in (19):

**Proposition 3.1** (\(\text{EM}\iff\text{IPF}\)).: _Assume that the transition densities \(p^{\theta}(\mathbf{x}|\mathbf{z})\) and \(q^{\phi}(\mathbf{z}|\mathbf{x})\) are parameterised with perfect flexibility,3 and furthermore that the EM-scheme (19) is initialised at \(\phi_{0}\) in such a way that \(q^{\phi_{0}}(\mathbf{z}|\mathbf{x})=r(\mathbf{z}|\mathbf{x})\). Then the IPF iterations in (18) agree with the EM iterations in (19) for all \(n\geq 1\), in the sense that_

Footnote 3: In precise terms, we assume that for any transition densities \(p(\mathbf{x}|\mathbf{z})\) and \(q(\mathbf{z}|\mathbf{x})\), there exist \(\theta_{*}\) and \(\phi_{*}\) such that \(p(\mathbf{x}|\mathbf{z})=p^{\theta_{*}}(\mathbf{x}|\mathbf{z})\) and \(q(\mathbf{x}|\mathbf{z})=q^{\phi_{*}}(\mathbf{x}|\mathbf{z})\).

\[\pi^{n}(\mathbf{x},\mathbf{z})=q^{\phi_{(n-1)/2}}(\mathbf{z}|\mathbf{x})\mu(\mathbf{x}),\quad\text {for $n$ odd},\quad\pi^{n}(\mathbf{x},\mathbf{z})=p^{\theta_{n/2}}(\mathbf{x}|\mathbf{z})\nu(\mathbf{z }),\quad\text{for $n$ even}. \tag{20}\]

From the proof (Appenix E), it is clear that flexibility of parameterisations is crucial, and thus \(\text{EM}\iff\text{IPF}\) fails for classical VAEs, but holds up to a negligle error for the SDE-parameterisations from Section 2.2, see also Liu et al. (b). Under this assumption, the key observation is that replacing forward-\(D_{\mathrm{KL}}\) by reverse-\(D_{\mathrm{KL}}\) in one or both of (18a) and (18b) does not - in theory - change the sequence of minimisers.

In practice favoring the EM objectives over IPF can offer an advantage as optimizing with respect to forward-\(D_{\mathrm{KL}}\) and backward-\(D_{\mathrm{KL}}\) encourages moment-matching and mode-seeking behavior, respectively, and so an alternating scheme as defined in (19) might present a suitable compromise over optimizing a single direction of \(D_{\mathrm{KL}}\)'s, empirical exploration is left for future work.

Whilst EM and IPF might seem appealing for learning a sampler they both require sequentially solving a series of minimization problems, which we can only solve approximately; this is not only slow but also causes a sequential accumulation of errors arising from each iterate (Vargas et al., 2021a; Fernandes et al., 2021). In order to address both issues we will present a novel approach (CMCD) that similarly to IPF learns both the forward and backward processes whilst preserving the desired uniqueness property. However, in contrast to IPF it does so in an end-to-end fashion and performs updates simultaneously. As an alternative in Appendix E.5 we also discuss a regularised IPF objective and leave further empirical exploration for future work.

### Score-based annealing: the Controlled Monte Carlo Diffusion sampler

In this section, we fix a prescribed curve of distributions \((\pi_{t})_{t\in[0,T]}\), whose scores \(\nabla\ln\pi_{t}\) (and unnormalised densities \(\widehat{\pi}_{t}\)) are assumed to be available in tractable form; this is the scenario typically encountered in annealed importance sampling (IS) and related approaches towards computing posterior expectations (Neal, 2001; Reich, 2011; Heng et al., 2021, 2020; Arbel et al., 2021; Doucet et al., 2022a). The _Controlled Monte Carlo Diffusion sampler_ (CMCD) learns the vector field \(\nabla\phi_{t}\) in

\[\mathrm{d}\mathbf{Y}_{t}\!=\!\big{(}\sigma^{2}\nabla\ln\pi_{t}(\mathbf{Y}_{t})\!+\! \nabla\phi_{t}(\mathbf{Y}_{t})\big{)}\,\mathrm{d}t+\sigma\!\sqrt{2}\overset{\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!so that (21) produces the interpolation from the prior \(\pi_{0}\) to the posterior \(\pi_{T}\), i.e., \(\overrightarrow{\mathbb{P}}_{t_{0},\sigma^{2}\nabla\ln\pi+\nabla\phi}=\pi_{t}\), for all \(t\in[0,T]\). Note that if \(\pi_{t}\) were constant in time (\(\pi_{t}=\pi_{0}\)), then \(\phi=0\) would reduce (21) to equilibrium overdamped Langevin dynamics, preserving \(\pi_{0}\). With \(\pi_{t}\) varying in time, \(\nabla\phi_{t}\) can be thought of as a control enabling transitions between neighbouring densities \(\pi_{t}\) and \(\pi_{t+\delta t}\).

To obtain \(\nabla\phi_{t}\) we invoke Framework 1\({}^{\prime}\), but restrict \(\overleftarrow{\mathbb{P}}^{\pi_{T},b}\) to retain uniqueness. Proposition 2.1 motivates the choice \(b_{t}=(\sigma^{2}\nabla\ln\pi_{t}+\nabla\phi_{t})-2\sigma^{2}\nabla\ln\pi_{t}= -\sigma^{2}\nabla\ln\pi_{t}+\nabla\phi_{t}\),4 leading to

Footnote 4: Note the additional factor of 2 in Nelson’s relation due to the noise scaling \(\sigma\sqrt{2}\operatorname{d}\overleftarrow{\mathbb{P}}_{t}\) in (21).

\[\mathcal{L}_{D}^{\text{CMCD}}(\phi):=D\left(\overrightarrow{\mathbb{P}}_{\pi_{ 0},\sigma^{2}\nabla\ln\pi+\nabla\phi},\overleftarrow{\mathbb{P}}_{\pi_{T},- \sigma^{2}\nabla\ln\pi+\nabla\phi}\right), \tag{22}\]

which is valid for any choice of divergence \(D\). The additional score constraint \(b_{t}=a_{t}-2\sigma^{2}\nabla\ln\pi_{t}\) restores uniqueness in Framework 1\({}^{\prime}\) (see Appendix D for a proof):

**Proposition 3.2** (Existence and uniqueness).: _Under mild conditions on \((\pi_{t})_{t\in[0,T]}\), (22) admits a (\(\pi_{t}\)-a.e.) unique minimiser \(\phi^{*}\), up to additive constants, satisfying \(\mathcal{L}_{\text{CMCD}}(\phi^{*})=0\)._

Given the optimal vector field \(\nabla\phi^{*}_{t}\), we can produce samples from \(\pi_{T}\) by simulating (21). Following Zhang and Chen (2022); Vargas et al. (2023a),we can estimate \(Z\) in \(\pi_{T}=\hat{\pi}_{T}/Z_{T}\) unbiasedly via

\[Z=\mathbb{E}\left[\frac{\operatorname{d}\overleftarrow{\mathbb{P}}_{\pi_{T},- \sigma^{2}\nabla\ln\pi+\nabla\phi}}{\operatorname{d}\overrightarrow{\mathbb{P }}_{\pi_{0},\sigma^{2}\nabla\ln\pi+\nabla\phi}}\right]=\frac{\operatorname{d} \overrightarrow{\mathbb{P}}_{\pi_{T},-\sigma^{2}\nabla\ln\pi+\nabla\phi^{*}}}{ \operatorname{d}\overrightarrow{\mathbb{P}}_{\pi_{0},\sigma^{2}\nabla\ln\pi+ \nabla\phi^{*}}}(\mathbf{Y}), \tag{23}\]

where the expectation is taken with respect to (21), and is valid for any (possibly suboptimal) \(\nabla\phi_{t}\). The right-hand side, on the other hand, shows that optimality of \(\nabla\phi^{*}_{t}\) yields a zero-variance estimator of \(Z\), as the statement holds almost surely in \(\mathbf{Y}\), without taking the expectation. To give a broader perspective, we give the following slight generalisation of a well-known result from statistical physics:

**Proposition 3.3** (Controlled Crooks' fluctuation theorem and Jarzynski's equality).: _Following Jarzynski (1997); Chen et al. (2019), define work and free energy as \(\mathcal{W}_{T}(\mathbf{Y}):=-\int_{0}^{T}\sigma^{2}\partial_{t}\ln\hat{\pi}_{t}( \mathbf{Y}_{t})\operatorname{d}\!t\), \(\mathcal{F}_{t}:=-\sigma^{2}\ln Z_{t}:=\sigma^{2}\ln(\hat{\pi}_{t}/\pi_{t})\). Then, we have the controlled Crooks' identity,_

\[\left(\frac{\operatorname{d}\overrightarrow{\mathbb{P}}_{\pi_{0},\sigma^{2} \nabla\ln\pi+\nabla\phi}}{\operatorname{d}\overrightarrow{\mathbb{P}}_{\pi_{T},-\sigma^{2}\nabla\ln\pi+\nabla\phi}}\right)(\mathbf{Y})=\exp\left(-\frac{1}{ \sigma^{2}}(\mathcal{F}_{T}-\mathcal{F}_{0})+\frac{1}{\sigma^{2}}\mathcal{W}_ {T}(\mathbf{Y})+\mathcal{C}_{T}^{\phi}(\mathbf{Y})\right),\]

_where \(\mathcal{C}_{T}^{\phi}(\mathbf{Y}):=-\frac{1}{\sigma^{2}}\!\int_{0}^{T}\nabla\phi_{ t}(\mathbf{Y}_{t})\cdot\nabla\ln\pi_{t}(\mathbf{Y}_{t})\operatorname{d}\!t-\int_{0}^{T} \Delta\phi_{t}(\mathbf{Y}_{t})\operatorname{d}\!t\). By taking expectations and \(\phi=0\), this implies Jarzynski's equality \(\mathbb{E}_{\overrightarrow{\mathbb{P}}_{\pi_{0},\sigma^{2}\nabla\ln\pi+\nabla \phi}}[-\frac{1}{\sigma^{2}}\mathcal{W}_{T}]=Z_{T}/Z_{0}\)._

The proof uses Proposition 2.2 to compute the \(\operatorname{RND}\overrightarrow{\mathbb{P}}_{\pi_{0},\sigma^{2}\nabla\ln\pi+ \nabla\phi}/\overleftarrow{\mathbb{P}}_{\pi_{T},-\sigma^{2}\nabla\ln\pi+ \nabla\phi}\), followed by applying Ito's formula to \(t\to\ln\hat{\pi}_{t}(\mathbf{Y}_{t})\), see Appendix E.2. For \(\phi=0\), we recover Crooks fluctuation theorem (Crooks, 1999), but the additional control allows CMCD to suppress said fluctuations by adjusting the interaction term \(\mathcal{C}_{T}^{\phi}(\mathbf{Y})\). Indeed, prior works (Neal, 2001; Chopin, 2002; Vaikuntanathan and Jarzynski, 2008; Hartmann et al., 2019; Zhang, 2021) have used the Jarzynski equality to estimate \(Z\) via importance sampling, but this approach might suffer from high variance, see (Del Moral et al., 2006), (Stoltz et al., 2010, Section 4.1.4). In contrast, the CMCD estimator version of (23) achieves zero variance if trained to optimality (see Appendix E.1.1 for a convenient discretised version).

Our next result (proof in Appendix D.4) connects CMCD to Section 3.1, showing that minimising (22) can be viewed as jointly solving an infinite number of Schrodinger problems on infinitesimal time intervals:

**Proposition 3.4** (infinitesimal Schrodinger problems).: _The minimiser \(\phi^{*}\) can be characterised as follows: For \(N\in\mathbb{N}\), partition the interval \([0,T]\) into \(N\) subintervals of length \(T/N\), and on each subinterval \([(i-1)T/N,iT/N]\), solve the Schrodinger problem (17) with marginals \(\mu=\pi_{(i-1)T/N}\), \(\nu=\pi_{iT/N}\) and prior drift \(f_{t}=\nabla\ln\pi_{t}\). Concatenate the solutions to obtain the drift \(\nabla\phi^{(N)}\), defined on \([0,T]\). Then, \(\nabla\phi^{(N)}\to\nabla\phi\) as \(N\to\infty\) in the sense of \(L^{2}([0,T]\times\mathbb{R}^{d},\pi)\)._

Note the similarity of this interpretation to the sequential Schrodinger samplers of Bernton et al. (2019, Section 3). Making specific choices for \(D\) in 22, we can establish further connections to other methods:

1. For \(D=D_{\text{KL}}\), direct computation (see Appendix D.1) based on Proposition 2.2 shows that

\[\mathcal{L}^{\text{CMCD}}_{D_{\text{KL}}}(\phi) =\mathbb{E}_{\mathbf{Y}_{\sim}\overrightarrow{\pi}_{0},\sigma^{2} \otimes\ln+\nu\phi}\left[\ln\left(\frac{\mathrm{d}\overrightarrow{\mathbb{P}} \pi_{0},\sigma^{2}\nabla\ln\pi+\nabla\phi}{\mathrm{d}\overrightarrow{\mathbb{P }}\pi_{T},-\sigma^{2}\nabla\ln\pi+\nabla\phi}\right)(\mathbf{Y})\right]\] \[=\mathbb{E}\Bigg{[}\sigma^{2}\!\!\int_{0}^{T}\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!(ULA) (Wu et al., 2020; Thin et al., 2021) and Monte Carlo Diffusion (MCD) (Doucet et al., 2022b); and two overdamped baselines, Uncorrected Hamiltonian Annealing (UHA) (Geffner and Domke, 2021; Zhang et al., 2021) and Langevin Diffusion Variational Inference (LDVI) (Geffner and Domke, 2023). Furthermore, we include comparisons of \(\ln Z\) estimation on two datasets with known partition function, the funnel and gmmm, and compare against baselines from Vargas et al. (2023a), PIS (Barr et al., 2020; Vargas et al., 2023b; Zhang and Chen, 2022), DDS (Vargas et al., 2023a), and Sequential Monte Carlo Sampler (SMC) (Del Moral et al., 2006; Zhou et al., 2016).

We report the mean ELBO achieved by each method over 30 seeds of sampling, for Euler discretisation steps \(K\in\{8,16,32,64,128,256\}\), comparing the underdamped and overdamped baselines to their respective CMCD counterparts in Figure 1. We see that both overdamped and underdamped CMCD consistently outperform all baseline methods, especially at low \(K\), and in fact, across most targets overdamped CMCD outperforms the underdamped baselines. Figure 1 also reports \(\ln Z\) for two target distributions with known \(Z\), comparing against PIS, DDS, and SMC. Again, CMCD recovers the log-partition more consistently, even at low \(K\). Finally, as another measure of sample quality, we report the entropy-regularised OT distance (\(\mathcal{W}_{2}^{\gamma}\)) between obtained samples and samples from the target for funnel and gmm. Hyperparameter tuning and other experimental details can be found in Appendix F.We also provide an anonymised code release5

Footnote 5: [https://anonymous.4open.science/r/CMCD-6BF6/](https://anonymous.4open.science/r/CMCD-6BF6/)

## 5 Discussion

Overall we have successfully introduced a novel variational framework bridging VI and transport using modern advances in diffusion models and processes. In particular, we have shown that many existing diffusion-based methods for generative modelling and sampling can be viewed as special instances of our proposed framework. Building on this, we have developed novel objectives for dynamic entropy regularised transports (based on a relationship between the EM and IPF algorithms) and annealed flows (with connections to fluctuation theorems due to Crook and Jarzynski, rooted in statistical physics). Finally, we have explored the CMCD inference scheme obtaining state-of-the-art results across a suite of challenging inference benchmarks. We believe this experimental success is partly due to our approach striking a balance between parametrising a flexible family of distributions whilst being constrained enough such that learning the sampler is not overly expensive (Tzen and Raginsky, 2019; Vargas et al., 2023c). Future directions can explore optimal schemes for the annealed flow \(\pi_{t}\)(Goshtasbpour et al., 2023) and alternate divergences (Nusken and Richter, 2021; Midgley et al., 2022).

Figure 1: Figure panes a) and b) report ELBOs across methods and targets following the experimental setup in Geffner and Domke (2023), the (OD) and (UD) columns group over and under-damped methods seperately. Figure c) reports IS \(\ln Z\) estimates and sample quality (where available) using eOT. Higher ELBO and \(\ln Z\) denote better estimates, lower \(\mathcal{W}_{2}^{\gamma}\) signifies better sample quality.

## References

* Albergo et al. (2023) Michael S Albergo, Nicholas M Boffi, and Eric Vanden-Eijnden. Stochastic interpolants: A unifying framework for flows and diffusions. _arXiv preprint arXiv:2303.08797_, 2023.
* Anderson (1982) Brian D.O. Anderson. Reverse-time diffusion equation models. _Stochastic Processes and their Applications_, 12(3):313-326, 1982.
* Arbel et al. (2021) Michael Arbel, Alex Matthews, and Arnaud Doucet. Annealed flow transport Monte Carlo. In _International Conference on Machine Learning_, pp. 318-330. PMLR, 2021.
* Bakry et al. (2014) Dominique Bakry, Ivan Gentil, Michel Ledoux, et al. _Analysis and geometry of Markov diffusion operators_, volume 103. Springer, 2014.
* Barr et al. (2020) Ariel Barr, Willem Gispen, and Austen Lamacraft. Quantum ground states from reinforcement learning. In _Mathematical and Scientific Machine Learning_, pp. 635-653. PMLR, 2020.
* Baudoin (2002) Fabrice Baudoin. Conditioned stochastic differential equations: theory, examples and application to finance. _Stochastic Processes and their Applications_, 100(1-2):109-145, 2002.
* Bengio et al. (2021) Yoshua Bengio, Salem Lahlou, Tristan Deleu, Edward J Hu, Mo Tiwari, and Emmanuel Bengio. GflowNet foundations. _arXiv preprint arXiv:2111.09266_, 2021.
* Berner et al. (2022) Julius Berner, Lorenz Richter, and Karen Ullrich. An optimal control perspective on diffusion-based generative modeling. In _NeurIPS 2022 Workshop on Score-Based Methods_, 2022.
* Bernton et al. (2019) Espen Bernton, Jeremy Heng, Arnaud Doucet, and Pierre E Jacob. Schrodinger bridge samplers. _arXiv preprint_, 2019.
* Billingsley (2013) Patrick Billingsley. _Convergence of probability measures_. John Wiley & Sons, 2013.
* Blei et al. (2017) David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: A review for statisticians. _Journal of the American statistical Association_, 112(518):859-877, 2017.
* Burda et al. (2015) Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. _arXiv preprint arXiv:1509.00519_, 2015.
* Chen et al. (2022) Tianrong Chen, Guan-Horng Liu, and Evangelos Theodorou. Likelihood training of Schrodinger bridge using forward-backward SDEs theory. In _International Conference on Learning Representations_, 2022. URL [https://openreview.net/forum?id=nioAdKCEdXB](https://openreview.net/forum?id=nioAdKCEdXB).
* Chen et al. (2016) Yongxin Chen, Tryphon T Georgiou, and Michele Pavon. On the relation between optimal transport and Schrodinger bridges: A stochastic control viewpoint. _Journal of Optimization Theory and Applications_, 169(2):671-691, 2016.
* Chen et al. (2019) Yongxin Chen, Tryphon T Georgiou, and Allen Tannenbaum. Stochastic control and nonequilibrium thermodynamics: Fundamental limits. _IEEE transactions on automatic control_, 65(7):2979-2991, 2019.
* Chen et al. (2021) Yongxin Chen, Tryphon T Georgiou, and Michele Pavon. Stochastic control liaisons: Richard sinkhorn meets gaspard monge on a schrodinger bridge. _Siam Review_, 63(2):249-313, 2021.
* Chopin (2002) Nicolas Chopin. A sequential particle filter method for static models. _Biometrika_, 89(3):539-552, 2002.
* Clark (1991) JMC Clark. A local characterization of reciprocal diffusions. _Applied Stochastic Analysis_, 5:45-59, 1991.
* Crooks (1999) Gavin E Crooks. Entropy production fluctuation theorem and the nonequilibrium work relation for free energy differences. _Physical Review E_, 60(3):2721, 1999.
* Cuturi (2013) Marco Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. In _Advances in Neural Information Processing Systems_, 2013.
* Dai Pra (1991) Paolo Dai Pra. A stochastic control approach to reciprocal diffusion processes. _Applied mathematics and Optimization_, 23(1):313-329, 1991.

* Daudel et al. (2022) Kamelia Daudel, Joe Benton, Yuyang Shi, and Arnaud Doucet. Alpha-divergence variational inference meets importance weighted auto-encoders: Methodology and asymptotics. _arXiv preprint arXiv:2210.06226_, 2022.
* De Bortoli et al. (2021) Valentin De Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet. Diffusion Schrodinger bridge with applications to score-based generative modeling. _Advances in Neural Information Processing Systems_, 34:17695-17709, 2021.
* Doral et al. (2006) Pierre Del Moral, Arnaud Doucet, and Ajay Jasra. Sequential Monte Carlo samplers. _Journal of the Royal Statistical Society: Series B (Statistical Methodology)_, 68(3):411-436, 2006.
* Dempster et al. (1977) Arthur P Dempster, Nan M Laird, and Donald B Rubin. Maximum likelihood from incomplete data via the EM algorithm. _Journal of the royal statistical society: series B (methodological)_, 39(1):1-22, 1977.
* Doucet et al. (2022) Arnaud Doucet, Will Grathwohl, Alexander G Matthews, and Heiko Strathmann. Score-based diffusion meets annealed importance sampling. _Advances in Neural Information Processing Systems_, 35:21482-21494, 2022a.
* Doucet et al. (2022b) Arnaud Doucet, Will Sussman Grathwohl, Alexander G de G Matthews, and Heiko Strathmann. Annealed importance sampling meets score matching. In _ICLR Workshop on Deep Generative Models for Highly Structured Data_, 2022b.
* Dupuis and Ellis (2011) Paul Dupuis and Richard S Ellis. _A weak convergence approach to the theory of large deviations_. John Wiley & Sons, 2011.
* El Moselhy and Marzouk (2012) Tarek A El Moselhy and Youssef M Marzouk. Bayesian inference with optimal maps. _Journal of Computational Physics_, 231(23):7815-7850, 2012.
* Fernandes et al. (2021) David Lopes Fernandes, Francisco Vargas, Carl Henrik Ek, and Neill DF Campbell. Shooting Schrodinger's cat. In _Fourth Symposium on Advances in Approximate Bayesian Inference_, 2021.
* Figalli and Glaudo (2021) Alessio Figalli and Federico Glaudo. _An invitation to optimal transport, Wasserstein distances, and gradient flows_. 2021.
* Follmer (1984) H. Follmer. An entropy approach to the time reversal of diffusion processes. _Lecture Notes in Control and Information Sciences_, 69:156-163, 1984.
* Follmer (2006a) Hans Follmer. Calcul d'Ito sans probabilites. In _Seminaire de Probabilites XV 1979/80: Avec table generale des exposes de 1966/67 a 1978/79_, pp. 143-150. Springer, 2006a.
* Follmer (2006b) Hans Follmer. Time reversal on Wiener space. In _Stochastic Processes--Mathematics and Physics: Proceedings of the 1st BiBoS-Symposium held in Bielefeld, West Germany, September 10-15, 1984_, pp. 119-129. Springer, 2006b.
* Follmer and Protter (2000) Hans Follmer and Philip Protter. On Ito's formula for multidimensional Brownian motion. _Probability Theory and Related Fields_, 116:1-20, 2000.
* Fortet (1940) Robert Fortet. Resolution d'un systeme d'equations de M. Schrodinger. _J. Math. Pure Appl. IX_, 1:83-105, 1940.
* Friz and Hairer (2020) Peter K Friz and Martin Hairer. _A course on rough paths_. Springer, 2020.
* Geffner and Domke (2021) Tomas Geffner and Justin Domke. Mcmc variational inference via uncorrected hamiltonian annealing. _Advances in Neural Information Processing Systems_, 34:639-651, 2021.
* Geffner and Domke (2023) Tomas Geffner and Justin Domke. Langevin diffusion variational inference. In _International Conference on Artificial Intelligence and Statistics_, pp. 576-593. PMLR, 2023.
* Goshtasbpour et al. (2023) Shirin Goshtasbpour, Victor Cohen, and Fernando Perez-Cruz. Adaptive annealed importance sampling with constant rate progress. 2023.
* Grathwohl et al. (2019) Will Grathwohl, Ricky T. Q. Chen, Jesse Bettencourt, and David Duvenaud. Scalable reversible generative models with free-form continuous dynamics. In _International Conference on Learning Representations_, 2019. URL [https://openreview.net/forum?id=rJxgknCcK7](https://openreview.net/forum?id=rJxgknCcK7).

* Gushchin et al. (2022) Nikita Gushchin, Alexander Kolesov, Alexander Korotin, Dmitry Vetrov, and Evgeny Burnaev. Entropic neural optimal transport via diffusion processes. _arXiv preprint arXiv:2211.01156_, 2022.
* Hartmann et al. (2013) Carsten Hartmann, Ralf Banisch, Marco Sarich, Tomasz Badowski, and Christof Schutte. Characterization of rare events in molecular dynamics. _Entropy_, 16(1):350-376, 2013.
* Hartmann et al. (2019) Carsten Hartmann, Christof Schutte, and Wei Zhang. Jarzynski's equality, fluctuation theorems, and variance reduction: Mathematical analysis and numerical algorithms. _Journal of Statistical Physics_, 175:1214-1261, 2019.
* Haussmann & Pardoux (1985) UG Haussmann and E Pardoux. Time reversal of diffusion processes. In _Stochastic Differential Systems Filtering and Control_, pp. 176-182. Springer, 1985.
* Heng et al. (2020) Jeremy Heng, Adrian Bishop, George Deligiannidis, and Arnaud Doucet. Controlled sequential Monte Carlo. _Annals of Statistics_, 48(5), 2020.
* Heng et al. (2021) Jeremy Heng, Arnaud Doucet, and Yvo Pokern. Gibbs flow for approximate transport with applications to Bayesian computation. _Journal of the Royal Statistical Society Series B: Statistical Methodology_, 83(1):156-187, 2021.
* Hernandez-Lobato et al. (2016) Jose Hernandez-Lobato, Yingzhen Li, Mark Rowland, Thang Bui, Daniel Hernandez-Lobato, and Richard Turner. Black-box alpha divergence minimization. In _International conference on machine learning_, pp. 1511-1520. PMLR, 2016.
* Ho et al. (2020) Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. _Advances in Neural Information Processing Systems_, 33:6840-6851, 2020.
* Huang et al. (2021a) Chin-Wei Huang, Jae Hyun Lim, and Aaron C Courville. A variational perspective on diffusion-based generative models and score matching. _Advances in Neural Information Processing Systems_, 34:22863-22876, 2021a.
* Huang et al. (2021b) Jian Huang, Yuling Jiao, Lican Kang, Xu Liao, Jin Liu, and Yanyan Liu. Schrodinger-Follmer sampler: Sampling without ergodicity. _arXiv preprint arXiv:2106.10880_, 2021b.
* Hutchinson (1989) Michael F Hutchinson. A stochastic estimator of the trace of the influence matrix for Laplacian smoothing splines. _Communications in Statistics-Simulation and Computation_, 18(3):1059-1076, 1989.
* Hyvarinen & Dayan (2005) Aapo Hyvarinen and Peter Dayan. Estimation of non-normalized statistical models by score matching. _Journal of Machine Learning Research_, 6(4), 2005.
* Jarzynski (1997) Christopher Jarzynski. Nonequilibrium equality for free energy differences. _Physical Review Letters_, 78(14):2690, 1997.
* Karatzas et al. (1991) Ioannis Karatzas, Ioannis Karatzas, Steven Shreve, and Steven E Shreve. _Brownian motion and stochastic calculus_, volume 113. Springer Science & Business Media, 1991.
* Kingma et al. (2021) Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational diffusion models. _Advances in neural information processing systems_, 34:21696-21707, 2021.
* Kingma & Ba (2015) Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. _ICLR 2015_, 2015.
* Kingma & Welling (2014) Diederik P Kingma and Max Welling. Auto-encoding variational Bayes. _ICLR_, 2014.
* Kingma et al. (2019) Diederik P Kingma, Max Welling, et al. An introduction to variational autoencoders. _Foundations and Trends(r) in Machine Learning_, 12(4):307-392, 2019.
* Kloeden et al. (1992) Peter E Kloeden, Eckhard Platen, Peter E Kloeden, and Eckhard Platen. _Stochastic differential equations_. Springer, 1992.
* Koshizuka & Sato (2023) Takeshi Koshizuka and Issei Sato. Neural Lagrangian Schrodinger bridge: Diffusion modeling for population dynamics. In _The Eleventh International Conference on Learning Representations_, 2023. URL [https://openreview.net/forum?id=d3QNWD_pcFv](https://openreview.net/forum?id=d3QNWD_pcFv).

* Kullback (1968) Solomon Kullback. Probability densities with given marginals. _The Annals of Mathematical Statistics_, 39(4):1236-1243, 1968.
* Kunita (2019) Hiroshi Kunita. _Stochastic flows and jump-diffusions_, volume 92. Springer, 2019.
* Leonard (2014a) Christian Leonard. A survey of the Schrodinger problem and some of its connections with optimal transport. _Discrete and Continuous Dynamical Systems-Series A_, 34(4):1533-1574, 2014a.
* Leonard (2014b) Christian Leonard. Some properties of path measures. In _Seminaire de Probabilites XLVI_, pp. 207-230. Springer, 2014b.
* Leonard et al. (2014) Christian Leonard, Sylvie Roelly, and Jean-Claude Zambrini. Reciprocal processes. a measure-theoretical point of view. 2014.
* Li et al. (2020) Xuechen Li, Ting-Kam Leonard Wong, Ricky T. Q. Chen, and David K. Duvenaud. Scalable gradients and variational inference for stochastic differential equations. In _Symposium on Advances in Approximate Bayesian Inference_, pp. 1-28. PMLR, 2020.
* Li and Turner (2016) Yingzhen Li and Richard E Turner. Renyi divergence variational inference. _Advances in neural information processing systems_, 29, 2016.
* Liu et al. (2019) Chang Liu, Jingwei Zhuo, Pengyu Cheng, Ruiyi Zhang, and Jun Zhu. Understanding and accelerating particle-based variational inference. In _International Conference on Machine Learning_, pp. 4082-4092. PMLR, 2019.
* Liu et al. (2021) Guan-Horng Liu, Tianrong Chen, Oswin So, and Evangelos Theodorou. Deep generalized Schrodinger bridge. In _Advances in Neural Information Processing Systems_, a.
* Liu et al. (2022) Xingchao Liu, Lemeng Wu, Mao Ye, et al. Let us build bridges: Understanding and extending diffusion generative models. In _NeurIPS 2022 Workshop on Score-Based Methods_, b.
* Matthews et al. (2022) Alex Matthews, Michael Arbel, Danilo Jimenez Rezende, and Arnaud Doucet. Continual repeated annealed flow transport monte carlo. In _International Conference on Machine Learning_, pp. 15196-15219. PMLR, 2022.
* Midgley et al. (2022) Laurence Illing Midgley, Vincent Stimper, Gregor NC Simm, Bernhard Scholkopf, and Jose Miguel Hernandez-Lobato. Flow annealed importance sampling bootstrap. _arXiv preprint arXiv:2208.01893_, 2022.
* Millet et al. (1989) Annie Millet, David Nualart, and Marta Sanz. Integration by parts and time reversal for diffusion processes. _The Annals of Probability_, pp. 208-238, 1989.
* Moller et al. (1998) Jesper Moller, Anne Randi Syversveen, and Rasmus Plenge Waagepetersen. Log gaussian cox processes. _Scandinavian journal of statistics_, 25(3):451-482, 1998.
* Neal (2001) Radford M Neal. Annealed importance sampling. _Statistics and computing_, 11:125-139, 2001.
* Neal (2003) Radford M Neal. Slice sampling. _The annals of statistics_, 31(3):705-767, 2003.
* Neal and Hinton (1998) Radford M Neal and Geoffrey E Hinton. A view of the EM algorithm that justifies incremental, sparse, and other variants. _Learning in graphical models_, pp. 355-368, 1998.
* Neklyudov et al. (2023) Kirill Neklyudov, Rob Brekelmans, Daniel Severo, and Alireza Makhzani. Action matching: Learning stochastic dynamics from samples. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), _Proceedings of the 40th International Conference on Machine Learning_, volume 202 of _Proceedings of Machine Learning Research_, pp. 25858-25889. PMLR, 23-29 Jul 2023. URL [https://proceedings.mlr.press/v202/neklyudov23a.html](https://proceedings.mlr.press/v202/neklyudov23a.html).
* Nelson (1967) Edward Nelson. _Dynamical theories of Brownian motion_, volume 3. Princeton university press, 1967.
* Nusken and Richter (2021) Nikolas Nusken and Lorenz Richter. Solving high-dimensional Hamilton-Jacobi-Bellman PDEs using neural networks: perspectives from the theory of controlled diffusions and measures on path space. _Partial Differential Equations and Applications_, 2(4):1-48, 2021.

* Nusken and Richter (2023) Nikolas Nusken and Lorenz Richter. Interpolating between BSDEs and PINNs: Deep learning for elliptic and parabolic boundary value problems. _Journal of Machine Learning_, 2(1):31-64, 2023.
* Oksendal (2003) Bernt Oksendal. Stochastic differential equations. In _Stochastic differential equations_, pp. 65-84. Springer, 2003.
* Onken et al. (2021) Derek Onken, Samy Wu Fung, Xingjian Li, and Lars Ruthotto. OT-flow: Fast and accurate continuous normalizing flows via optimal transport. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 35, pp. 9223-9232, 2021.
* Papamakarios et al. (2017) George Papamakarios, Theo Pavlakou, and Iain Murray. Masked autoregressive flow for density estimation. _arXiv preprint arXiv:1705.07057_, 2017.
* Papamakarios et al. (2021) George Papamakarios, Eric Nalisnick, Danilo Jimenez Rezende, Shakir Mohamed, and Balaji Lakshminarayanan. Normalizing flows for probabilistic modeling and inference. _The Journal of Machine Learning Research_, 22(1):2617-2680, 2021.
* Peluchetti (2023) Stefano Peluchetti. Diffusion bridge mixture transports, Schrodinger bridge problems and generative modeling. _arXiv preprint arXiv:2304.00917_, 2023.
* Reich (2011) Sebastian Reich. A dynamical systems framework for intermittent data assimilation. _BIT Numerical Mathematics_, 51(1):235-249, 2011.
* Reich (2022) Sebastian Reich. Data assimilation: A dynamic homotopy-based coupling approach. _arXiv preprint arXiv:2209.05279_, 2022.
* Revuz and Yor (2013) Daniel Revuz and Marc Yor. _Continuous martingales and Brownian motion_, volume 293. Springer Science & Business Media, 2013.
* Rezende and Mohamed (2015) Danilo Rezende and Shakir Mohamed. Variational inference with normalizing flows. In _International conference on machine learning_, pp. 1530-1538. PMLR, 2015.
* Rezende et al. (2014) Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. In _International conference on machine learning_, pp. 1278-1286. PMLR, 2014.
* Richter et al. (2020) Lorenz Richter, Ayman Boustati, Nikolas Nusken, Francisco Ruiz, and Omer Deniz Akyildiz. Vargrad: a low-variance gradient estimator for variational inference. _Advances in Neural Information Processing Systems_, 33:13481-13492, 2020.
* Roeder et al. (2017) Geoffrey Roeder, Yuhuai Wu, and David Duvenaud. Sticking the landing: Simple, lower-variance gradient estimators for variational inference. _arXiv preprint arXiv:1703.09194_, 2017.
* Reelly (2013) Sylvie Reelly. Reciprocal processes: a stochastic analysis approach. In _Modern stochastics and applications_, pp. 53-67. Springer, 2013.
* Rogers and Williams (2000) L Chris G Rogers and David Williams. _Diffusions, Markov processes and martingales: Volume 2, Ito calculus_, volume 2. Cambridge university press, 2000.
* Ruschendorf (1995) Ludger Ruschendorf. Convergence of the iterative proportional fitting procedure. _The Annals of Statistics_, 23(4):1160-1174, 1995.
* Russo and Vallois (1995) Francesco Russo and Pierre Vallois. The generalized covariation process and Ito formula. _Stochastic Processes and their applications_, 59(1):81-104, 1995.
* Russo and Vallois (1996) Francesco Russo and Pierre Vallois. Ito formula for \(C^{1}\)-functions of semimartingales. _Probability theory and related fields_, 104:27-41, 1996.
* Schrodinger (1931) Erwin Schrodinger. Uber die Umkehrung der Naturgesetze. _Sitzungsberichte der Preuss Akad. Wissen. Berlin, Phys. Math. Klasse_, pp. 144-153, 1931.
* Shi et al. (2023) Yuyang Shi, Valentin De Bortoli, Andrew Campbell, and Arnaud Doucet. Diffusion Schrodinger bridge matching. _arXiv preprint arXiv:2303.16852_, 2023.

* Sohl-Dickstein et al. (2015) Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In _International Conference on Machine Learning_, pp. 2256-2265. PMLR, 2015.
* Song & Ermon (2019) Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. _Advances in neural information processing systems_, 32, 2019.
* Song et al. (2020) Yang Song, Sahaj Garg, Jiaxin Shi, and Stefano Ermon. Sliced score matching: A scalable approach to density and score estimation. In _Uncertainty in Artificial Intelligence_, pp. 574-584. PMLR, 2020.
* Song et al. (2021) Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In _International Conference on Learning Representations_, 2021. URL [https://openreview.net/forum?id=PxTIG12RRHS](https://openreview.net/forum?id=PxTIG12RRHS).
* Stoltz et al. (2010) Gabriel Stoltz, Mathias Rousset, et al. _Free energy computations: A mathematical perspective_. World Scientific, 2010.
* Sutton & Barto (2018) Richard S Sutton and Andrew G Barto. _Reinforcement learning: An introduction_. MIT press, 2018.
* Thieullen (2002) Michele Thieullen. Reciprocal diffusions and symmetries of parabolic PDE: The nonflat case. _Potential Analysis_, 16:1-28, 2002.
* Thin et al. (2021) Achille Thin, Nikita Kotelevskii, Arnaud Doucet, Alain Durmus, Eric Moulines, and Maxim Panov. Monte carlo variational auto-encoders. In _International Conference on Machine Learning_, pp. 10247-10257. PMLR, 2021.
* Tzen & Raginsky (2019a) Belinda Tzen and Maxim Raginsky. Neural stochastic differential equations: Deep latent Gaussian models in the diffusion limit. _arXiv preprint arXiv:1905.09883_, 2019a.
* Tzen & Raginsky (2019b) Belinda Tzen and Maxim Raginsky. Theoretical guarantees for sampling and inference in generative models with latent diffusions. In _Conference on Learning Theory_, pp. 3084-3114. PMLR, 2019b.
* Ustunel & Zakai (2013) A Suleyman Ustunel and Moshe Zakai. _Transformation of measure on Wiener space_. Springer Science & Business Media, 2013.
* Vaikuntanathan & Jarzynski (2008) Suriyanarayanan Vaikuntanathan and Christopher Jarzynski. Escorted free energy simulations: Improving convergence by reducing dissipation. _Physical Review Letters_, 100(19):190601, 2008.
* Vargas (2021) Francisco Vargas. Machine-learning approaches for the empirical Schrodinger bridge problem. Technical report, University of Cambridge, Computer Laboratory, 2021.
* Vargas et al. (2021a) Francisco Vargas, Pierre Thodoroff, Austen Lamacraft, and Neil Lawrence. Solving Schrodinger bridges via maximum likelihood. _Entropy_, 23(9):1134, 2021a.
* Vargas et al. (2021b) Francisco Vargas, Pierre Thodoroff, Austen Lamacraft, and Neil Lawrence. Solving Schrodinger bridges via maximum likelihood. _Entropy_, 23(9), 2021b. ISSN 1099-4300. doi: 10.3390/e23091134. URL [https://www.mdpi.com/1099-4300/23/9/1134](https://www.mdpi.com/1099-4300/23/9/1134).
* Vargas et al. (2023a) Francisco Vargas, Will Sussman Grathwohl, and Arnaud Doucet. Denoising diffusion samplers. In _The Eleventh International Conference on Learning Representations_, 2023a. URL [https://openreview.net/forum?id=8pvmfTAbul1f](https://openreview.net/forum?id=8pvmfTAbul1f).
* Vargas et al. (2023b) Francisco Vargas, Andrius Ovsianas, David Fernandes, Mark Girolami, Neil D Lawrence, and Nikolas Nusken. Bayesian learning via neural Schrodinger-Follmer flows. _Statistics and Computing_, 33(1):3, 2023b.
* Vargas et al. (2023c) Francisco Vargas, Teodora Reu, and Anna Kerekes. Expressiveness remarks for denoising diffusion based sampling. In _Fifth Symposium on Advances in Approximate Bayesian Inference_, 2023c.
* Villani (2003) Cedric Villani. _Topics in optimal transportation_. Number 58. American Mathematical Soc., 2003.
* Villani et al. (2009) Cedric Villani et al. _Optimal transport: old and new_, volume 338. Springer, 2009.
* Vedral et al. (2018)* Wu et al. (2020) Hao Wu, Jonas Kohler, and Frank Noe. Stochastic normalizing flows. _Advances in Neural Information Processing Systems_, 33:5933-5944, 2020.
* Xu et al. (2021) Winnie Xu, Ricky T. Q. Chen, Xuechen Li, and David Duvenaud. Infinitely deep Bayesian neural networks with stochastic differential equations. _arXiv preprint arXiv:2102.06559_, 2021.
* Ye et al. (2022) Mao Ye, Lemeng Wu, and Qiang Liu. First hitting diffusion models for generating manifold, graph and categorical data. In _Advances in Neural Information Processing Systems_, 2022.
* Zhang & Katsoulakis (2023) Benjamin J Zhang and Markos A Katsoulakis. A mean-field games laboratory for generative modeling. _arXiv preprint arXiv:2304.13534_, 2023.
* Zhang et al. (2021) Guodong Zhang, Kyle Hsu, Jianing Li, Chelsea Finn, and Roger Grosse. Differentiable annealed importance sampling and the perils of gradient noise. In _Advances in Neural Information Processing Systems_, 2021.
* Zhang (2017) Jianfeng Zhang. _Backward stochastic differential equations_. Springer, 2017.
* Zhang & Chen (2021) Qinsheng Zhang and Yongxin Chen. Diffusion normalizing flow. _Advances in Neural Information Processing Systems_, 34:16280-16291, 2021.
* Zhang & Chen (2022) Qinsheng Zhang and Yongxin Chen. Path integral sampler: A stochastic control approach for sampling. In _International Conference on Learning Representations_, 2022. URL [https://openreview.net/forum?id=_uCb2ynRu7Y](https://openreview.net/forum?id=_uCb2ynRu7Y).
* Zhang (2021) Wei Zhang. Some new results on relative entropy production, time reversal, and optimal control of time-inhomogeneous diffusion processes. _Journal of Mathematical Physics_, 62(4):043302, 2021.
* Zhang et al. (2014) Wei Zhang, Han Wang, Carsten Hartmann, Marcus Weber, and Christof Schutte. Applications of the cross-entropy method to importance sampling and optimal control of diffusions. _SIAM Journal on Scientific Computing_, 36(6):A2654-A2672, 2014.
* Zhou et al. (2016) Yan Zhou, Adam M Johansen, and John AD Aston. Toward automatic model comparison: an adaptive sequential monte carlo approach. _Journal of Computational and Graphical Statistics_, 25(3):701-726, 2016.

## Appendix A Stochastic analysis for backward processes

In this appendix, we briefly discuss background in stochastic analysis relevant to the SDEs in (12), here repeated for convenience:

\[\mathrm{d}\mathbf{Y}_{t} =a_{t}(\mathbf{Y}_{t})\,\mathrm{d}t+\sigma\overrightarrow{\mathrm{d}} \mathbf{W}_{t}, \mathbf{Y}_{0}\sim\mu, \tag{25a}\] \[\mathrm{d}\mathbf{Y}_{t} =b_{t}(\mathbf{Y}_{t})\,\mathrm{d}t+\sigma\overrightarrow{\mathrm{d} }\mathbf{W}_{t}, \mathbf{Y}_{T}\sim\nu. \tag{25b}\]

Recall that the forward Ito differential \(\overrightarrow{\mathrm{d}}\) in (25a) is far more commonly denoted simply6 by \(\mathrm{d}\), and theory for the forward SDE (25a) is widely known (Karatzas et al., 1991; Qksendal, 2003). In contrast, reverse-time SDEs of the form (25b) are less common and there are fewer textbook accounts of their interactions with forward SDEs. We highlight Kunita (2019) for an in-depth treatment, and alert the reader to the fact that 'backward stochastic differential equations' as discussed in Zhang (2017); Chen et al. (2022), for instance, are largely unrelated. We therefore refer to (25b) as a'reverse-time' SDE.

Footnote 6:...but in this paper we stick to the notation \(\overrightarrow{\mathrm{d}}\) to emphasise the symmetry of the setting.

**Remark 5** (Notation).: **We deliberately depart from some of the notation employed in the recent literature (see, for instance, Huang et al. (2021); Liu et al. (b)) by using \(\mathbf{Y}_{t}\) in both (25a) and (25b), and not introducing an auxiliary process capturing the reverse-time dynamics. From a technical perspective, this is justified since \((\mathbf{Y}_{t})_{0\leq t\leq T}\) merely represents a generic element in path space, and full information is encoded in the path measures \(\mathbb{Q}^{\mu,a}\equiv\overrightarrow{\mathrm{P}}^{\mu,a}\) and \(\mathbb{P}^{\nu,b}\equiv\overleftarrow{\mathrm{P}}^{\nu,b}\). Importantly, placing (25a) and (25b) on an equal footing seems essential for a convenient formulation of Proposition 2.2. Slightly departing from the VAE-inspired notation from Section 2.1, we equivalently refer to these path measures by \(\overrightarrow{\mathrm{P}}^{\mu,a}\) and \(\overleftarrow{\mathrm{P}}^{\nu,b}\), highlighting the symmetry of the setting in (25).

Intuitively, (25) can be viewed as continuous time limits of the Markov chains defined in (9), or, in other words, the Markov chains (9) are the Euler-Maruyama discretisations for (25), see Kloeden et al. (1992, Section 9.1). Throughout, we impose the following:

**Assumption A.1** (Smoothness and linear growth of vector fields).: All (time-dependent) vector fields in this paper belong to the set

\[\mathcal{U}:=\Bigg{\{}a\in C^{\infty}([0,T]\times\mathbb{R}^{d}; \mathbb{R}^{d}):\quad\text{there exists a constant }\,C>0\] \[\text{such that }\|a_{t}(\mathbf{x})-a_{t}(\mathbf{y})\|\leq C\|\mathbf{x}- \mathbf{y}\|,\,\text{for all }t\in[0,T],\,\,\,\mathbf{x},\mathbf{y}\in\mathbb{R}^{d}\Bigg{\}}.\]

The preceding assumption guarantees existence and uniqueness for (25a) and (25b), and it allows us to use Girsanov's theorem in the proof of Proposition 2.2 (Novikov's condition can be shown to be satisfied, see Oksendal (2003, Section 8.6)). Furthermore, Assumption A.1 is sufficient to conclude Nelson's relation (Proposition 2.1), see Haussmann & Pardoux (1985); Millet et al. (1989); Follmer (2006b) and the discussion in Russo & Vallois (1996). Having said all that, it is possible to substantially weaken Assumption A.1 with more technical effort. Moreover, we can replace the constant \(\sigma>0\) by \(\sigma:[0,T]\times\mathbb{R}^{d}\to\mathbb{R}^{d\times d}\) throughout, assuming sufficient regularity, growth and invertibility properties, and amending the formulas accordingly.

The precise meaning of (25) is given by the integrated formulations

\[\mathbf{Y}_{t} =\mathbf{Y}_{0}+\int_{0}^{t}a_{s}(\mathbf{Y}_{s})\,\mathrm{d}s+\int_{0}^{ t}\sigma\,\overrightarrow{\mathrm{d}}\mathbf{W}_{s}, \mathbf{Y}_{0}\sim\mu, \tag{27a}\] \[\mathbf{Y}_{t} =\mathbf{Y}_{T}-\int_{t}^{T}b_{s}(\mathbf{Y}_{s})\,\mathrm{d}s-\int_{t}^{ T}\sigma\,\overleftarrow{\mathrm{d}}\mathbf{W}_{s}, \mathbf{Y}_{T}\sim\nu, \tag{27b}\]

where the forward and backward integrals need defining. Roughly speaking, we have

\[\int_{t_{0}}^{t_{1}}\mathbf{X}_{s}\cdot\overrightarrow{\mathrm{d}}\bm {Z}_{s} =\lim_{\Delta t\to 0}\sum_{i}\mathbf{X}_{t_{i}}\cdot(\mathbf{Z}_{t_{i+1}}-\mathbf{Z} _{t_{i}}), \tag{28a}\] \[\int_{t_{0}}^{t_{1}}\mathbf{X}_{s}\cdot\overleftarrow{\mathrm{d}}\bm {Z}_{s} =\lim_{\Delta t\to 0^{\prime}}\sum_{i}\mathbf{X}_{t_{i+1}}\cdot(\mathbf{Z}_{t_{i+ 1}}-\mathbf{Z}_{t_{i}}), \tag{28b}\]

see Remark 3, for 'appropriate' processes \((\mathbf{X}_{t})_{0\leq t\leq T}\) and \((\mathbf{Z}_{t})_{0\leq t\leq T}\), and where the limit \(\Delta t\to 0\) of vanishing step sizes needs careful analysis (see Remark 6 below). The most salient difference between (25a) and (25b) is the fact that \(\mathbf{X}_{t_{i}}\) is replaced by \(\mathbf{X}_{t_{i+1}}\) in (28b).

**Remark 6** (Convergence of the limits in (28)).: If we only assume that \(\mathbf{X},\mathbf{Z}\in C([t_{0},t_{1}];\mathbb{R}^{d})\), possibly pathwise, that is, deterministically, then the limits in (28) might not exist, or when they do, their values might depends on the specific sequence of mesh refinements. The following approaches are available to make the definitions (28) rigorous:

1. Ito calculus (see, for example, Revuz & Yor (2013, Chapter 9)) uses adaptedness and semimartingale properties for the forward integral in (28a), but note that the definition is not pathwise (that is, the limit (28a) is defined up to a set of measure zero). For the backward integrals in (28b) and, importantly for us, in (64), it can then be shown that the relevant processes are (continuous) reverse-time martingales (see Kunita (2019) for a discussion of the corresponding filtrations). The latter property is guaranteed under Assumption A.1, see the discussion around Theorem 2.3 in Russo & Vallois (1996).
2. Follmer's Ito calculus without probabilities' (Follmer, 2006a) is convenient, since it allows to us to perform calculations using (25) and Proposition 2.2 without introducing filtrations and related stochastic machinery. The caveat is that the results may in principle depend on the sequence of mesh refinements, but under Assumption A.1, those differences only appear on a set of measure zero, see Russo & Vallois (1995); Follmer & Protter (2000).
3. Similarly, the integrals in (28) can be defined in a pathwise fashion using rough path techniques, see Friz & Hairer (2020, Section 5.4).

For the current paper, the following conversion formulas are crucial,

\[\int_{0}^{t}\mathbf{X}_{s}\cdot\overleftarrow{\mathrm{d}}\mathbf{Z}_{s}-\int _{0}^{t}\mathbf{X}_{s}\cdot\overrightarrow{\mathrm{d}}\mathbf{Z}_{s}=\langle\mathbf{X},\mathbf{Z }\rangle_{t}, \tag{29a}\] \[\int_{0}^{t}\mathbf{X}_{s}\cdot\overleftarrow{\mathrm{d}}\mathbf{Z}_{s}+ \int_{0}^{t}\mathbf{X}_{s}\cdot\overrightarrow{\mathrm{d}}\mathbf{Z}_{s}=2\int_{0}^{t} \mathbf{X}_{s}\circ\mathbf{Z}_{s}, \tag{29b}\]

where \(\langle\mathbf{X},\mathbf{Z}\rangle\) is the quadratic variation process (if defined, see Russo and Vallois (1995)), and \(\circ\) denotes Stratonovich integration. For solutions to (25), we obtain (15) from (29a). In particular, we can often trade backward integrals for divergence terms (see Appendix C.1), using the (backward) martingale properties

\[\mathbb{E}\left[\int_{0}^{t}f_{t}(\mathbf{Y}_{t})\cdot\overrightarrow {\mathrm{d}}\mathbf{W}_{t}\right]=0,\quad\text{if }(\mathbf{Y}_{t})_{0\leq t\leq T}\text{ solves }(25a), \tag{30a}\] \[\mathbb{E}\left[\int_{t}^{T}f_{t}(\mathbf{Y}_{t})\cdot\overleftarrow{ \mathrm{d}}\mathbf{W}_{t}\right]=0,\quad\text{if }(\mathbf{Y}_{t})_{0\leq t\leq T}\text{ solves }(25b). \tag{30b}\]

## Appendix B Variational inference and divergences

Various concepts well-known in the variational inference community have direct counterparts in the diffusion setting. In this appendix we review a few that are directly relevant to this paper.

**Maximum likelihood.** Framework 1 with \(D=D_{\mathrm{KL}}\) leads via direct calculations to

\[\mathcal{L}_{D_{\mathrm{KL}}}(\phi,\theta)=-\mathbb{E}_{\mathbf{x}\sim\mu(\mathbf{x})} \overbrace{\left[\int\ln\frac{p^{\theta}(\mathbf{x}|\mathbf{z})\nu(\mathbf{z})}{q^{\phi}( \mathbf{z}|\mathbf{x})}q^{\phi}(\mathrm{d}\mathbf{z}|\mathbf{x})\right]}^{=\mathrm{ELBO}_{ \mathbf{x}}(\phi,\theta)}+\int\ln\mu(\mathbf{x})\mu(\mathrm{d}\mathbf{x}), \tag{31}\]

so that maximising \(\mathbb{E}_{\mathbf{x}\sim\mu(\mathbf{x})}[\mathrm{ELBO}_{x}(\phi,\theta)]\) is equivalent to minimising \(\mathcal{L}_{D_{\mathrm{KL}}}(\phi,\theta)\).

However, the traditional approach (Blei et al., 2017; Kingma et al., 2019) towards the _evidence lower bound_ (ELBO) in (31) is via maximum likelihood in latent variable models. Using the notation and set-up from the introduction, one can show using Jensen's inequality (or dual representations of the KL divergence), that

\[\ln\left(\int p_{\theta}(\mathbf{x},\mathbf{z})\,\mathrm{d}\mathbf{z}\right)=\ln p_{ \theta}(\mathbf{x})\geq\mathrm{ELBO}_{\mathbf{x}}(\phi,\theta), \tag{32}\]

with equality if and only if \(q_{\phi}(\mathbf{z}|\mathbf{x})=p_{\theta}(\mathbf{z}|\mathbf{x})\). The bound in (32) motivates maximising the (tractable) right-hand side, performing model selection (according to Bayesian evidence) and posterior approximation (in terms of the variational family \(q_{\phi}(\mathbf{z}|\mathbf{x})\)) at the same time. The calculation in (31) shows that this objective can equivalently be derived from Framework 1 and connected to the KL divergence between the joint distributions \(q_{\phi}(\mathbf{x},\mathbf{z})\) and \(p_{\theta}(\mathbf{x},\mathbf{z})\).

**Reparameterisation trick (Kingma and Welling, 2014; Rezende et al., 2014).** For optimising \(\mathrm{ELBO}_{\mathbf{x}}(\phi,\theta)\), it is crucial to select efficient low-variance gradient estimators. In this context, it has been observed that reparameterising \(\mathbf{z}\sim q_{\phi}(\mathbf{z}|\mathbf{x})\) in the form \(\mathbf{z}=g(\epsilon,\phi,\mathbf{x})\), see Kingma et al. (2019, Section 2.4.1), substantially stabilises the training procedure. Here, \(\epsilon\) is an auxiliary random variable with tractable 'base distribution' that is independent of \(\phi\) and \(\mathbf{x}\), and \(g\) is a deterministic function (transforming \(\epsilon\) into \(\mathbf{z}\)), parameterised by \(\phi\) and \(\mathbf{x}\). We would like to point out that many (although not all, see below) objectives in diffusion modelling are already reparameterised, since the SDEs (12) transform the 'auxiliary' variables \((\mathbf{W}_{t})_{0\leq t\leq T}\) into \((\mathbf{Y}_{t})_{0\leq t\leq T}\). With this viewpoint, the vector field \(a_{t}\) corresponds to the parameter \(\phi\), \((\mathbf{W}_{t})_{0\leq t\leq T}\) corresponds to \(\epsilon\), and \(g\) corresponds to the solution map associated to the SDE (12a), sometimes referred to as the Ito map. In this sense, the objectives (74), (39) and (40) are reparameterised, but \(\mathcal{C}_{\mathrm{Var}}^{\mathrm{CMCD}}\) from Section 3.2 is not if the gradients are detached as in (Nusken and Richter, 2021; Richter et al., 2020). We mention in passing that _sticking the landing_(Roeder et al., 2017) offers a further variance reduction close to optimality, and that the same method can be employed for diffusion objectives, see Vargas et al. (2023); Xu et al. (2021).

**Reinforce gradient estimators.** As an alternative to the KL-divergence, Nusken and Richter (2021) investigated the family of _log-variance divergences_

\[D_{\mathrm{Var}}^{u}(q||p)=\mathrm{Var}_{\mathbf{x}\sim u}\left(\ln\frac{\mathrm{d} q}{\mathrm{d}p}(\mathbf{x})\right), \tag{33}\]parameterised by an auxiliary distribution \(u\), in order to connect variational inference to backward stochastic differential equations (Zhang, 2017). The fact that gradients of (33) do not have to be taken with respect to \(\mathbf{x}\) (see Remark (Nusken and Richter, 2021; Richter et al., 2020)) reduces the computational cost and provides additional flexibility in the choice of \(u\), but the gradient estimates potentially suffer from higher variance since the reparameterisation trick is not available. The latter drawback is alleviated somewhat by the fact that particular choices of \(u\) can be linked to control variate enhanced reinforce gradient estimators (Richter et al., 2020) that are particularly useful when reparameterisation is not available (such as in discrete models). We note that the same divergence has also been used as a variational inference objective in El Mosehy and Marzouk (2012).

**Importance weighted autoencoders (IWAE).**Burda et al. (2015) have developed a multi-sample version of \(\operatorname{ELBO}_{\mathbf{x}}(\phi,\theta)\) that achieves a tighter lower bound on the marginal log-likelihood in (32). To develop similar objectives in a diffusion setting, we observe that for each \(K\geq 1\),

\[D^{(K)}_{\text{KL}}(q||p)=\mathbb{E}_{x_{1},\ldots,x_{K}\overset{iid}{\sim}q} \left[\ln\left(\frac{1}{K}\sum_{i=1}^{K}\frac{\mathrm{d}q}{\mathrm{d}p}(x_{i} )\right)\right] \tag{34}\]

defines a generalised KL divergence7 that reproduces the IWAE lower bound as per Framework 1, in the sense of equation (31). To the best of our knowledge, the precise formulation in (34) is new, but similar to the previous works Hernandez-Lobato et al. (2016); Li and Turner (2016); Daudel et al. (2022). We exhibit an example of (34) applied in a diffusion context in Section C.3, see Remark 7.

Footnote 7: Indeed, by Jensen’s inequality, we have that \(D^{(K+1)}_{\text{KL}}(q||p)\geq D^{(K)}_{\text{KL}}(q||p)\), so that in particular \(q\neq p\) implies \(D^{(K)}_{\text{KL}}(q||p)>0\).

## Appendix C Connections to previous work

Discussion of equivalent expressions for \(D_{\text{KL}}(\overrightarrow{\mathbb{P}}^{\mu,a}||\overleftarrow{\mathbb{P}} ^{\nu,b})\)

Notice that we can realise samples from \(\overleftarrow{\mathbb{P}}^{\nu,b}\) both via the reverse-time SDE in (12b) or via its time reversal given by the following forward SDE (Nelson, 1967; Anderson, 1982; Haussmann and Pardoux, 1985):

\[\mathrm{d}\widehat{\mathbf{Y}}_{t}=\left(b_{T-t}(\widehat{\mathbf{Y}}_{t})-\sigma^{2} \nabla\ln\overleftarrow{\rho}_{T-t}^{\nu,b}(\widehat{\mathbf{Y}}_{t})\right) \mathrm{d}t+\sigma\overrightarrow{\mathrm{d}}\mathbf{W}_{t},\qquad\widehat{\mathbf{Y} }_{0}\sim\nu, \tag{35}\]

using \(\widehat{\mathbf{Y}}_{t}:=\widehat{\mathbf{Y}}_{T-t}\). This allows us to obtain an expression for \(D_{\text{KL}}(\overrightarrow{\mathbb{P}}^{\mu,a}||\overleftarrow{\mathbb{P}} ^{\nu,b})\) via Girsanov's theorem:

\[D_{\text{KL}}(\overrightarrow{\mathbb{P}}^{\mu,a}||\overleftarrow{\mathbb{P} }^{\nu,b})=D_{\text{KL}}(\overleftarrow{\rho}_{0}^{\nu,b}||\nu)+\mathbb{E} \left[\frac{1}{2\sigma^{2}}\int_{0}^{T}\Big{|}\Big{|}a_{t}(\mathbf{Y}_{t})-\left( b_{t}(\mathbf{Y}_{t})-\sigma^{2}\nabla\ln\overleftarrow{\rho}_{t}^{\nu,b}(\mathbf{Y}_{t}) \right)\Big{|}\Big{|}^{2}\mathrm{d}t\right]. \tag{36}\]

However there are several terms here that we cannot estimate or realise in a tractable manner, one being the score \(\nabla\ln\overleftarrow{\rho}_{t}^{\nu,b}\) and the other being sampling from the distribution \(\overleftarrow{\rho}_{0}^{\nu,b}\).8

Footnote 8: When \(\mathbf{Y}_{t}\) is an OU process and \(\mu\) is Gaussian we are in the traditional DDPM setting (Song et al., 2021) and these two quantities admit the classical tractable score matching approximations

In order to circumvent the score term, the authors Vargas et al. (2021b); Chen et al. (2022) use the Fokker-Plank (FPK) equation and integration by parts, respectively, trading of the score with a divergence term, whilst Huang et al. (2021a) use a variant of the Feynman Kac formula to arrive at an equivalent solution. From Proposition 2.2, we can avoid the divergence entirely and replace it by a backwards integral (making use of the conversion formula (15) and the fact that the ensuing forward integral is zero in expectation). As hinted at in Remark 3, this replacement might have favourable variance-reducing properties, but numerical evidence would be necessary.

### Score-based generative modeling

Generative modeling is concerned with the scenario where \(\mu(\mathbf{x})\) can be sampled from (but its density is unknown), and the goal is to learn a backward diffusion as in (12b) that allows us to generate further samples from \(\mu(\mathbf{x})\), see Song et al. (2021). We may fix a reference forward drift \(a_{t}\), and,motivated by Proposition 2.1, parameterise the backward drift as \(b_{t}=a_{t}-s_{t}\), so that in the case when \(\overrightarrow{\mathbb{P}}^{\mu,a}=\overrightarrow{\mathbb{P}}^{\nu,b}\), the variable drift component \(s_{t}\) will represent the score \(\sigma^{2}\nabla\ln\rho_{t}^{\mu,a}\). When the diffusion associated to \(a_{t}\) is ergodic and \(T\) is large, \(\overrightarrow{\mathbb{P}}^{\mu,a}=\overleftarrow{\mathbb{P}}^{\nu,b}\) requires that \(\nu(\mathbf{z})\) is close to the corresponding invariant measure. Choosing \(\gamma_{t}^{-}=a_{t}\), and, for simplicity \(\sigma=1\), direct calculations using Proposition 2.2 show that

\[\mathcal{L}_{\mathrm{ISM}}(s):=D_{\mathrm{KL}}(\overrightarrow{ \mathbb{P}}^{\mu,a}\|\big{\|}^{\overleftarrow{\mathbb{P}}^{\nu,a-s}})=\mathbb{ E}_{\mathbf{Y}\sim\overrightarrow{\mathbb{P}}^{\mu,a}}\left[\tfrac{1}{2}\int_{0}^{T}s_{t}^ {2}(\mathbf{Y}_{t})\,\mathrm{d}t+\int_{0}^{T}(\nabla\cdot s_{t})(\mathbf{Y}_{t})\, \mathrm{d}t\right]+\mathrm{const}. \tag{37}\]

recovers the implicit score matching objective (Hyvarinen and Dayan, 2005), up to a constant that does not depend on \(s_{t}\).

Proof.: We start by noticing that the contributions in (14a) and (14b) do not depend on \(s_{t}\), and can therefore be absorbed in the constant in (37) Notice that the precise forms of \(\Gamma_{0}\), \(\Gamma_{T}\) and \(\gamma^{+}\) are left unspecified or unknown, but this does not affect the argument. We find

\[D_{\mathrm{KL}}(\overrightarrow{\mathbb{P}}^{\mu,a}\|\big{\|} \overleftarrow{\mathbb{P}}^{\nu,a-s}) =\mathbb{E}_{\mathbf{Y}\sim\overrightarrow{\mathbb{P}}^{\nu,a}}\left[ \int_{0}^{T}s_{t}(\mathbf{Y}_{t})\cdot\left(\overleftarrow{\mathrm{d}}\mathbf{Y}_{t}- \tfrac{1}{2}\left(2a_{t}-s_{t}\right)(\mathbf{Y}_{t})\,\mathrm{d}t\right)\right]+ \mathrm{const}.\] \[=\mathbb{E}\left[\int_{0}^{T}s_{t}(\mathbf{Y}_{t})\cdot\left(\sigma \overleftarrow{\mathrm{d}}\mathbf{W}_{t}+\tfrac{1}{2}s_{t}(\mathbf{Y}_{t})\,\mathrm{d }t\right)\right]+\mathrm{const}.\] \[=\mathbb{E}\left[\tfrac{1}{2}\int_{0}^{T}s_{t}^{2}(\mathbf{Y}_{t})\, \mathrm{d}t+\int_{0}^{T}(\nabla\cdot s_{t})(\mathbf{Y}_{t})\,\mathrm{d}t\right]+ \mathrm{const}.,\]

where in the first line we use Proposition 2.2 together with \(b_{t}=a_{t}-s_{t}\) and \(\gamma_{t}^{-}=a_{t}\), and to proceed to the second line we substitute \(\overleftarrow{\mathrm{d}}\mathbf{Y}_{t}\) using the SDE in (12a). The last equality follows from the conversion formula between forward and backward Ito integrals, see (15), and the fact that forward integrals with respect to Brownian motion have zero (forward) expectation, see (30a). 

Notice that the nonuniqueness in Framework \(1^{\prime}\) has been circumvented by fixing the forward drift \(a_{t}\); indeed \(\mathcal{L}_{\mathrm{ISM}}\) is convex in \(s\), confirming Note that using integration by parts, \(\mathcal{L}_{\mathrm{ISM}}\) is equivalent to denoising score matching (Song et al., 2020; 2021):

\[D_{\mathrm{KL}}(\overrightarrow{\mathbb{P}}^{\mu,a}\|\big{\|}^{\overleftarrow {\mathbb{P}}^{\nu,a-s}})=\mathbb{E}_{\mathbf{Y}\sim\overrightarrow{\mathbb{P}}^{ \mu,a}}\left[\tfrac{1}{2\sigma^{2}}\int_{0}^{T}\left\|s_{t}(\mathbf{Y}_{t})-\nabla \ln\rho_{t|0}^{\mu,a}(\mathbf{Y}_{t}|\mathbf{Y}_{0})\right\|^{2}\,\mathrm{d}t\right]+ \mathrm{const}. \tag{38}\]

Framework \(1^{\prime}\) accommodates modifications of (37); in particular the divergence term in (37) can be replaced by a backward integral, see Appendix C.1 and Remark 3. Note that the settings discussed in this section are also akin to the formulations in Kingma et al. (2021); Huang et al. (2021).

Finally, it is worth highlighting that this setting is not limited to ergodic models and can in fact accommodate finite time models in the exact same fashion as the Follmer drift is used for sampling (Section C.3) by using a Doob's transform (Rogers and Williams, 2000) based SDE for \(\overrightarrow{\mathbb{P}}^{\mu,a}\) as opposed to the classical VP-SDE see Example 2.4 in Ye et al. (2022).

### Score-based sampling

Consider the setting when \(\nu(\mathbf{z})\) is a target distribution that can be evaluated pointwise up to a normalisation constant. In order to construct a diffusion process that transports an appropriate auxiliary distribution \(\mu(\mathbf{x})\) to \(\nu(\mathbf{z})\), one approach is to fix a drift \(b_{t}\) in the backward diffusion (12b), and then learn the corresponding forward diffusion (12a) by minimising \(a\mapsto D(\overrightarrow{\mathbb{P}}^{\mu,a}\big{\|}\overleftarrow{\mathbb{ P}}^{\nu,b})\). Tractability of this objective requires that \(\mu:=\overrightarrow{\mathbb{P}}^{\nu,b}_{0}\) be known explicitly, at least approximately. In the following we review possible choices.

The Follmer drift.Choosing \(b_{t}(x)=x/t\), one can show using Doob's transform (Rogers & Williams, 2000, Theorem 40.3(iii)), that \(\overrightarrow{\mathbb{P}}_{0}^{\nu,b}(\mathbf{x})=\delta(\mathbf{x})\), for any terminal distribution \(\nu(\mathbf{z})\). Hence, minimising \(a\mapsto D_{\mathrm{KL}}(\overrightarrow{\mathbb{P}}^{\delta_{0},a}| \overrightarrow{\mathbb{P}}^{\nu,b})\) leads to a tractable objective. In particular consider the choice \(\Gamma_{0}=\delta_{0}\), \(\gamma^{+}=0\), corresponding to a standard Brownian motion, then it follows that \(\gamma^{-}=\frac{\pi}{t}\), \(\Gamma_{T}=\mathcal{N}(0,T\sigma^{2})\) and thus via Proposition 2.2:

\[D_{\mathrm{KL}}(\overrightarrow{\mathbb{P}}^{\delta_{0},a}| \overleftarrow{\mathbb{P}}^{\nu,b})=\mathbb{E}_{\mathbf{Y}_{\gamma}\to \overrightarrow{\mathbb{P}},n}\Bigg{[}\frac{1}{\sigma^{2}}\!\!\int_{0}^{T}\!a ^{2}(\mathbf{Y}_{t})\,\mathrm{d}t+\!\ln\!\bigg{(}\frac{\mathrm{d}\mathcal{N}(0,T \sigma^{2})}{\mathrm{d}\nu}\bigg{)}(\mathbf{Y}_{T})\Bigg{]}+\mathrm{const.}, \tag{39}\]

in accordance with (Dai Pra, 1991; Vargas et al., 2023b; Zhang & Chen, 2022). For further details, see Follmer (1984); Vargas et al. (2023b); Zhang & Chen (2022); Huang et al. (2021b). As hinted at in Appendix B, replacing \(D_{\mathrm{KL}}\) in (39) by the log-variance divergence (33) leads to an objective that directly links to BSDEs, see (Nusken & Richter, 2021, Section 3.2).

Ergodic diffusions.Vargas et al. (2023a); Berner et al. (2022) fix a backward drift \(b_{t}\) that induces an ergodic backward diffusion, so that for large \(T\), the marginal at initial time \(\overleftarrow{\mathbb{P}}_{t=0}^{\nu,b}\) is close to the corresponding invariant distribution, and in particular (almost) independent of \(\nu(\mathbf{z})\).9 Defining \(\mu:=\overleftarrow{\mathbb{P}}_{t=0}^{\nu,b}\), Vargas et al. (2023a); Berner et al. (2022) set out to minimise the denoising diffusion sampler loss \(\mathcal{L}_{\mathrm{DDS}}(f):=D_{\mathrm{KL}}(\overrightarrow{\mathbb{P}}^{ \mu,b+\sigma^{2}f}|\overleftarrow{\mathbb{P}}^{\nu,b})\). Choosing the reference process to be \(\Gamma_{0,T}=\mu\), \(\gamma^{\pm}=b\) (that is, the reference process is at stationarity, with invariant measure \(\mu(\mathbf{z})\)), direct calculation based on (14) shows that

Footnote 9: Vargas et al. (2023a) chose a (time-inhomoegenous) backward Ornstein-Uhlenbeck process, so that \(\overleftarrow{\mathbb{P}}_{t=0}^{\nu,b}\) is close to a Gaussian, but generalisations are straightforward.

\[\mathcal{L}_{\mathrm{DDS}}(f)=\mathbb{E}_{\mathbf{Y}_{\gamma}\to \overrightarrow{\mathbb{P}},n,k+2\,\prime}\Bigg{[}\sigma^{2}\!\!\int_{0}^{T}\! \!\!f^{2}(\mathbf{Y}_{t})\,\mathrm{d}t+\!\ln\!\bigg{(}\frac{\mathrm{d}\Gamma_{T}}{ \mathrm{d}\nu}\bigg{)}(\mathbf{Y}_{T})\Bigg{]}\,, \tag{40}\]

**Remark 7** (IWAE-objective).: In line with (34), we may also consider the multi-sample objective

\[\mathcal{L}_{\mathrm{DDS}}^{(K)}(f) :=D_{\mathrm{KL}}^{(K)}(\overrightarrow{\mathbb{P}}^{\mu,b+ \sigma^{2}f}|\overleftarrow{\mathbb{P}}^{\nu,b})\] \[=\mathbb{E}_{\mathbf{Y}^{1},\ldots,\mathbf{Y}^{K}i\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!where we overload notation and denote the Lebesgue densities of \(\mu\) and \(\nu\) with the same letters. In the second line we have used the conversion formula in (15), together with the fact that the forward Ito integrals are forward martingales (Kunita, 2019), and therefore have zero expectation. Comparing (40) and (42b), we notice the additional divergence term, due to the fact that the choice \(\gamma^{-}=0\) does not cancel the terms in (64). See also the discussion in Appendix C.1. 

Finally we note that whilst the work in Berner et al. (2022) focuses on exploring a VP-SDE-based approach which is ergodic, their overarching framework generalises beyond ergodic settings, notice this objective is akin to the KL expressions in Vargas (2021, Proposition 1) and Liu et al. (a, Proposition 9).

### Action matching (Neklyudov et al., 2023)

Similar to our approach in Section 3.2, Neklyudov et al. (2023) fix a curve of distributions \((\pi_{t})_{t\in[0,T]}\). In contrast to us, they assume that samples from \(\pi_{t}\) are available, for each \(t\in[0,T]\) (but scores and unnormalised densities are not). Still, we can use Framework 1\({}^{\prime}\) to rederive their objective:

Akin to the proof of Proposition 3.2, under mild conditions on \((\pi_{t})_{t\in[0,T]}\), there exists a unique vector field \(\nabla\phi_{t}^{*}\) that satisfies the Fokker-Planck equation

\[\partial_{t}\pi_{t}+\nabla\cdot(\pi_{t}\nabla\phi_{t}^{*})=\tfrac{\sigma^{2}}{ 2}\Delta\pi_{t}. \tag{43}\]

We can now use the reference process \(\overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\phi^{*}}\) (that is, \(\Gamma_{0}=\pi_{0}\), \(\gamma_{t}^{+}=\nabla\phi_{t}^{*}\), \(\Gamma_{T}=\pi_{T}\), \(\gamma_{t}^{-}=\nabla\phi_{t}^{*}-\sigma^{2}\nabla\ln\pi_{t}\)) to compute the objective

\[\psi\mapsto D_{\mathrm{KL}}(\overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\psi}| \big{\lvert}\overleftarrow{\mathbb{P}}^{\pi_{T},\nabla\psi-\sigma^{2}\nabla \ln\pi}),\]

relying on the same calculational techniques as in Sections C.2 and C.3 (the particular choice of reference process cancels the terms in (14a)). Notice that the parameterisation in this objective constrains the target diffusion to have time-marginals \(\pi_{t}\), just as in Section 3.2. By direct calculation, we obtain (up to a factor of \(2/\sigma^{2}\)) the action-gap in equation (5) in Neklyudov et al. (2023). Indeed, we see that

\[D_{\mathrm{KL}}(\overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\psi} |\big{\lvert}\overleftarrow{\mathbb{P}}^{\pi_{T},\nabla\psi-\sigma^{2}\nabla \ln\pi})=\mathbb{E}_{\overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\psi}}\left[ \ln\left(\frac{\mathrm{d}\overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\psi}}{ \mathrm{d}\overrightarrow{\mathbb{P}}^{\nabla\psi-\sigma^{2}\nabla\ln\pi}} \right)\right]\] \[=\mathbb{E}\left[\tfrac{1}{\sigma^{2}}\int_{0}^{T}\left(\nabla \psi_{t}-\nabla\phi_{t}^{*}\right)^{2}\left(\mathbf{Y}_{t}\right)\mathrm{d}t- \tfrac{1}{\sigma}\int_{0}^{T}(\nabla\psi_{t}-\nabla\phi_{t}^{*})(\mathbf{Y}_ {t})\cdot\overleftarrow{\mathrm{d}}\mathbf{W}_{t}\right.\] \[\qquad\qquad-\left.\int_{0}^{T}\nabla\ln\pi_{t}(\mathbf{Y}_{t}) \cdot(\nabla\psi_{t}-\nabla\phi_{t}^{*})(\mathbf{Y}_{t})\,\mathrm{d}t\right]\] \[=\mathbb{E}\left[\tfrac{1}{\sigma^{2}}\int_{0}^{T}\left(\nabla \psi_{t}-\nabla\phi_{t}^{*}\right)^{2}\left(\mathbf{Y}_{t}\right)\mathrm{d}t \right],\]

where in the last line we have used the conversion formula (15) together with (30a) to compute

\[\mathbb{E}\left[\tfrac{1}{\sigma}\int_{0}^{T}(\nabla\psi_{t}- \nabla\phi_{t}^{*})(\mathbf{Y}_{t})\cdot\overleftarrow{\mathrm{d}}\mathbf{W}_ {t}\right] =\mathbb{E}\left[\int_{0}^{T}(\nabla\cdot(\nabla\psi_{t}-\nabla \phi_{t}^{*}))(\mathbf{Y}_{t})\,\mathrm{d}t\right]\] \[=\int_{0}^{T}\int_{\mathbb{R}^{4}}(\nabla\cdot(\nabla\psi_{t}- \nabla\phi_{t}^{*}))(\mathbf{x})\pi_{t}(\mathrm{d}\mathbf{x})\,\mathrm{d}t =-\int_{0}^{T}\int_{\mathbb{R}^{4}}(\nabla\psi_{t}-\nabla\phi_{t }^{*})(\mathbf{x})\cdot\nabla\ln\pi_{t}(\mathbf{x})\pi_{t}(\mathrm{d}\mathbf{ x})\,\mathrm{d}t\] \[=\mathbb{E}\left[\int_{0}^{T}\nabla\ln\pi_{t}(\mathbf{Y}_{t}) \cdot(\nabla\psi_{t}-\nabla\phi_{t}^{*})(\mathbf{Y}_{t})\,\mathrm{d}t\right]\]

and cancel the two last terms in the penultimate line.

## Appendix D Controlled Monte Carlo Diffusions (Section 3.2)

### Derivation of \(\mathcal{L}^{\mathrm{CMCD}}_{D_{\mathrm{KL}}}\)

The proof uses Proposition 2.2, choosing \(\Gamma_{0}=\Gamma_{T}\) to be the Lebesgue measure, with \(\gamma^{+}=\gamma^{-}=0\) (but notice that \(\sigma\) in (14) needs to be replaced by \(\sigma\sqrt{2}\) due to the scaling in (21)). We compute

\[\mathcal{L}^{\mathrm{CMCD}}_{D_{\mathrm{KL}}}(\phi)=\mathbb{E}_{ \boldsymbol{Y}\sim\overline{\mathbb{P}}\,\pi_{0},\sigma^{2}\nabla\ln\pi+\nabla \phi}\left[\ln\left(\frac{\mathrm{d}\,\overline{\mathbb{P}}\,\pi_{0},\sigma^{2} \nabla\ln\pi+\nabla\phi}{\mathrm{d}\,\overline{\mathbb{P}}\,\pi_{T},-\sigma^{2} \nabla\ln\pi+\nabla\phi}\right)(\boldsymbol{Y})\right]\] \[= \mathbb{E}\left[\ln\pi_{0}(\boldsymbol{Y}_{0})-\ln\pi_{T}( \boldsymbol{Y}_{T})\right]\] \[+\mathbb{E}\left[\tfrac{1}{2\sigma^{2}}\int_{0}^{T}(\sigma^{2} \nabla\ln\pi_{t}+\nabla\phi_{t})(\boldsymbol{Y}_{t})\cdot\left(\overline{ \mathrm{d}}\,\boldsymbol{Y}_{t}-\tfrac{1}{2}(\sigma^{2}\nabla\ln\pi_{t}+ \nabla\phi_{t})(\boldsymbol{Y}_{t})\,\mathrm{d}t\right)\right]\] \[-\mathbb{E}\left[\tfrac{1}{2\sigma^{2}}\int_{0}^{T}(-\sigma^{2} \nabla\ln\pi_{t}+\nabla\phi_{t})(\boldsymbol{Y}_{t})\cdot\left(\overleftarrow{ \mathrm{d}}\,\boldsymbol{Y}_{t}-\tfrac{1}{2}(-\sigma^{2}\nabla\ln\pi_{t}+ \nabla\phi_{t})(\boldsymbol{Y}_{t})\,\mathrm{d}t\right)\right]\] \[= \mathbb{E}\left[\ln\pi_{0}(\boldsymbol{Y}_{0})-\ln\pi_{T}( \boldsymbol{Y}_{T})\right]\] \[+\mathbb{E}\left[\tfrac{1}{2\sigma^{2}}\int_{0}^{T}(\sigma^{2} \nabla\ln\pi_{t}+\nabla\phi_{t})(\boldsymbol{Y}_{t})\cdot\overrightarrow{ \mathrm{d}}\boldsymbol{Y}_{t}\right]-\mathbb{E}\left[\tfrac{1}{2\sigma^{2}} \int_{0}^{T}(-\sigma^{2}\nabla\ln\pi_{t}+\nabla\phi_{t})(\boldsymbol{Y}_{t}) \cdot\overleftarrow{\mathrm{d}}\,\boldsymbol{Y}_{t}\right]\] \[-\tfrac{1}{\sigma^{2}}\mathbb{E}\left[\int_{0}^{T}(\sigma^{2} \nabla\ln\pi_{t}\cdot\nabla\phi_{t})(\boldsymbol{Y}_{t})\,\mathrm{d}t\right]\] \[= \mathbb{E}\left[\ln\pi_{0}(\boldsymbol{Y}_{0})-\ln\pi_{T}( \boldsymbol{Y}_{T})\right]\] \[+\mathbb{E}\left[\sigma^{2}\int_{0}^{T}|\nabla\ln\pi_{t}( \boldsymbol{Y}_{t})|^{2}\mathrm{d}t+\tfrac{1}{\sigma\sqrt{2}}\int_{0}^{T} \left(\sigma^{2}\nabla\ln\pi_{t}-\nabla\phi_{t}\right)(\boldsymbol{Y}_{t}) \cdot\overleftarrow{\mathrm{d}}\,\boldsymbol{W}_{t}\right],\]

where in the last equality we have inserted the dynamics (21) and used the martingale property (30a). Notice that the expectation of the backward integral is not zero, see Appendix A.

### Derivation of \(\mathcal{L}^{\mathrm{CMCD}}_{\mathrm{Var}}\)

In this section, we first verify the expression for \(\mathcal{L}^{\mathrm{CMCD}}_{\mathrm{Var}}\) in Section 3.2, using Proposition 2.2, and choosing \(\Gamma_{0}=\Gamma_{T}\) to be the Lebesgue measure, \(\gamma^{+}=\gamma^{-}=0\). We recall that although the Lebesgue measure in not normalisable, the arguments can be made rigorous using the techniques in Leonard (2014a, Appendix A).

The Radon-Nikodym derivative (RND) along (21) reads

\[\left(\ln\frac{\mathrm{d}\,\overline{\mathbb{P}}\,\pi_{0},\sigma ^{2}\nabla\ln\pi+\nabla\phi}{\mathrm{d}\,\overline{\mathbb{P}}\,\pi_{T},- \sigma^{2}\nabla\ln\pi+\nabla\phi}\right)(\boldsymbol{Y})=(\ln\pi_{0})( \boldsymbol{Y}_{0})-(\ln\pi_{T})(\boldsymbol{Y}_{T})\] \[+\tfrac{1}{2\sigma^{2}}\!\int_{0}^{T}\!\!\!\!\left(\sigma^{2} \nabla\ln\pi_{t}\!+\!\nabla\phi_{t})(\boldsymbol{Y}_{t})\!\left(\!\!\!\left( \sigma^{2}\nabla\!\ln\pi_{t}\!+\!\nabla\phi_{t})(\boldsymbol{Y}_{t})\, \mathrm{d}t\!+\!\sqrt{2}\sigma\overrightarrow{d}\boldsymbol{W}_{t}\!-\!\tfrac {1}{2}(\sigma^{2}\nabla\!\ln\pi_{t}\!+\!\nabla\phi_{t})(\boldsymbol{Y}_{t})\, \mathrm{d}t\!\right)\] \[-\tfrac{1}{2\sigma^{2}}\!\!\int_{0}^{T}\!\!\!\!\!\left(\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!Using (29b), we obtain

\[\tfrac{\sigma}{\sqrt{2}}\left(\int_{0}^{T}\nabla\ln\pi_{t}(\mathbf{Y}_{t})\cdot \overrightarrow{\mathrm{d}}\mathbf{W}_{t}+\int_{0}^{T}\nabla\ln\pi_{t}(\mathbf{Y}_{t}) \cdot\overleftarrow{\mathrm{d}}\mathbf{W}_{t}\right)=\sqrt{2}\sigma\int_{0}^{T} \nabla\ln\pi_{t}(\mathbf{Y}_{t})\circ\mathrm{d}\mathbf{W}_{t}.\]

Furthermore, from (15) we see that

\[\tfrac{1}{\sigma\sqrt{2}}\left(\int_{0}^{T}\nabla\phi(\mathbf{Y}_{t})\cdot \overrightarrow{\mathrm{d}}\mathbf{W}_{t}-\int_{0}^{T}\nabla\phi(\mathbf{Y}_{t})\cdot \overleftarrow{\mathrm{d}}\mathbf{W}_{t}\right)=-\int_{0}^{T}\Delta\phi_{t}(\mathbf{Y }_{t})\,\mathrm{d}t, \tag{47}\]

from which the claim follows.

**Remark 8** (Estimating \(\mathcal{L}^{\mathrm{CMCD}}_{\mathrm{Var}}\) without second derivatives).: Using (47), we can equivalently write the RND as

\[\left(\ln\frac{\mathrm{d}\overrightarrow{\mathbb{P}}_{\pi_{0}, \sigma^{2}\nabla\ln\pi+\nabla\phi}}{\mathrm{d}\overrightarrow{\mathbb{P}}_{\pi _{T},-\sigma^{2}\nabla\ln\pi+\nabla\phi}}\right)(\mathbf{Y})=\ln\pi_{T}(\mathbf{Y}_{T} )-\ln\pi_{0}(\mathbf{Y}_{0})\] \[-\tfrac{1}{\sigma\sqrt{2}}\left(\int_{0}^{T}\nabla\phi(\mathbf{Y}_{t })\cdot\overrightarrow{\mathrm{d}}\mathbf{W}_{t}-\int_{0}^{T}\nabla\phi(\mathbf{Y}_{t })\cdot\overleftarrow{\mathrm{d}}\mathbf{W}_{t}\right)\] \[-\sigma\sqrt{2}\!\int_{0}^{T}\!\!\!\nabla\ln\pi_{t}(\mathbf{Y}_{t}) \circ\!\mathrm{d}\mathbf{W}_{t}\!-\sigma^{2}\!\!\int_{0}^{T}\!\!\!|\nabla\ln\pi_{t} (\mathbf{Y}_{t})|^{2}\,\mathrm{d}t,\]

so that \(\mathcal{L}^{\mathrm{CMCD}}_{\mathrm{Var}}\) can be estimated without the need to evaluate \(\Delta\phi\). Note that the identity (47) is similar to a finite difference approximation of \(\Delta\phi\) along the process \(\mathbf{Y}_{t}\).

### Existence and uniqueness of the drift

Before proceeding to the proof of Proposition 3.2, we state the following assumption on the curve of distributions \((\pi_{t})_{t\in[0,T]}\):

**Assumption D.1**.: Assume that \(\pi\in C^{\infty}([0,T]\times\mathbb{R}^{d};\mathbb{R})\), and that for all \(t\in[0,T]\)

1. the time derivative \(\partial_{t}\pi_{t}\) is square-integrable, that is, \(\partial_{t}\pi_{t}(t,\cdot)\in L^{2}(\mathbb{R}^{d})\),
2. \(\pi_{t}\) satisfies a Poincare inequality, that is, there exists a constant \(C_{t}>0\) such that \[\mathrm{Var}_{\pi_{t}}(f)\leq C_{t}\int_{\mathbb{R}^{d}}|\nabla f|^{2}\mathrm{ d}\pi_{t},\] (49) for all \(f\in C_{b}^{1}(\mathbb{R}^{d})\).

Note that at the boundary \(\partial[0,T]=\{0,T\}\), we agree to denote by \(\partial_{t}\pi_{t}\) the 'inward-pointing derivative' and interpret \(\hat{C}^{\infty}([0,T]\times\mathbb{R}^{d};\mathbb{R})\) in that way. We remark that the Poincare inequality (49) is satisfied under relatively mild conditions on the tails of \(\pi_{t}\) (for instance, Gaussian tails) and control of its derivatives, see, e.g., Bakry et al. (2014, Chapter 4). Under Assumption D.1, we can prove Proposition 3.2 as follows:

Proof of Proposition 3.2.: The Fokker-Planck equation associated to (21) is given by

\[\partial_{t}\pi_{t}+\nabla\cdot(\pi_{t}\nabla\phi_{t})=0. \tag{50}\]

The operator \(\phi\mapsto-\nabla\cdot(\pi_{t}\nabla\phi)\) is essentially self-adjoint in \(L^{2}(\mathbb{R}^{d})\), and, by (49) coercive on \(L^{2}_{0}(\mathbb{R}^{d}):=\{f\in L^{2}(\mathbb{R}^{d}):\ \int f\mathrm{d}x=0\}\). Therefore, there exists a unique solution \(\phi_{t}^{*}\in L^{2}_{0}(\mathbb{R}^{d})\) to (50), for any \(t\in[0,T]\). This solution is smooth by elliptic regularity. By Proposition 2.1 and our general framework, any minimiser \(\widetilde{\phi}\) of (22) necessarily satisfies (50) as well. We then obtain

\[\nabla\cdot(\pi_{t}\nabla(\phi_{t}-\widetilde{\phi}_{t}))=0.\]

Multiplying this equation by \(\phi_{t}-\widetilde{\phi}_{t}\), integrating, and integrating by parts shows that \(\int\|\nabla(\phi-\widetilde{\phi})\|^{2}\,\mathrm{d}\pi_{t}=0\), proving the claim.

**Remark 9** (Relation to previous work).: Note we can carry out a change of variables to equation (50),

\[\partial_{t}\ln\pi_{t}=-\pi_{t}^{-1}(\nabla\pi_{t}\cdot\nabla\phi_{t}+\pi_{t} \Delta\phi)=-\nabla\ln\pi_{t}\cdot\nabla\phi-\Delta\phi,\]

yielding the PDE

\[\partial_{t}\ln\pi_{t}+\nabla\ln\pi_{t}\cdot\nabla\phi+\Delta\phi=0,\]

which when considered in terms of the unnormalised flow \(\hat{\pi}_{t}=Z_{t}\pi_{t}\) coincides with PDE in Vaikuntanathan & Jarzynski (2008); Arbel et al. (2021):

\[\partial_{t}\ln\hat{\pi}_{t}+\nabla\ln\hat{\pi}_{t}\cdot\nabla\phi+\Delta\phi- \mathbb{E}_{\pi_{t}}[\partial_{t}\ln\hat{\pi}_{t}]=0.\]

In particular, we note that the Markov chain proposed in Arbel et al. (2021) converges to our proposed parameterisation in equation (21) (see equation (12) in Arbel et al. (2021)).

### Infinitesimal Schrodinger bridges (proof of Proposition 3.4)

Throughout this proof, we assume that the Schrodinger problems on the intervals \([iT/N,(i+1)T/N]\), \(i=0,\ldots,N-1\) admit unique solutions, with drifts of regularity specified in Assumption A.1, see (Leonard, 2014a, Proposition 2.5) for sufficient conditions. We also work under Assumption D.1, so that the drift \(\nabla\phi^{*}\) exists and is unique by Proposition 3.2.

Given the interpolation \((\pi_{t})_{t\in[0,T]}\), we define the constraint sets

\[\mathcal{M}^{N}(\pi):=\Bigg{\{}a\in\mathcal{U}^{N}:\quad\overrightarrow{\mathbb{ P}}_{t_{i}}^{\pi_{0},\nabla\ln\pi+a}=\pi_{t_{i}}\quad\text{ at times }\quad t_{i}=\frac{iT}{N},\quad i=0,\ldots,N\Bigg{\}}, \tag{51}\]

as well as

\[\mathcal{M}^{\infty}(\pi):=\Bigg{\{}a\in\mathcal{U}:\quad\overrightarrow{ \mathbb{P}}_{t}^{\pi_{0},\nabla\ln\pi+a}=\pi_{t}\quad\text{for all }\quad t\in[0,T]\Bigg{\}}.\] (52a) In ( 51 ), the set \[\mathcal{U}^{N}\] is given by \[\mathcal{U}^{N}:=\Bigg{\{}a\in C([0,T]\times\mathbb{R}^{d};\mathbb{R}^{d}): \quad a\in C^{\infty}([\frac{iT}{N},\frac{(i+1)T}{N}]\times\mathbb{R}^{d}; \mathbb{R}^{d}),\quad\text{for all }i=0,\ldots,N-1,\] \[\exists L>0\text{ such that }\|a_{t}(\mathbf{x})-a_{t}(\mathbf{y})\|\leq L\|\mathbf{x}-\mathbf{y}\|,\,\text{for all }t\in[0,T],\ \mathbf{x},\mathbf{y}\in\mathbb{R}^{d}\Bigg{\}},\] and we recall that \[\mathcal{U}\] has been defined in Assumption A.1.

By the construction in Proposition 3.4, the drift \(\nabla\phi^{(N)}\) can be characterised by

\[\nabla\phi^{(N)} \in\operatorname*{arg\,min}_{a\in\mathcal{M}^{N}(\pi)}\mathbb{E}_{\bm {Y}\sim\overrightarrow{\mathbb{P}}_{\pi_{0}},\nabla\ln\pi+a}\Bigg{[}\frac{1}{ 2\sigma^{2}}\int_{0}^{T}\|a_{t}(\mathbf{Y})\|^{2}\,\mathrm{d}t\Bigg{]} \tag{54a}\] \[=\operatorname*{arg\,min}_{a\in\mathcal{M}^{N}(\pi)}D_{\mathrm{KL }}(\overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\ln\pi+a}\big{[}\overrightarrow{ \mathbb{P}}^{\pi_{0},\nabla\ln\pi}), \tag{54b}\]

where the second line follows from Girsanov's theorem, see the proof of Proposition 2.2.

We now claim that the CMCD drift \(\nabla\phi^{*}\), by definition the minimiser in (22), can be characterised in a similar way by

\[\nabla\phi^{*} \in\operatorname*{arg\,min}_{a\in\mathcal{M}^{N}(\pi)}\mathbb{E}_{ \mathbf{Y}\sim\overrightarrow{\mathbb{P}}_{\pi_{0}},\nabla\ln\pi+a}\Bigg{[}\frac{ 1}{2\sigma^{2}}\int_{0}^{T}\|a_{t}(\mathbf{Y})\|^{2}\,\mathrm{d}t\Bigg{]} \tag{55a}\] \[=\operatorname*{arg\,min}_{a\in\mathcal{M}^{N}(\pi)}D_{\mathrm{KL }}(\overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\ln\pi+a}|\overrightarrow{ \mathbb{P}}^{\pi_{0},\nabla\ln\pi}). \tag{55b}\]

Indeed, the constraint \(\overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\ln\pi+a}=\pi_{t}\) for all \(t\in[0,T]\) implies that \(a\) satisfies the Fokker-Planck equation \(\partial_{t}\pi_{t}+\nabla\cdot(\pi_{t}a_{t})=0\). By the Helmholtz decomposition (Figalli & Glaudo, 2021, Section 2.5.4), minimisers of \(a_{t}\mapsto\int a_{t}^{2}\mathrm{d}\pi_{t}\) are of gradient form, thus (55a) holds.

Comparing (54) and (55a), it is plausible to infer the convergence \(\nabla\phi^{(N)}\to\nabla\phi^{*}\), as the marginal constraints at the discrete time points \(0,1/T,2/T,...,T\) become dense and approach the continuous-time constraint in (52).

To make this more precise, we note that since \(\mathcal{M}^{\infty}(\pi)\subset\mathcal{M}^{N}(\pi)\) for all \(N\in\mathbb{N}\), we have that

\[D_{\mathrm{KL}}(\overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\ln\pi+\nabla\phi^{( N)}}|\overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\ln\pi})\leq D_{\mathrm{KL}}( \overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\ln\pi+\nabla\phi^{*}}| \overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\ln\pi}), \tag{56}\]

for all \(N\in\mathbb{N}\). Since \(D_{\mathrm{KL}}(\cdot|\overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\ln\pi})\) has weakly compact sublevel sets (Dupuis & Ellis, 2011, Lemma 1.4.3), we can extract a subsequence \(\overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\ln\pi+\nabla\phi^{(N_{k})}}\) that converges weakly towards a path measure \(\widetilde{\mathbb{P}}\in\mathcal{P}(C([0,T];\mathbb{R}^{d}))\). To show that indeed \(\widetilde{\mathbb{P}}=\overrightarrow{\mathbb{P}}^{\pi_{0},\nabla\ln\pi+ \nabla\phi^{*}}\), it is sufficient to note that by the constraints in (51) those measures necessarily have the same finite-dimensional marginals, and to combine this observation with the continuity statement of Theorem 2.7.3 in Billingsley (2013), as well as the uniqueness from Proposition 3.2. The convergence of the drifts in the sense of \(L^{2}([0,T]\times\mathbb{R}^{d};\mathbb{R}^{d})\) now follows from the lower semicontinuity of \(D_{\mathrm{KL}}\) in combination with Girsanov's theorem.

### Discretisation and Objective

In the setting of CMCD with KL divergence we can use the EM approximations to the RND presented in Proposition E.1 to express the objective as:

\[\mathcal{L}^{\mathrm{CMCD}}_{D_{\mathrm{KL}}}(\phi)\!\approx\! \mathbb{E}\!\left[\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!

#### d.6.1 Time Discretisation and Objective

To discretise the above processes we follow the exact same discretisation scheme carried out in Geffner and Domke (2023), however in this case we have to adapt the forward discretisation scheme to include the non-linear drift when carrying out the momentum re-sample step, specific details for this scheme can be found in Algorithms 3 and 4. This discretisation in turn allows us to compute the discrete RND between these two processes which we require for Framework 1\({}^{\prime}\).

Now via Propostion 1 in (Geffner and Domke, 2023) it follows that

\[\frac{\pi_{0}(\mathbf{Y}_{0},\mathbf{Z}_{0})}{\pi_{T}(\mathbf{Y}_{T},\mathbf{Z}_{ T})}\prod_{k=0}^{K-1}\frac{F_{t_{k}}(\mathbf{Z}_{t_{k+1}},\mathbf{Y}_{t_{k+1}}|\mathbf{Z}_{t_{ k}},\mathbf{Y}_{t_{k}})}{B_{t_{k}}(\mathbf{Z}_{t_{k}},\mathbf{Y}_{t_{k}}|\mathbf{Z}_{t_{k+1}}, \mathbf{Y}_{t_{k+1}})}\] \[=\frac{\pi_{0}(\mathbf{Y}_{0},\mathbf{Z}_{0})}{\pi_{T}(\mathbf{Y}_{T},\mathbf{Z}_{ T})}\prod_{k=0}^{K-1}\frac{\mathcal{N}\left(\mathbf{Y}_{t_{k}}^{\prime}\mid\mathbf{Y}_{t_{ k}}(1-\sigma\Delta t_{k})+\nabla\phi_{t_{k}}(\mathbf{Y}_{t_{k}},\mathbf{Z}_{t_{k}}) \Delta t_{k},2\sigma\Delta t_{k}I\right)}{\mathcal{N}\left(\mathbf{Y}_{t_{k}}\mid \mathbf{Y}_{t_{k}}^{\prime}(1-\sigma\Delta t_{k})-\nabla\phi_{t_{k}}(\mathbf{Y}_{t_{k} }^{\prime},\mathbf{Z}_{t_{k}})\Delta t_{k},2\sigma\Delta t_{k}I\right)} \tag{61}\]

then we can use the above discrete time RND to approximate the KL divergence between SDEs (59) and (60) yielding our objective for the under dampened setting:

\[\mathcal{L}_{D_{\text{KL}}}^{\text{CMCD-UD}}(\!\phi\!)\!\approx\!\mathbb{E} \left[\!\ln\!\frac{\pi_{0}(\mathbf{Y}_{0},\mathbf{Z}_{0})}{\pi_{T}(\mathbf{Y}_{T},\mathbf{Z}_ {T})}\!\!\prod_{k=0}^{K-1}\!\frac{\mathcal{N}\left(\mathbf{Y}_{t_{k}}^{\prime}|\mathbf{ Y}_{t_{k}}(1-\sigma\Delta t_{k})+\nabla\phi_{t_{k}}(\mathbf{Y}_{t_{k}},\mathbf{Z}_{t_{k}}) \Delta t_{k},2\sigma\Delta t_{k}I\right)}{\mathcal{N}\left(\mathbf{Y}_{t_{k}}|\mathbf{ Y}_{t_{k}}^{\prime}(1-\sigma\Delta t_{k})-\nabla\phi_{t_{k}}(\mathbf{Y}_{t_{k}}^{ \prime},\mathbf{Z}_{t_{k}})\Delta t_{k},2\sigma\Delta t_{k}I\right)}\!\right] \tag{62}\]

Where the expectation is taken with respect to the discrete-time process in Algorithm 3.

``` \(\mathbf{Z}_{t_{k+1}},\mathbf{Y}_{t_{k+1}}\), step-size \(\Delta t_{k}\) \(\mathbf{Z}_{t_{k+1}},\mathbf{Y}_{t_{k+1}}\), step-size \(\Delta t_{k}\) \(\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}-\Delta t_{k}\mathbf{Y}_{t_{k}}^{\prime\prime}\) \(\mathbf{Z}_{t_{k+1}}=\mathbf{Y}_{t_{k+1}}^{\prime\prime}+\frac{\Delta t_{k}}{2}\nabla \ln\pi_{t_{k}}(\mathbf{Z}_{t_{k+1}})\) \(\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}+\Delta t_{k}\mathbf{Y}_{t_{k}}^{\prime\prime}\) \(\mathbf{Z}_{t_{k+1}}=\mathbf{Y}_{t_{k}}^{\prime\prime}+\frac{\Delta t_{k}}{2}\nabla \ln\pi_{t_{k}}(\mathbf{Z}_{t_{k+1}})\) \(\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{ k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{ k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{ k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k +1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_ {t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1 }}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{ k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}= \mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{k+1}}=\mathbf{Z}_{t_{introduce the time-reversal operator \(\mathcal{R}\), acting as \((\mathcal{R}\mathbf{Y})_{t}:=\mathbf{Y}_{T-t}\) on paths10, and as \((\mathcal{R}a)_{t}(\mathbf{y}):=a_{T-t}(\mathbf{y})\) on vector fields. We then observe that

Footnote 10: Although pathwise definitions should be treated with care (because Ito integrals are defined only up to a set of measure zero), the arguments can be made rigorous using the machinery referred to in Appendix A.

\[\ln\left(\frac{\mathrm{d}\overrightarrow{\mathbb{P}}\mu,\mathcal{R}a}{\mathrm{d }\overrightarrow{\mathbb{P}}\nu,\mathcal{R}b}\right)(\mathcal{R}\mathbf{Y})=\ln \left(\frac{\mathrm{d}\overrightarrow{\mathbb{P}}\mu,a}{\mathrm{d} \overrightarrow{\mathbb{P}}\nu,b}\right)(\mathbf{Y}),\]

for instance by comparing the discrete-time processes in (9a) and (9b). Equivalently,

\[\ln\left(\frac{\mathrm{d}\overleftarrow{\mathbb{P}}\mu,a}{\mathrm{d} \overrightarrow{\mathbb{P}}\nu,b}\right)(\mathbf{Y})=\ln\left(\frac{\mathrm{d} \overrightarrow{\mathbb{P}}\mu,\mathcal{R}a}{\mathrm{d}\overrightarrow{ \mathbb{P}}\nu,\mathcal{R}b}\right)(\mathcal{R}\mathbf{Y}),\]

since \(\mathcal{R}^{2}\) is the identity. Building on (63), the backward Radon-Nikodym derivative therefore reads

\[\ln\left(\frac{\mathrm{d}\overleftarrow{\mathbb{P}}\nu,b}{ \mathrm{d}\overrightarrow{\mathbb{P}}\nu,b}\right)(\mathbf{Y}) =\ln\left(\frac{\mathrm{d}\mu}{\mathrm{d}\nu}\right)((\mathcal{R }\mathbf{Y})_{0})+\tfrac{1}{\sigma^{2}}\int_{0}^{T}((\mathcal{R}a)_{t}-(\mathcal{R }b)_{t})(\mathcal{R}\mathbf{Y}_{t})\cdot\overrightarrow{\mathrm{d}}(\mathcal{R}\bm {Y})_{t}\] \[+\tfrac{1}{2\sigma^{2}}\int_{0}^{T}\left((\mathcal{R}b)_{t}^{2}-( \mathcal{R}a)_{t}^{2}\right)((\mathcal{R}\mathbf{Y})_{t})\,\mathrm{d}t,\] \[=\ln\left(\frac{\mathrm{d}\mu}{\mathrm{d}\nu}\right)(\mathbf{Y}_{T})+ \tfrac{1}{\sigma^{2}}\int_{0}^{T}(a_{t}-b_{t})(\mathbf{Y}_{t})\cdot\overleftarrow{ \mathrm{d}}\mathbf{Y}_{t}+\tfrac{1}{2\sigma^{2}}\int_{0}^{T}\left(b_{t}^{2}-a_{t} ^{2}\right)(\mathbf{Y}_{t})\,\mathrm{d}t, \tag{64}\]

where the integrals have been transformed using the substitution \(t\mapsto T-t\). The result in (14) now follows by writing

\[\ln\left(\frac{\mathrm{d}\overrightarrow{\mathbb{P}}\mu,a}{\mathrm{d} \overrightarrow{\mathbb{P}}\nu,b}\right)(\mathbf{Y})=\ln\left(\frac{\mathrm{d} \overrightarrow{\mathbb{P}}\mu,a}{\mathrm{d}\overrightarrow{\mathbb{P}}\Gamma _{0},\gamma^{+}}\right)(\mathbf{Y})+\ln\left(\frac{\mathrm{d}\overleftarrow{ \mathbb{P}}\Gamma_{T},\gamma^{-}}{\mathrm{d}\overrightarrow{\mathbb{P}}\nu,b} \right)(\mathbf{Y}),\]

using the assumption \(\overrightarrow{\mathbb{P}}\Gamma_{0},\gamma^{+}=\overleftarrow{\mathbb{P}} \Gamma_{T},\gamma^{-}\), and inserting (63) as well as (64). 

#### e.1.1 Discretisation and connection to DNFs (diffusion normalising flows)

In this section we derive the main discretisation formula used in our implementations for the forward-backwards Radon-Nikodym derivative (RND).

**Proposition E.1**.: _Letting \(\Gamma_{0}=\Gamma_{T}=\mathrm{Leb}\) and \(\gamma^{\pm}=0\), we have that the RND in (14) is given by_

\[\ln\left(\frac{\mathrm{d}\overrightarrow{\mathbb{P}}\mu,a}{ \mathrm{d}\overrightarrow{\mathbb{P}}\nu,b}\right)(\mathbf{Y}) =\ln\mu(\mathbf{Y}_{0})-\ln\nu(\mathbf{Y}_{T})+\tfrac{1}{\sigma^{2}}\int _{0}^{T}a_{t}(\mathbf{Y}_{t})\cdot\overrightarrow{\mathrm{d}}\mathbf{Y}_{t}-\tfrac{1 }{2\sigma^{2}}\int_{0}^{T}\lvert\lvert a_{t}(\mathbf{Y}_{t})\rvert\rvert^{2}\, \mathrm{d}t\] \[-\tfrac{1}{\sigma^{2}}\int_{0}^{T}b_{t}(\mathbf{Y}_{t})\cdot \overleftarrow{\mathrm{d}}\mathbf{Y}_{t}+\tfrac{1}{2\sigma^{2}}\int_{0}^{T}\lvert \lvert b_{t}(\mathbf{Y}_{t})\rvert\rvert^{2}\,\mathrm{d}t,\qquad\overrightarrow{ \mathbb{P}}\mu,a\text{-almost surely,}\]

_and admits the following discrete-time approximation up to constant terms in \(a_{t}\) and \(b_{t}\) (following Remark 3),_

\[\ln\left(\frac{\widehat{\mathrm{d}\overrightarrow{\mathbb{P}}\mu,a}}{ \mathrm{d}\overrightarrow{\mathbb{P}}\nu,b}\right)(\!\mathbf{Y})\!=\!\!-\!\ln\nu( \mathbf{Y}_{T})\!+\!\!\sum_{i=0}^{K-1}\!\!\!\frac{1}{2\sigma^{2}(t_{i+1}-t_{i+1}) }\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!From here on, we will use the notation \(f_{t_{i}}=f_{t_{i}}(\mathbf{Y}_{t_{i}})\) for brevity. Following Remark 3 we have that

\[\ln\left(\frac{\mathrm{d}\overrightarrow{\mathbb{P}}_{\mu,a}}{ \mathrm{d}\overrightarrow{\mathbb{P}}_{\nu,b}}\right)(\mathbf{Y}) \approx\ln\mu(\mathbf{Y}_{0})-\ln\nu(\mathbf{Y}_{T})\] \[+\frac{1}{\sigma^{2}}\sum_{i=0}^{K-1}a_{t_{i}}\cdot(\mathbf{Y}_{t_{i+1 }}-\mathbf{Y}_{t_{i}})-\frac{1}{2\sigma^{2}}\sum_{i=0}^{K-1}||a_{t_{i}}||^{2}\,(t_ {i+1}-t_{i})\] \[-\frac{1}{\sigma^{2}}\sum_{i=0}^{K-1}b_{t_{i+1}}\cdot(\mathbf{Y}_{t_{i +1}}-\mathbf{Y}_{t_{i}})+\frac{1}{2\sigma^{2}}\sum_{i=0}^{K-1}||b_{t_{i+1}}||^{2} \,(t_{i+1}-t_{i}).\]

Adding and subtracting \(||\mathbf{Y}_{t_{i+1}}-\mathbf{Y}_{t_{i}}||^{2}/(\sigma^{2}(t_{i+1}-t_{i}))\) allows us to complete the square in each sum, resulting in:

\[\ln\left(\frac{\mathrm{d}\overrightarrow{\mathbb{P}}_{\mu,a}}{ \mathrm{d}\overrightarrow{\mathbb{P}}_{\nu,b}}\right)(\mathbf{Y}) \approx\ln\mu(\mathbf{Y}_{0})-\ln\nu(\mathbf{Y}_{T})-\sum_{i=0}^{K-1} \frac{1}{2\sigma^{2}(t_{i+1}-t_{i})}||\mathbf{Y}_{t_{i+1}}-\mathbf{Y}_{t_{i}}-a_{t_{i}} (t_{i+1}-t_{i})||^{2}\] \[+\sum_{i=0}^{K-1}\frac{1}{2\sigma^{2}(t_{i+1}-t_{i})}||\mathbf{Y}_{t_{ i}}-\mathbf{Y}_{t_{i+1}}+b_{t_{i+1}}(t_{i+1}-t_{i})||^{2}. \tag{67}\]

Now notice that under the Euler-Maruyama discretisation \(||\mathbf{Y}_{t_{i+1}}-\mathbf{Y}_{t_{i}}-a_{t_{i}}(t_{i+1}-t_{i})||^{2}=(t_{i+1}-t_{i })\sigma^{2}||\xi||^{2}\) where \(\xi\sim\mathcal{N}(0,I)\) does not depend on \(a_{t}\) or \(b_{t}\); in particular when using \(D_{\mathrm{KL}}\) for the divergence we have that \(\mathbb{E}_{\overrightarrow{\mathbb{P}}_{\mathrm{EM}}^{\mu,a}}||\mathbf{Y}_{t_{i+ 1}}-\mathbf{Y}_{t_{i}}-a_{t_{i}}(t_{i+1}-t_{i})||^{2}=\sigma^{2}\) and thus:

\[\ln\left(\frac{\widehat{\mathrm{d}\overrightarrow{\mathbb{P}}_{ \mu,a}}}{\mathrm{d}\overrightarrow{\mathbb{P}}_{\nu,b}}\right)(\mathbf{Y})\propto \ln\mu(\mathbf{Y}_{0})-\ln\nu(\mathbf{Y}_{T})+\sum_{i=0}^{K-1}\frac{1}{2\sigma^{2}(t_{i +1}-t_{i})}||\mathbf{Y}_{t_{i}}-\mathbf{Y}_{t_{i+1}}+b_{t_{i+1}}(t_{i+1}-t_{i})||^{2}. \tag{68}\]

Notice that in expectation (for computing \(D_{\mathrm{KL}}\)), equation (68) matches equation (15) in Zhang and Chen (2021) and thus provides a theoretical backing to the objective used in Zhang and Chen (2021). Resolving the term \(\mathbb{E}_{\overrightarrow{\mathbb{P}}_{\mathrm{EM}}^{\mu,a}}||\mathbf{Y}_{t_{i+ 1}}-\mathbf{Y}_{t_{i}}-a_{t_{i}}(t_{i+1}-t_{i})||^{2}\) analytically may offer a variance reduction similar to the analytic calculations in Sohl-Dickstein et al. (2015, Equation 14) and the Rao-Blackwellizations of \(D_{\mathrm{KL}}\) in Ho et al. (2020).

**Remark 10**.: The time discretised RND in equation (67) can be expressed as the ratio of the transition densities corresponding to two discrete-time Markov chains \(\mu(\mathbf{y}_{0})q^{a}(\mathbf{y}_{1:K}|\mathbf{y}_{0})/b^{b}(\mathbf{y}_{0:K-1}|\mathbf{y}_{K} )\nu(\mathbf{y}_{K})\) with \(\mathbf{y}_{0:K}\sim q^{a}(\mathbf{y}_{1:K}|\mathbf{y}_{0})\mu(\mathbf{y}_{0})\). As a result considering \(\nu(x)=\dot{\nu}(\mathbf{x})/Z\) and the IS estimator \(\hat{Z}=p^{b}(\mathbf{y}_{0:K-1}|\mathbf{y}_{K})\dot{\nu}(\mathbf{y}_{K})/\mu(\mathbf{y}_{0})q ^{a}(\mathbf{y}_{1:K}|\mathbf{y}_{0})\) it follows that \(\mathbb{E}_{q^{a}(\mathbf{y}_{1:K}|\mathbf{y}_{0})\mu(\mathbf{y}_{0})}[\ln\hat{Z}]\) is an ELBO of \(\hat{Z}\) (e.g. \(\mathbb{E}_{q^{a}(\mathbf{y}_{1:K}|\mathbf{y}_{0})\mu(\mathbf{y}_{0})}[\ln\hat{Z}]\leq\ln Z\)).

Whilst superficially simple, Remark 10 guarantees that normalizing constant estimators arising from our discretisation do not overestimate the true normalizing constant. This result is beneficial in practice as it allows us to compare estimators possessing this property by selecting the one with the largest value. As highlighted in Vargas et al. (2023) many SDE discretisations can result in estimators that do not yield an ELBO: for example, the estimators used in Berner et al. (2022) can result in overestimating the normalising constant. Note similar remarks have been established in the context of free energy computation and the Jarzynski equality see Stoltz et al. (2010, Remark 4.5).

### Proof of Proposition 3.3 (Controlled Crooks' fluctuation theorem and the Jarzinsky equality)

Proof.: Following the computations in Appendix D.1 and using the formulae (29), we compute

\[\ln\left(\frac{\mathrm{d}\overrightarrow{\mathbb{P}}_{\mu,\sigma^{2}\nabla\ln \pi+\nabla\phi}}{\mathrm{d}\overrightarrow{\mathbb{P}}_{\nu,-\sigma^{2} \nabla\ln\pi+\nabla\phi}}\right)(\mathbf{Y})=\ln\mu(\mathbf{Y}_{0})-\ln\nu(\mathbf{Y}_{T})\] \[+\int_{0}^{T}\nabla\ln\pi_{t}(\mathbf{Y}_{t})\circ\mathrm{d}\mathbf{Y}_{t}- \frac{1}{\sigma^{2}}\int_{0}^{T}\nabla\phi_{t}(\mathbf{Y}_{t})\cdot\nabla\ln\pi_{t}( \mathbf{Y}_{t})\,\mathrm{d}t-\int_{0}^{T}\Delta\phi(\mathbf{Y}_{t})\,\mathrm{d}t.\]Then via Ito's lemma applied to the unnormalised annealed log target \(\ln\hat{\pi}_{t}=\ln\pi_{t}-\ln\mathcal{Z}_{t}\) we have

\[\ln\hat{\pi}_{T}(\mathbf{Y}_{T})-\ln\hat{\pi}_{0}(\mathbf{Y}_{0})-\int_{0}^{T}\partial_{ t}\ln\hat{\pi}_{t}(\mathbf{Y}_{t})\,\mathrm{d}t=\int_{0}^{T}\nabla\ln\hat{\pi}_{t}( \mathbf{Y}_{t})\circ\mathrm{d}\mathbf{Y}_{t}=\int_{0}^{T}\nabla\ln\pi_{t}(\mathbf{Y}_{t}) \circ\mathrm{d}\mathbf{Y}_{t},\]

thus we arrive at

\[\ln\left(\frac{\mathrm{d}\overrightarrow{\mathbb{P}}_{\mu,\sigma^ {2}\nabla\ln\pi+\nabla\phi}}{\mathrm{d}\overrightarrow{\mathbb{P}}_{\nu,- \sigma^{2}\nabla\ln\pi+\nabla\phi}}\right)(\mathbf{Y})=\ln\mu(\mathbf{Y}_{0})-\ln\nu( \mathbf{Y}_{T})+\ln\hat{\pi}_{T}(\mathbf{Y}_{T})-\ln\hat{\pi}_{0}(\mathbf{Y}_{0})\] \[-\int_{0}^{T}\partial_{t}\ln\hat{\pi}_{t}(\mathbf{Y}_{t})\,\mathrm{d} t-\tfrac{1}{\sigma^{2}}\int_{0}^{T}\nabla\phi_{t}(\mathbf{Y}_{t})\cdot\nabla\ln\pi_{t }(\mathbf{Y}_{t})\,\mathrm{d}t-\int_{0}^{T}\Delta\phi_{t}(\mathbf{Y}_{t})\,\mathrm{d}t.,\]

for arbitrary initial and final densities \(\mu\) and \(\nu\). Crooks' generalised fluctuation theorem (Crooks, 1999) now follows from taking \(\phi=0\), and the controlled version in Proposition 3.3 follows from \(\mu=\pi_{0}\) and \(\nu=\pi_{T}\). Finally notice that:

\[1 =\mathbb{E}_{\overrightarrow{\mathbb{P}}_{\mu,\sigma^{2}\nabla\ln \pi}}\left[\left(\frac{\mathrm{d}\overrightarrow{\mathbb{P}}_{\mu,\sigma^{2} \nabla\ln\pi}}{\mathrm{d}\overrightarrow{\mathbb{P}}_{\nu,-\sigma^{2}\nabla \ln\pi}}\right)^{-1}\right]\] \[=\mathbb{E}_{\overrightarrow{\mathbb{P}}_{\mu,\sigma^{2}\nabla \ln\pi}}\left[\exp\left(-\ln\mu(\mathbf{Y}_{0})+\ln\nu(\mathbf{Y}_{T})-\ln\hat{\pi}_{T} (\mathbf{Y}_{T})+\ln\hat{\pi}_{0}(\mathbf{Y}_{0})+\int_{0}^{T}\partial_{t}\ln\hat{\pi} _{t}(\mathbf{Y}_{t})\,\mathrm{d}t\right)\right],\]

which implies the Jarzynski equality when considering the boundaries \(\mu=\pi_{0}\) and \(\nu=\pi_{T}\), resulting in:

\[\mathbb{E}_{\overrightarrow{\mathbb{P}}_{\pi_{0},\sigma^{2}\nabla \ln\pi}}\left[\exp\left(\int_{0}^{T}\partial_{t}\ln\hat{\pi}_{t}(\mathbf{Y}_{t}) \,\mathrm{d}t\right)\right]=e^{-(\ln\mathcal{Z}_{0}-\ln\mathcal{Z}_{T})}.\]

### Proof of Proposition 3.1: Em \(\iff\) IPF

In applications, IPF is faced with the following challenges:

1. The sequential nature of IPF, coupled with the need for each iteration to undergo comprehensive training as outlined in Section C.3, results in significant computational demands.
2. The reference distribution \(r(\mathbf{x},\mathbf{z})\) (or the reference vector field \(f_{t}\)) enters the iterations in (18) only through the initialisation. As a consequence, numerical errors accumulate, and it is often observed that the Schrodinger prior is 'forgotten' as IPF proceeds (Vargas et al., 2021; Fernandes et al., 2021; Shi et al., 2023).

Thus to address these challenges this section will focus on establishing the connection between EM and IPF which in turn will provide us with a family of algorithms that circumvent the sequential nature of IPF, further bridging variational inference and entropic optimal transport.

Proof.: The proof proceeds by induction.

To begin with, the update formula in (18a) implies that

\[\pi^{1}(\mathbf{x},\mathbf{z})=\operatorname*{arg\,min}_{\pi(\mathbf{x},\mathbf{z})}\left\{D_{ \mathrm{KL}}(\pi(\mathbf{x},\mathbf{z})||r(\mathbf{x},\mathbf{z})):\ \pi_{\mathbf{x}}(\mathbf{x})=\mu(\mathbf{x}) \right\},\]

recalling the initialisation \(\pi(\mathbf{x},\mathbf{z})=r(\mathbf{x},\mathbf{z})\). To take account of the marginal constraint, we may write \(\pi(\mathbf{x},\mathbf{z})=\mu(\mathbf{x})\pi(\mathbf{z}|\mathbf{x})\) and vary over the conditionals \(\pi(\mathbf{z}|\mathbf{x})\). By the chain rule for \(D_{\mathrm{KL}}\), we see that

\[D_{\mathrm{KL}}(\mu(\mathbf{x})\pi(\mathbf{z}|\mathbf{x})||r(\mathbf{x},\mathbf{z}))=D_{\mathrm{ KL}}(\mu(\mathbf{x})||r(\mathbf{x}))+\mathbb{E}_{\mathbf{x}\sim\mu(\mathbf{x})}[D_{\mathrm{KL}}( \pi(\mathbf{z}|\mathbf{x})||r(\mathbf{z}|\mathbf{x}))], \tag{70}\]

which is minimised at \(\pi(\mathbf{z}|\mathbf{x})=r(\mathbf{z}|\mathbf{x})\). From this, it follows that \(\pi^{1}(\mathbf{x},\mathbf{z})=\mu(\mathbf{x})r(\mathbf{z}|\mathbf{x})\) for the first IPF iterate. By assumption, the EM iteration is initialised in such a way that \(q^{\phi_{0}}(\mathbf{z}|\mathbf{x})=r(\mathbf{z}|\mathbf{x})\), so that indeed \(\pi^{1}(\mathbf{x},\mathbf{z})=q^{\phi_{0}}(\mathbf{z}|\mathbf{x})\mu(\mathbf{x})\).

The induction step is split (depending on whether \(n\) is odd or even):

1.) First assume that the first line of (20) holds for a fixed odd \(n\geq 1\). Our aim is to show that this implies that

\[\pi^{n+1}(\mathbf{x},\mathbf{z})=p^{\theta_{(n+1)/2}}(\mathbf{x}|\mathbf{z})\nu(\mathbf{z}), \tag{71}\]

that is, the second line of (20) with \(n\) replaced by \(n+1\). From (18b), we see that

\[\pi^{n+1}(\mathbf{x},\mathbf{z})=\operatorname*{arg\,min}_{\pi(\mathbf{x},\mathbf{z})}\left\{D_ {\mathrm{KL}}(\pi(\mathbf{x},\mathbf{z})||\pi^{n}(\mathbf{x},\mathbf{z})):\;\pi_{\mathbf{z}}(\mathbf{ z})=\nu(\mathbf{z})\right\}.\]

Again, we enforce the marginal constraint by setting \(\pi(\mathbf{x},\mathbf{z})=\pi(\mathbf{z}|\mathbf{x})\nu(\mathbf{z})\) and proceed as in (70) to obtain \(\pi^{n+1}(\mathbf{x},\mathbf{z})=\pi^{n}(\mathbf{x}|\mathbf{z})\nu(\mathbf{z})\). The statement in (71) is therefore equivalent to \(\pi^{n}(\mathbf{x}|\mathbf{z})=p^{\theta_{(n+1)/2}}(\mathbf{x}|\mathbf{z})\). To show this, we observe from the EM-scheme in (19) that

\[\theta_{(n+1)/2}=\operatorname*{arg\,min}_{\theta}\mathcal{L}_{D_{\mathrm{KL} }}(\phi_{(n-1)/2},\theta).\]

In combination with the second line of (20) and the definition of \(\mathcal{L}_{D}(\phi,\theta)\) in (5), we obtain

\[\theta_{(n+1)/2}=\operatorname*{arg\,min}_{\theta}D_{\mathrm{KL}}(\pi^{n}(\mathbf{ x},\mathbf{z})||p^{\theta}(\mathbf{x}|\mathbf{z})\nu(\mathbf{z}))=\operatorname*{arg\,min}_{ \theta}\mathbb{E}_{\mathbf{z}\sim\pi_{\mathbf{z}}^{n}(\mathbf{z})}\left[D_{\mathrm{KL}}( \pi^{n}(\mathbf{x}|\mathbf{z})||p^{\theta}(\mathbf{x}|\mathbf{z}))\right],\]

where the second equality follows from the chain rule for \(D_{\mathrm{KL}}\) as in (70). Since by assumption the parameterisation of \(p^{\theta}(\mathbf{x}|\mathbf{z})\) is flexible, we indeed conclude that \(\pi^{n}(\mathbf{x}|\mathbf{z})=p^{\theta_{(n+1)/2}}(\mathbf{x}|\mathbf{z})\).

2.) Assume now that the second line of (20) holds for a fixed even \(n\geq 2\). We need to show that the first line holds with \(n\) replaced by \(n+1\), that is,

\[\pi^{n+1}(\mathbf{x},\mathbf{z})=q^{\phi_{n/2}}(\mathbf{z}|\mathbf{x})\mu(\mathbf{x}).\]

Using similar arguments as before, we see that \(\pi^{n+1}(\mathbf{x},\mathbf{z})=\pi^{n}(\mathbf{x}|\mathbf{z})\mu(\mathbf{x})\), so that it is left to show that \(\pi^{n}(\mathbf{x}|\mathbf{z})=q^{\phi_{n/2}}(\mathbf{z}|\mathbf{x})\). Along the same lines as in 1.), we obtain

\[\phi_{n/2}=\operatorname*{arg\,min}_{\phi}\mathcal{L}_{D_{\mathrm{ KL}}}(\phi,\theta_{n/2}) =\operatorname*{arg\,min}_{\phi}D_{\mathrm{KL}}(q^{\phi}(\mathbf{z}|\mathbf{x}) \mu(\mathbf{x})||\pi^{n}(\mathbf{x},\mathbf{z}))\] \[=\operatorname*{arg\,min}_{\phi}\mathbb{E}_{\mathbf{z}\sim\mu(\mathbf{x} )}\left[q^{\phi}(\mathbf{z}|\mathbf{x})||\pi^{n}(\mathbf{z}|\mathbf{x})\right].\]

Again, this allows us to conclude, since the parameterisation in \(q^{\phi}(\mathbf{z}|\mathbf{x})\) is assumed to be flexible enough to allow for \(q^{\phi_{n/2}}(\mathbf{z}|\mathbf{x})=\pi^{n}(\mathbf{x}|\mathbf{z})\).

The proof for the path space IPF scheme is verbatim the same after adjusting the notation. For completeness, we consider a drift-wise version below. 

**Remark 11** (Extension to \(f\)-divergences).: The proof does not make use of specific properties of \(D_{\mathrm{KL}}\), other than that it satisfies the chain rule. As a consequence, the statement of Proposition 3.1 straightforwardly extends to other divergences with this property, in particular to \(f\)-divergences, see Proposition 6 in (Baudoin, 2002).

### Drift based EM

As remarked in the previous subsection, the proof of the equivalence between IPF and EM in path space follows the exact same lines, replacing the chain rule of \(D_{\mathrm{KL}}\) with the (slightly more general) disintegration theorem (Leonard, 2014b). In this section, we provide a direct extension to the control setting, yielding yet another IPF-type algorithm and motivating certain design choices for the family of methods we study.

**Corollary E.2** (Path space EM).: _For the initialisation \(\phi_{0}=0\) the alternating scheme_

\[\theta_{n+1} =\operatorname*{arg\,min}_{\theta}D_{\mathrm{KL}}(\overrightarrow{ \mathbb{P}}^{\mu,f+\sigma^{2}\nabla\phi_{n}},\overleftarrow{\mathbb{P}}^{\nu,f+\sigma^{2}\nabla\theta}),\] \[\phi_{n+1} =\operatorname*{arg\,min}_{\phi}D_{\mathrm{KL}}(\overrightarrow{ \mathbb{P}}^{\mu,f+\sigma^{2}\nabla\phi},\overleftarrow{\mathbb{P}}^{\nu,f+ \sigma^{2}\nabla\theta_{n+1}}) \tag{73}\]

_agrees with the path space IPF iterations in (Bernton et al., 2019; Vargas et al., 2021a; De Bortoli et al., 2021)._Proof.: For brevity let \(\mathcal{L}_{\mathrm{FB}}(\phi,\theta):=D_{\mathrm{KL}}(\overrightarrow{\mathbb{P}} ^{\mu,f+\sigma^{2}\nabla\phi},\,\overleftarrow{\mathbb{P}}^{\nu,f+\sigma^{2} \nabla\theta})\). Additionally, we parameterise the forwards and backwards SDEs with respective path distributions \(\overrightarrow{\mathbb{P}}^{\mu,f+\sigma^{2}\nabla\phi}\), \(\overleftarrow{\mathbb{P}}^{\nu,f+\sigma^{2}\nabla\theta}\) as:

\[\mathrm{d}\mathbf{Y}_{t} =f_{t}(\mathbf{Y}_{t})\,\mathrm{d}t+\sigma^{2}\nabla\phi_{t}(\mathbf{Y}_{ t})\,\mathrm{d}t+\sigma\overrightarrow{\mathbb{J}}\mathbf{W}_{t},\quad\mathbf{Y}_{0} \operatorname{\sim}\mu,\] \[\mathrm{d}\mathbf{Y}_{t} =f_{t}(\mathbf{Y}_{t})\,\mathrm{d}t+\sigma^{2}\nabla\theta_{t}(\mathbf{Y} _{t})\,\mathrm{d}t+\sigma\overleftarrow{\mathbb{d}}\mathbf{W}_{t},\quad\mathbf{Y}_{T }\sim\nu.\]

The proof will proceed quite similarly, so instead we will consider just the inductive step for the odd half bridge:

\[\theta_{n}=\operatorname*{arg\,min}_{\theta}\mathcal{L}_{\mathrm{FB}}(\phi_{n- 1},\theta).\]

We can show via the \(D_{\mathrm{KL}}\) chain rule and the disintegration theorem (Leonard, 2014) that the above is minimised when \(\theta\) satisfies \(\overleftarrow{\mathbb{P}}^{\nu,f+\sigma^{2}\nabla\theta}=\overrightarrow{ \mathbb{P}}^{\mu,f+\sigma^{2}\nabla\phi_{n-1}}\frac{\mathrm{d}\nu}{\mathrm{d} \rho_{T}^{\mu,f+\sigma^{2}\nabla\phi_{n-1}}}\) which corresponds to \(\nabla\theta_{n}=\sigma^{2}\nabla\phi_{n-1}-\sigma^{2}\nabla\ln\rho_{t}^{\mu, f+\sigma^{2}\nabla\phi_{n-1}}\) following Observation 1 in Vargas et al. (2021). Similarly as per Proposition 3.1 the results will follow for the even half bridges.

EM initialisation:The above corollary provides us with convergence guarantees when performing coordinate descent on \(D_{\mathrm{KL}}(\overrightarrow{\mathbb{P}}^{\mu,f+\sigma^{2}\nabla\phi}, \,\overleftarrow{\mathbb{P}}^{\nu,f+\sigma^{2}\nabla\theta})\) subject to initialising \(\phi_{0}=0\). n practice, this indicates that the way of initialising \(\phi\) has a major impact on which bridge we converge to.

Thus as a rule of thumb we propose initialising \(\phi_{0}=0\) such that we initialise at the Schrodinger prior: then one may carry out joint updates as an alternate heuristic, we call this approach DNF (EM Init), as it is effectively a clever initialisation of DNF inspired by the relationship between IPF and EM.

### HJB-Regularizers

As per Section 3.1, IPF resolves the nonquiqueness in minimising \(\mathcal{L}_{D}(\phi,\theta)\) by performing the coordinate-wise updates (19) starting from an initialisation informed by the Schrodinger prior. On the basis of this observation, the joint updates \((\phi_{n+1},\theta_{n+1})\leftarrow(\phi_{n},\theta_{n})-h\nabla_{\phi,\theta }\mathcal{L}_{D}(\phi,\theta)\) suggest themselves, in the spirit of VAEs (Kingma et al., 2019) and as already proposed in this setting by Neal & Hinton (1998). However, as is clear from the introduction, the limit \(\lim_{n\to\infty}(\phi_{n},\theta_{n})\), can merely be expected to respect the marginals in (6), and no optimality in the sense of (17) is expected. As a remedy, we present the following result:

**Proposition E.3**.: _For \(\lambda>0\), a divergence \(D\) on path space, and \(\phi,\psi\in C^{1,2}([0,T]\times\mathbb{R}^{d};\mathbb{R})\), let_

\[\mathcal{L}^{\mathrm{Schr}}(\phi,\theta):=D(\overrightarrow{\mathbb{P}}^{\mu, f+\sigma^{2}\nabla\phi},\overleftarrow{\mathbb{P}}^{\nu,f+\sigma^{2}\nabla \theta})+\lambda\mathrm{Reg}(\phi), \tag{74}\]

_where \(\mathrm{Reg}(\phi)=0\) if and only if the HJB-equation \(\partial_{t}\phi+f\cdot\nabla\phi+\frac{\sigma^{2}}{2}\Delta\phi+\frac{ \sigma^{2}}{2}|\nabla\phi|^{2}=0\) holds. Then \(\mathcal{L}_{\mathrm{Schr}}(\phi,\theta)=0\) implies that the drift \(a_{t}:=\sigma^{2}\nabla\phi_{t}\) solves (17)._

The proof rests on an optimal control reformulation of the Schrodinger problem (see Appendix E), identifying the HJB-equation as the missing link that renders joint minimisation of (74) theoretically sound for solving (17). The loss in (74) has two important benefits compared to standard IPF. First, it circumvents the need for the sequential updates used in IPF, thereby simplifying and speeding up the optimisation procedure. Second, it enforces the Schrodinger prior drift \(f\) directly, rather than recursively via eq. (18a), (18b). This prevents the prior from being forgotten, as is usually the case in regular IPF. In Appendix E.5, we detail possible constructions of \(\mathrm{Reg}(\phi)\), discuss relationships to previous work, and evaluate the performance of the suggested approach in numerical experiments.

This result can be found in Chen et al. (2021, Proposition 5.1), for instance, but since it is relevant to the connections pointed out in Remark 13 below, we present an independent proof:

**Proposition E.4** (Mean-field game formulation).: _Assume that \(\phi\operatorname{\in}C^{1,2}([0,T]\times\mathbb{R}^{d};\mathbb{R})\) satisfies the conditions:_

1. _The forward SDE_ \[\mathrm{d}\mathbf{Y}_{t} =f_{t}(\mathbf{Y}_{t})\,\mathrm{d}t+\sigma^{2}\nabla\phi_{t}(\mathbf{Y}_{ t})\,\mathrm{d}t+\sigma\overrightarrow{\mathrm{d}}\mathbf{W}_{t},\ \mathbf{Y}_{0} \operatorname{\sim}\mu\] (75) _admits a unique strong solution on_ \([0,T]\)_, satisfying moreover the terminal constraint_ \(\mathbf{Y}_{T}\sim\nu\)2. _The Hamilton-Jacobi-Bellmann (HJB) equation_ \[\partial_{t}\phi+f\cdot\nabla\phi+\frac{\sigma^{2}}{2}\Delta\phi+\tfrac{\sigma^{2}} {2}|\nabla\phi|^{2}=0\] (76) _holds for all_ \((t,x)\in[0,T]\times\mathbb{R}^{d}\)_._

_Then \(a=\sigma^{2}\nabla\phi\) provides the unique solution to the dynamical Schrodinger problem as posed in (17)._

Proof.: We denote the path measures associated to the SDE

\[\mathrm{d}\mathbf{Y}_{t}=f_{t}(\mathbf{Y}_{t})\,\mathrm{d}t+\sigma\,\mathrm{d}\mathbf{W}_{t} \tag{77}\]

by \(\mathbb{P}\) and the SDE (75) by \(\mathbb{P}^{\phi}\), respectively. According to Girsanov's theorem, the Radon-Nikodym derivative satisfies

\[\frac{\mathrm{d}\mathbb{P}^{\phi}}{\mathrm{d}\mathbb{P}}=\exp\left(\sigma\int_ {0}^{T}\nabla\phi_{t}(\mathbf{Y}_{t})\cdot\mathrm{d}\mathbf{W}_{t}-\tfrac{\sigma^{2}} {2}\int_{0}^{T}|\nabla\phi_{t}|^{2}(\mathbf{Y}_{t})\,\mathrm{d}t\right), \tag{78}\]

provided that the marginals agree at initial time, \(\mathbb{P}_{0}=\mathbb{P}_{0}^{\phi}\). Along solutions of (77), we have by Ito's formula

\[\phi_{T}(\mathbf{Y}_{T})-\phi_{0}(\mathbf{Y}_{0})= \int_{0}^{T}\!\!\partial_{t}\phi_{t}(\mathbf{Y}_{t})\,\mathrm{d}t+\! \int_{0}^{T}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \!\!where the variance is taken with respect to the path measure induced by (77), is a valid HJB-regulariser in the sense of Proposition E.3. The equivalence between \(\operatorname{Reg}_{\text{BSDE}}(\phi)=0\) and the HJB equation (76) follows from the theory of backward stochastic differential equations (BSDEs)11, see, for example, the proof of Proposition 3.4 in Nusken and Richter (2023) and the discussion in Nusken and Richter (2021, Section 3.2).

Footnote 11:... not to be confused with reverse-time SDEs as in (12).

In the following, we present an analogue of Proposition E.4 involving the backward drift (Chen et al., 2019):

**Proposition E.5**.: _Assume that \(\theta\in C^{1,2}([0,T]\times\mathbb{R}^{d};\mathbb{R})\) satisfies the following two conditions:_

1. _The backward SDE_ \[\mathrm{d}\mathbf{Y}_{t}=f_{t}(\mathbf{Y}_{t})\,\mathrm{d}t+\sigma^{2}\nabla \theta_{t}(\mathbf{Y}_{t})\,\mathrm{d}t+\sigma\overset{\leftarrow}{\mathrm{d} }\mathbf{W}_{t},\qquad\mathbf{Y}_{T}\sim\nu\] (82) _admits a unique strong solution on_ \([0,T]\)_, satisfying moreover the initial constraint_ \(\mathbf{Y}_{0}\sim\mu\)_._
2. _The Hamilton-Jacobi-Bellmann (HJB) equation_ \[\partial_{t}\theta+f\cdot\nabla\theta-\frac{\sigma^{2}}{2}\Delta\theta+\tfrac {\sigma^{2}}{2}|\nabla\theta|^{2}-\nabla\cdot f=0\] (83) _holds for all_ \((t,x)\in[0,T]\times\mathbb{R}^{d}\)_._

_Assuming furthermore that the solution to (82) admits a smooth positive density \(\rho\), we have that \(a_{t}=\nabla\theta_{t}+\sigma^{2}\nabla\ln\rho_{t}\) provides the unique solution to the Schrodinger problem as posed in (17)._

**Remark 14**.: As opposed to Chen et al. (2016, equation (41)), the HJB-equation (83) does not involve the time reversal of the Schrodinger prior; the form of the HJB equations is not uniquely determined. On the other hand, (83) contains the divergence term \(\nabla\cdot f\), which discourages us from enforcing this constraint in the same way as (76). An akin result can be found in Liu et al. (a) stated in terms of BSDEs.

Proof of Corollary E.5.: Using the forward-backward Radon-Nikodym derivative in (14), we compute

\[\ln\left(\frac{\mathrm{d}\overrightarrow{\mathbb{P}}^{\mu,f}}{ \mathrm{d}\overrightarrow{\mathbb{P}}^{\nu,f+\sigma^{2}\nabla\phi}}\right)( \mathbf{Y})=\ln\left(\frac{\mathrm{d}\mu}{\mathrm{d}\mathrm{Leb}}\right)-\ln \left(\frac{\mathrm{d}\nu}{\mathrm{d}\mathrm{Leb}}\right)+\sigma\int_{0}^{T} \!\!\!f_{t}(\mathbf{Y}_{t})\cdot\mathrm{d}\mathbf{W}_{t}-\sigma\!\!\int_{0}^{T }\!\!\!f_{t}(\mathbf{Y}_{t})\cdot\overline{\mathrm{d}}\mathbf{W}_{t}\] \[-\sigma\int_{0}^{T}\nabla\theta_{t}(\mathbf{Y}_{t})\cdot\overleftarrow {\mathrm{d}}\mathbf{W}_{t}+\tfrac{\sigma^{2}}{2}\int_{0}^{T}|\nabla\theta_{t}| ^{2}(\mathbf{Y}_{t})\,\mathrm{d}t\] \[=\ln\left(\frac{\mathrm{d}\mu}{\mathrm{d}\mathrm{Leb}}\right)-\ln \left(\frac{\mathrm{d}\nu}{\mathrm{d}\mathrm{Leb}}\right)-\sigma\!\!\int_{0}^{ T}\!\!

### ELBO experiments and Comparison to Geffner & Domke (2023)

We compare our underdamped and overdamped CMCD variants against 5 datasets from Geffner & Domke (2023), which we describe in further detail below.

* log_sonar (\(d=61\)) and log_ionosphere (\(d=35\)) are Bayesian logistic regression models: \(x\sim\mathcal{N}(0,\sigma_{w}^{2}l),y_{i}\sim\text{Bernoulli}(\text{sigmoid}(x^ {\top}u_{i}))\) with posteriors conditioned on the _sonar_ and _ionosphere_ datasets respectively.
* brownian (\(d=32\)) corresponds to the time discretisation of a Brownian motion: \[\alpha_{\text{inn}} \sim\text{LogNormal}(0,2),\] \[\alpha_{\text{obs}} \sim\text{LogNormal}(0,2),\] \[x_{1} \sim\mathcal{N}(0,\alpha_{\text{inn}}),\] \[x_{i} \sim\mathcal{N}(x_{i-1},\alpha_{\text{inn}}),\quad i=2,\ldots 20,\] \[y_{i} \sim\mathcal{N}(x_{i},\alpha_{\text{obs}}),\quad i=1,\ldots 30.\] inference is performed over the variables \(\alpha_{\text{inn}},\alpha_{\text{obs}}\) and \(\{x_{i}\}_{i=1}^{30}\) given the observations \(\{y_{i}\}_{i=1}^{10}\cup\{y_{i}\}_{i=20}^{30}\).
* lorenz (\(d=90\)) is the discretisation of a highly stiff 3-dimensional SDE that models atmospheric convection: \[\begin{array}{lcl}x_{1}&\sim\mathcal{N}(\text{ loc }=0,\text{ scale }=1)\\ y_{1}&\sim\mathcal{N}(\text{ loc }=0,\text{ scale }=1)\\ z_{1}&\sim\mathcal{N}(\text{ loc }=0,\text{ scale }=1)\\ x_{i}&\sim\mathcal{N}(\text{ loc }=10\left(y_{i-1}-x_{i-1}\right),\text{ scale }=\alpha_{\text{inn}})&i=2,\ldots,30\\ y_{i}&\sim\mathcal{N}(\text{ loc }=x_{i-1}\left(28-z_{i-1}\right)-y_{i-1}),\text{ scale }=\alpha_{\text{inn}})&i=2,\ldots,30\\ z_{i}&\sim\mathcal{N}(\text{ loc }=x_{i-1}y_{i-1}-\frac{8}{3}z_{i-1},\text{ scale }=\alpha_{\text{inn}})&i=2,\ldots,30,\\ o_{i}&\sim\mathcal{N}(\text{ loc }=x_{i},\text{ scale }=1)&i=2,\ldots,30\\ \end{array}\] where \(\alpha_{\text{inn }}=0.1\) (determined by the discretization step-size used for the original SDE). The goal is to do inference over \(x_{i},y_{i},z_{i}\) for \(i=1,\ldots,30\), given observed values \(o_{i}\) for \(i\in\{1,\ldots,10\}\cup\{20,\ldots,30\}\).
* seeds (\(d=26\)) is a random effect regression model trained on the _seeds_ dataset: \[\begin{array}{lcl}\tau&\sim\text{Gamma}(0.01,0.01)\\ a_{0}&\sim\mathcal{N}(0,10)\\ a_{1}&\sim\mathcal{N}(0,10)\\ a_{2}&\sim\mathcal{N}(0,10)\\ a_{12}&\sim\mathcal{N}(0,10)\\ b_{i}&\sim\mathcal{N}\left(0,\frac{1}{\sqrt{\tau}}\right)\\ i&=1,\ldots,21\\ \text{logits}_{i}&=a_{0}+a_{1}x_{i}+a_{2}y_{i}+a_{12}x_{i}y_{i}+b_{1}\\ i&=1,\ldots,21\\ r_{i}&\sim\text{Binomial }(\text{logits}_{i},N_{i})\\ i&=1,\ldots,21.\end{array}\] The goal is to do inference over the variables \(\tau,a_{0},a_{1},a_{2},a_{12}\) and \(b_{i}\) for \(i=1,\ldots,21\), given observed values for \(x_{i},y_{i}\) and \(N_{i}\).

For all target distributions, we follow the hyperparameter setup from Geffner & Domke (2023) from their code repository12 for all baseline methods (ULA, MCD, UHA, and LDVI) as well as our overdamped and underdamped variants. We first pretrain the source distribution to a mean-field Gaussian distribution trained for \(150,000\) steps with ADAM and a learning rate of \(10^{-2}\). We thentrain for \(150000\) iterations with a batch size of \(5\), tuning learning rate between \([10^{-5},10^{-4},10^{-3}]\) picking the best one based on mean ELBO after training. For all methods, during training the mean-field source distribution is continued to be trained, as well as the discretisation step size and \(\epsilon=\delta t\sigma\). For the underdamped methods we also train the damping coefficient \(\gamma\), and for methods involving a score network, i.e. MCD, LDVI, CMCD and CMCD (UD), we train the networks which are chosen to be fully-connected residual networks with layer sizes of \([20,20]\). In order to report the mean ELBO after training, we obtain 500 samples with 30 seeds and report an averaged value over them.

### \(\ln Z\), sample quality experiments and comparison to (Zhang & Chen, 2022; Vargas et al., 2023a)

Furthermore, we also include comparisons to a large-dimensional target distribution and two standard distributions with known \(\ln Z\) replicated from Vargas et al. (2023a), which we summarise below.

* lgcp (\(d=1600\)) is a high-dimensional Log Gaussian Cox process popular in spatial statistics (Moller et al., 1998). Using a \(d=M\times M=1600\) grid, we obtain the unnormalised target density \(\mathcal{N}(x;\mu,K)\prod_{i\in[1:M]^{2}}\exp\left(x_{i}y_{i}-a\exp\left(x_{i} \right)\right)\).
* funnel (\(d=10\)) is a challenging distribution given by \(\pi_{T}(x_{1:10}=\mathcal{N}(x_{1};0,\sigma_{f}^{2})\mathcal{N}(x_{2:10};0, \exp(x_{1})I)\), with \(\sigma_{f}^{2}=9\)(Neal, 2003).
* gmm (\(d=2\)) is a two-dimensional Gaussian mixture model with three modes, given by the following target distribution \[\pi_{T}(x) =\frac{1}{3}\mathcal{N}\left(x;\begin{bmatrix}3\\ 0\end{bmatrix},\begin{bmatrix}0.7&0\\ 0&0.05\end{bmatrix}\right)+\frac{1}{3}\mathcal{N}\left(x;\begin{bmatrix}-2.5\\ 0\end{bmatrix},\begin{bmatrix}0.7&0\\ 0&0.05\end{bmatrix}\right)\] \[+\mathcal{N}\left(x;\begin{bmatrix}2\\ 3\end{bmatrix},\begin{bmatrix}1&0.95\\ 0.95&1\end{bmatrix}\right)\]

For these target distributions, we follow the hyperparameter setup from Vargas et al. (2023a) from their code repository13for the baseline methods of DDS and PIS, and replicate them as closely as possible for CMCD. Unlike the previous, we don't pretrain the mean-field Gaussian source distribution \(\mathcal{N}(0,\sigma_{\text{int}}^{2}I)\). We select the optimal learning rate in \([10^{-3},10^{-4},10^{-5}]\), the optimal standard deviation of the source distribution \(\sigma_{\text{int}}\) in \([1,2,3,4,5]\) and the optimal \(\alpha\) in \([0.1,0.5,1.15,2]\). Instead of training \(\epsilon=\delta t\sigma\), we sweep over an optimal value in \([10^{-2},10^{-1},1]\). The models are trained with a batch size of \(300\) for \(11000\) steps, where we keep the source distribution parameters fixed, as well as \(\epsilon\). For evaluation, we use 30 seeds with a batch size of 2000, and report average performance over the seeds. DDS and PIS use a 128-dimensional positional embedding, along with an additional network for the time parameters, however MCMD uses a regular score network. In order to make exact comparisons, we select differing network architecture sizes that result in an equivalent number of parameters for funnel and gmm. For lgcp, due to the high dimensionality of the dataset, we choose a small network for CMCD. We summarise these below. For gmm and funnel, it is possible to sample from the target distribution, and we report an OT-regularised distance (\(\mathcal{W}_{2}^{\gamma}\)) with a regularisation \(\gamma=10^{-2}\). Similar to the mean ELBO, we draw 2000 samples from the models and the targets, and average \(\mathcal{W}_{2}^{\gamma}\) over 30 seeds. We use the Python Optimal Transport14 library's default implementation of entropy-regularised distance. Results for comparisons to DNF can be found in Table 5.

Footnote 13: [https://github.com/franciscovargas/denoising_diffusion_samplers](https://github.com/franciscovargas/denoising_diffusion_samplers)

Footnote 14: [https://pythonot.github.io/](https://pythonot.github.io/)
Here, we report performance using the log-variance divergence-based loss (Nusken and Richter, 2021) introduced at the end of Section 3.2,

\[\mathcal{L}_{\mathrm{Var}}^{\mathrm{CMCD}}(\phi)\!\approx\!\mathrm{ Var}\!\left[\!\ln\!\frac{\pi_{0}(\mathbf{Y}_{0})}{\hat{\pi}(\mathbf{Y}_{T})}\!\!\prod_{k= 0}^{K-1}\!\frac{\mathcal{N}(\mathbf{Y}_{t_{k+1}}|\mathbf{Y}_{t_{k}}+(\nabla\ln\pi_{t_{k }}+\nabla\ln\phi_{t_{k}})(\mathbf{Y}_{t_{k}})\Delta t_{k},2\sigma^{2}\Delta t_{k})}{ \mathcal{N}(\mathbf{Y}_{t_{k}}|\mathbf{Y}_{t_{k+1}}\!\!+\!(\nabla\ln\pi_{t_{k+1}}\!\! -\!\nabla\ln\phi_{t_{k+1}})(\mathbf{Y}_{t_{k+1}})\Delta t_{k},2\sigma^{2}\Delta t_{ k})}\!\right]\!, \tag{24}\]

A careful reader will note this loss simply consists of replacing the expectation in the KL loss with a variance. A major computational advantage of this loss is that the measure that the expectations are taken with respect to can be any measure and is not restricted to the forward or backward SDEs like in KL (Richter et al., 2020; Nusken and Richter, 2021), this allows us to detach the samples and thus accommodating for a much more computational objective.

which we find performs quite well compared to our default loss function, especially for multimodal target distributions. We consider the very multi-modal mixture of Gaussian target distribution from Midgley et al. (2022), and report the ELBO and \(\ln Z\) numbers in the table below. For this experiment, we use a batch size of 2000 and train neural networks with a size \([130,130]\) for \(150k\) iterations.

\begin{table}
\begin{tabular}{l c c c} \hline \hline  & **GMM** & **LGCP** & **Funnel** \\ \hline DDS & \([10,10]\) & \([64,64]\) & \([64,64]\) \\ PIS & \([10,10]\) & \([64,64]\) & \([64,64]\) \\ CMCD & \([38,38]\) & \([64,64]\) & \([110,110]\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: **Network Sizes for comparison.** Note that CMCD has less parameters for the despite the Funnel target despite the larger drift due to the PIS and DDS networks having an additional grad network.

\begin{table}
\begin{tabular}{l c c c} \hline \hline  & ELBO & \(\ln Z\) & \(\mathcal{W}_{2}\) \\ \hline _log-variance_ loss & -1.279 \(\pm\) 0.096 & -0.065 \(\pm\) 0.101 & 0.0143 \(\pm\) 0.001 \\ KL loss & -2.286 \(\pm\) 0.1109 & -0.244 \(\pm\) 0.3309 & 0.0441 \(\pm\) 0.012 \\ \hline \hline \end{tabular}
\end{table}
Table 2: ELBO and \(\ln Z\) on 40-GMM

Figure 2: Architecture from (Geffner and Domke, 2023) used across experiments for our CMCD drift network. Softplus activations are used.

### Specification and Tuning: SMC, AFT, and NF-VI

We adopted the implementations15 provided by the studies in Arbel et al. (2021); Matthews et al. (2022) and initialized them with default hyperparameters before fine-tuning.

Footnote 15: [https://github.com/google-deepmind/annealed_flow_transport](https://github.com/google-deepmind/annealed_flow_transport)

**Sequential Monte Carlo (SMC).** For SMC, we utilized 2000 particles sampled from a zero-mean unit Gaussian distribution, implementing re-sampling if the effective sample size (ESS) fell below 0.3. We employed Hamiltonian Monte-Carlo (HMC) for particle mutation, executing one Markov Chain Monte Carlo (MCMC) step after each annealing step. The number of leapfrog steps was fixed at 10, and an extensive grid search over different step sizes was conducted, consistent with Arbel et al. (2021). This search spanned four different step sizes, contingent on the temperature, resulting in a grid search over 256 parameters. The finalized values are presented in Table 3. For SMC, \(K\) is defined by the number of temperatures.

Figure 4: Plots showing training loss curves for the log-variance loss and the default loss for different values of \(\Delta_{t_{k}}\). We find that a low value of \(\Delta_{t_{k}}=0.1\) is needed in order to obtain a low training loss for the default loss, whereas the log-variance loss is much more robust to different values of \(\Delta_{t_{k}}\). The x-axis reports an evaluation every 150 steps of training

Figure 3: (left) 2000 samples drawn from the CMCD algorithm trained with the default loss function, and (right) 2000 samples drawn from the algorithm trained with the log-variance divergence-based loss. We can see that the default loss function misses many modes in the target distribution, whereas the log-variance loss has not missed any modes. We report final results after sweeping over \(\Delta_{t_{k}}\) and learning rates for both methods, picking the one with lowest training loss.

Furthermore, we report the results for SMC in Table 3 for the tuned hyperparameters used for each target. Please note that we were able to obtain similar \(\ln Z\) values as in Vargas et al. (2023a) suggesting SMC was well-tuned. Finally, for each result, we report the mean and standard deviations across 30 different seeds, results can be seen in Table 3.

**Annealed Flow Transport Monte Carlo (AFT).** We maintained a similar setup to SMC, with a few adjustments: using 500 particles for training and 2000 for evaluation to accommodate the added complexity from the normalizing flows. We also decreased the number of temperatures and increased the number of MCMC steps to mitigate memory requirements from the flows. \(K\) is defined as the number of temperatures \(\times\) MCMC steps, with the latter fixed at 4, resulting in a maximum of 64 flows trained simultaneously. Inverse autoregressive flows (IAFs) were employed in all experiments except for _lgcp_, using a neural network with one hidden layer whose dimension matches the problem's dimensionality. For _lgcp_, a diagonal affine flow was used due to memory constraints arising from the high dimensionality. AFT flows were trained for 300 iterations until convergence.

**Variational Inference with Normalizing Flows (VI-NF).** We utilized the same flows as for AFT. In this case, \(K\) denotes the number of flows to stack. The flows were trained over a total of 2000 iterations with a batch size of 500. For some targets

### Further Ablation with NF-style methods and AFT

We further run both flow models (AFT and NFVI) on all possible target distributions (subject to OOM errors). Results can be found in Table 6.

\begin{table}
\begin{tabular}{l c c c c c c c c c} \hline \hline  & OOM & LGP & LGP2 & LGP3 & LGP4 & LGP5 & LGP6 & LGP7 \\ \hline \hline \(\Delta t\) & 0.5,0.5,0.4,0.8 & 0.3,0.3,0.2,0.2 & 0.60,0.01,0.08,0.06,0.01 & 0.3,0.2,0.6,0.05 & 0.2,0.6,0.25 & 0.1,0.2,0.2 & 0.2,0.1,0.05,0.01 & [0.60,0.2,0.0.05] \\ \hline \hline \end{tabular}
\end{table}
Table 3: **Tuned MCMC Step Sizes.**

\begin{table}
\begin{tabular}{l c c c c c c c c c} \hline \hline  & OOM & LGP & LGP2 & LGP3 & LGP4 & LGP5 & LGP6 & LGP7 \\ \hline \(\Delta t\) & 0.5,0.5,0.4,0.8 & 0.3,0.3,0.2,0.2 & 0.60,0.01,0.08,0.06 & 0.3,0.2,0.2 & 0.60,0.01,0.08,0.06 & 0.3,0.2,0.6,0.05 & 0.2,0.0.2 & 0.1,0.2,0.2 & 0.2,0.1,0.05,0.01 & [0.60,0.2,0.0.05] \\ \hline \hline \end{tabular}
\end{table}
Table 4: **SMC Results.** ELBO and \(\ln Z\) values for a different number of steps \(K\) and experiments.

\begin{table}
\begin{tabular}{l|c|c c c c c c c} \hline \hline Dataset & Method & \(K=8\) & \(K=16\) & \(K=32\) & \(K=64\) & \(K=128\) & \(K=256\) \\ \hline \hline funnel & CMCD & -0.3037 \(\pm\) 0.1507 & 0.223 \(\pm\) 0.1041 & -0.1805 \(\pm\) 0.0773 & -0.1058 \(\pm\) 0.1143 & -0.0573 \(\pm\) 0.0444 & -0.01928 \(\pm\) 0.0641 \\  & VLD-NF & -0.3768 \(\pm\) 0.2157 & 0.3517 \(\pm\) 0.1627 & -0.2919 \(\pm\) 0.0999 & -0.6941 \(\pm\) 0.0884 & -0.1947 \(\pm\) 0.1325 & -0.2124 \(\pm\) 0.0637 \\  & VLD-NF & -0.2066 \(\pm\) 0.079 & -0.2066 \(\pm\) 0.082 & -0.2066 \(\pm\) 0.0887 & -0.194 \(\pm\) 0.101 & -0.1828 \(\pm\) 0.097 & -0.1974 \(\pm\) 0.099 \\  & AFT & 0.8754 \(\pm\) 0.534 & -0.3956 \(\pm\) 0.351 & -0.3348 \(\pm\) 0.192 & -0.2717 \(\pm\) 0.227 & -0.235 \(\pm\) 0.139 & -0.1966 \(\pm\) 0.111 \\ \hline \hline gmm & CMCD & -0.1358 \(\pm\) 0.0839 & 0.0133 \(\pm\) 0.1222 & 0.0095 \(\pm\) 0.0495 & 0.0073 \(\pm\) 0.0277 & -0.0603 \(\pm\) 0.0068 & -0.0088 \(\pm\) 0.0520 \\  & VLD-NF & -0.3676 \(\pm\) 0.6134 & -0.2588 \(\pm\) 0.412 & -0.4938 \(\pm\) 0.3788 & 0.4449 \(\pm\) 0.5579 & -0.4652 \(\pm\) 0.3223 & -0.384 \(\pm\) 0.6381 \\  & VLD-NF & -0.3556 \(\pm\) 0.6988 & -0.4552 \(\pm\) 0.2588 & -0.0662 \(\pm\) 0.138 & -0.0482 \(\pm\) 0.15 & -0.0666 \(\pm\) 0.188 & -0.0458 \(\pm\) 0.177 \\  & AFT & -0.3357 \(\pm\) 0.0606 & -0.0682 & 0.0088 & -0.0616 \(\pm\) 0.024 & -0.0033 \(\pm\) 0.009 & 0.001 \(\pm\) 0.026 \\ \hline lgcp & CMCD & 49109 \(\pm\) 0.5533 & 498\(\pm\) 1.47 & 2.624 & 502\(\pm\) 0.2482 & 506\(\pm\) 0.0645 & 1.761 & 508\(\pm\) 1.853 & 509\(\pm\) 1.242 \\  & VLD-NF & 42473 \(\pm\) 0.5858 & 4247\(\pm\) 1.935 & 5.354 \(\pm\) 2474 \(\pm\) 3.8631 & 424\(\pm\) 719 \(\pm\) 3.860 & 424\(\pm\) 47 \(\pm\) 3.869 & 424\(\pm\) 45 \(\pm\) 5.996 \\  & AFT & 126,651 \(\pm\) 5.764 & 344.145 \(\pm\) 23.955 & 191\(\pm\) 613 & 173\(\pm\) 1783 & 420.259 \(\pm\) 91.43 & 480.1264 \(\pm\) 30.599 & 491.0284 \(\pm\) 8057 \\ \hline \hline \end{tabular}
\end{table}
Table 5: \(\ln Z\) **comparison.**\(\ln Z\) values for a different number of steps \(K\), experiments and methods. Not all methods could be evaluated on every \(K\)/experiment combination due to numerical instabilities or out-of-memory (OOM) problems.

### Wallclock times for \(\ln Z\) calculation

In order to calculate the average wall-clock time for \(\ln Z\) calculation, we calculate the time it takes to draw \(30\) seeds of \(2000\) samples each from the methods below, and use these samples to calculate the mean and standard deviation of \(\ln Z\) across \(30\) seeds.

### Training time comparisons to SMC

In this section, we explore a total time comparison between our approach CMCD and SMC.

As both methods are quite inherently different it is not immediately obvious how to carry out an insightful comparison. In order to do so we chose the LGCP which is our most numerically intense target and we phrase the following question:

"For how long do we have to train CMCD to outperform the best-run SMC"

For this, we look at our Figure 1 pane c) and we can see that at \(K=8\) CMCD already outperforms SMC at \(K=256\) with 2000 particles. So we choose these two approaches to compare to. In Table 9 is a brief comparison of total time calculations, note we have included tuning time for SMC which is akin to our training time as without tuning SMCs hyperparameters ELBOs and \(\ln Z\) estimations were much worse. We can observe that the total runtime for training and sampling CMCD to reach a better in \(Z\) value does not exceed the time required to tune SMC.

\begin{table}
\begin{tabular}{l|l|c c c c c} \hline \hline
**Dataset** & **Method** & \(K-8\) & \(K-16\) & \(K-32\) & \(K-64\) & \(K-128\) & \(K-256\) \\ \hline seeds & CMCD & \(74.501\pm 0.009\) & \(74.277\pm 0.065\) & \(74.742\pm 0.05\) & \(73.567\pm 0.088\) & \(73.783\pm 0.022\) & \(72.568\pm 0.032\) \\  & VINP & \(73.536\pm 0.003\) & \(73.247\pm 0.012\) & \(73.537\pm 0.012\) & \(72.385\pm 0.014\) & \(73.262\pm 0.014\) & \(73.675\pm 0.014\) \\  & AFT & \(14.477\pm 0.4308\) & \(16.134\pm 0.157\) & \(90.939\pm 0.621\) & \(73.466\pm 1.15\) & \(73.847\pm 0.15\) & \(73.664\pm 0.188\) \\  & CRAFT & \(14.567\pm 0.513\) & \(51.341\pm 0.505\) & \(-80.383\pm 0.344\) & \(76.555\pm 0.175\) & \(74.579\pm 0.413\) & \(74.229\pm 0.133\) \\ \hline log-language & \(\begin{array}{l}\text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \end{array}\) & \(\begin{array}{l}\text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \text{U-N}\\ \end{array}\) & \(\begin{array}{l}\text{U-N}\\ \text{U-N

## Appendix G Regularised IPF-type Experiments

For the purpose of completeness in this section, we empirically explore the regularised IPF-type objectives proposed in the main text. We explore a series of low-scale generative modelling experiments where the goal is to retain generative modelling performance whilst improving the quality of the bridge itself (i.e. solving the SBP problem better).

Across our experiments, we use \(D_{\mathrm{KL}}\) and let \(\Gamma_{0}=\Gamma_{T}=\mathrm{Leb}\), which can be simplified to the forward-backwards KL objective used in DNF (Zhang et al., 2014), see Appendix E.1.1. We use the Adam optimiser (Kingma & Ba, 2015) trained on 50,000 samples and batches of size 5000 following Zhang & Chen (2021). For the generative modelling tasks we use 30 time steps and train for 100 epochs whilst for the double well we train all experiments for 17 epochs (early stopping via the validation set) and 60 discretisation steps. Finally note we typically compare our approach with \(\lambda>0\) to DNF (\(\lambda=0\)), with DNF initialised at the reference process, which we call DNF (EM init), see Appendix E.4 for further details.

### 2D toy targets - generative modelling

Here we consider the suite of standard 2D toy targets for generative modelling explored in Zhang & Chen (2021) In contrast to Zhang & Chen (2021) we consider the SDE \(\mathrm{d}\mathbf{Y}_{t}=-\sigma^{2}\mathbf{Y}_{t}\,\mathrm{d}t+\sigma\sqrt{2 }\,\mathrm{d}\mathbf{W}_{t}\) as the Schrodinger prior across methods. We parametrise DNF and our proposed approach with the same architectures for a fair comparison. Furthermore, we incorporate the drift of the above Schrodinger prior into DNF via parameterising the forward drift as in (75), partly motivated by Corollary E.2.

In order to assess the quality of the bridge we consider three different error metrics. Firstly we estimate \(D_{\mathrm{KL}}\) between the Schrodinger prior and the learned forward process (i.e. \(\mathbb{E}_{\mathbf{Y}_{\mathbf{Y}_{\mathbf{Y}_{\mathbf{Y}_{\mathbf{Y}_{\mathbf{Y }_{\mathbf{Y}_{\mathbf{Y}_{\mathbf{Y}_{\mathbf{Y}_{\mathbf{Y}_{\mathbf{Y}_{ \mathbf{Y}_{\mathbf{Y}_{\mathbf{Y}}}}}}}\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,in particular sampling quite inconsistent trajectories. Finally for reference we train a DNF model with \(f_{t}=0\) and \(\phi\) (5d) initialised at random to illustrate the significance of the initialisation of \(\phi\).

#### g.2.1 Double well potential

We used the following potential (Vargas et al., 2021a):

\[U\left(\begin{pmatrix}x\\ y\end{pmatrix}\right)=\frac{5}{2}(x^{2}-1)^{2}+y^{2}+\frac{1}{\delta}\exp\left( -\frac{x^{2}+y^{2}}{\delta}\right), \tag{85}\]

with \(\delta=0.35\), furthermore, we used the boundary distributions:

\[\mu\sim\mathcal{N}\left(\begin{pmatrix}-1\\ 0\end{pmatrix},\begin{pmatrix}0.0125&0\\ 0&0.15\end{pmatrix}\right),\ \ \nu\sim\mathcal{N}\left(\begin{pmatrix}1\\ 0\end{pmatrix},\begin{pmatrix}0.0125&0\\ 0&0.15\end{pmatrix}\right).\]

The Schrodinger prior is given by:

\[\mathrm{d}\mathbf{Y}_{t}=-\nabla_{\mathbf{Y}_{t}}U(\mathbf{Y}_{t})\,\mathrm{d}t+\sigma\, \mathrm{d}\mathbf{W}_{t}, \tag{86}\]

with \(\sigma=0.4\). The terminal time is \(T=1\). Furthermore, we employ the same exponential discretisation scheme as in the generative modelling experiments.

### Implementation Details

#### g.3.1 Neural network parameterisations

Following Zhang & Chen (2021) and the recent success in score generative modelling we choose the following parameterisations:

\[a_{t}(\mathbf{x}) =f_{t}(\mathbf{x})+\sigma^{2}\nabla\phi(t,\mathbf{x}), \tag{87a}\] \[b_{t}(\mathbf{x}) =f_{t}(\mathbf{x})+\sigma^{2}\nabla\phi(t,\mathbf{x})-\sigma^{2}s_{\theta} (t,\mathbf{x}), \tag{87b}\]

where \(s_{\theta}\) is a score network (Song et al., 2021; De Bortoli et al., 2021; Zhang & Chen, 2021) and \(\phi(t,\mathbf{x})\) is a neural network potential. We adapt the architectures proposed in Onken et al. (2021); Koshizuka & Sato (2023) to general activation functions. Note that these architectures allow for

\begin{table}
\begin{tabular}{l l c c c c c c c c} \hline \hline \multirow{2}{*}{Target} & \multirow{2}{*}{Method} & \multicolumn{2}{c}{KL} & \multicolumn{2}{c}{SSP Loss} & \multicolumn{2}{c}{PINN Loss} & \multicolumn{2}{c}{Cross Ent} \\ \cline{3-11}  & & & Val & Train & Val & Train & Val & Train & Val & Train \\ \hline \multirow{2}{*}{tree} & \(\lambda=0.5\) & 1.67±0.02 & 1.40±0.01 & **47.84±1.58** & **42.31±1.52** & **0.66±0.00** & **0.05±0.00** & 2.87±0.01 & 2.80±0.01 \\  & DNF(EM Init) & 1.63±0.02 & 1.39±0.01 & 53.33±1.39 & 49.60±1.68 & 1.74±0.01 & 1.64±0.04 & 2.88±0.01 & 2.80±0.01 \\ \hline \multirow{3}{*}{fast computation of \(\Delta\phi\) comparable to that of Hutchinson's trace estimator (Grathwohl et al., 2019; Hutchinson, 1989).

Finally, we remark that the parametrisation in (87b) allows us to learn the score of the learned SDE and thus seamlessly adapt our approach to using the probability flow ODE (Song et al., 2021) at inference time.

#### g.3.2 PINN Loss

For the PINN loss across all tasks, we sample the trajectories from \(\mathbf{Y}_{0:T}^{\phi}\sim\overrightarrow{\mu,\nabla\phi}\) and thus employ the same discretisation as used in the KL loss. However, we detach the trajectories \(\mathbf{Y}_{0:T}^{\mathrm{detach}(\phi)}\) before calculating the gradient updates in a similar fashion to Nusken and Richter (2021).

Figure 6: Generated samples trained by our approach (\(\lambda=0.5\)) left and DNF (\(\lambda=0\)) right. Qualitatively we can observe that both learned models have similarly matched marginals.