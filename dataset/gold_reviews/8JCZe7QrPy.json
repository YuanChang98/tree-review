{
    "Decision": "Accept (poster)",
    "Comment": "This paper proposes ORCA, a model for object-centric relational abstraction\nand reasoning for visual data. The method combines Slot Attention with a\nrelational reasoning component and proves effective for several challenging\nsynthetic visual reasoning tasks. The paper further introduces a new reasoning\ntask based on CLEVR, called CLEVR-ART, which presents a valuable contribution\nto this area.\n\nThe reviewers agree that this is a paper of high quality that presents a\nvaluable contribution to the field. While the considered benchmark tasks are\nvisually simplistic, the experimental evaluation is very thorough with a solid\nrange of baseline comparisons and model ablations. While the positioning to\nrelated work could be expanded, this is a solid submission that in my view\nmeets the bar for acceptance at NeurIPS.",
    "reviews": [
        {
            "Summary": "This work proposed a new method, named OCRA, that combines object-centric presentation learning (for object abstraction) and a relational bottleneck (for relational abstraction). Particularly, OCRA consists of three components: 1) a slot attention to extract object level representations, 2) a relational operator to get pairwise visual relations, and 3) a transformer to model higher-order relations. The slot attention model is pretrained on a large dataset and the relational modules are trained on a small task-specific dataset while freezing the slot attention. Experiments were performed on three datasets: ART, SVRT and CLEVR-ART to show the effectiveness of the proposed method.",
            "Strengths": "1. The idea of combining slot attention with a relational bottleneck (relation operator and transformer) for solving visual relational reasoning problems sounds interesting and also novel to me.    2. The presentation of the idea and the overall writing are very clear.    3. Experiments on synthetic datasets (ART and SVRT and CLEVR-ART) shows the proposed method can work for various relational reasoning tasks and it achieves better performance than baselines in many cases.",
            "Weaknesses": "1. For the benchmarks, I have a concern about their simplicity. For example, the performance of many methods on the ART dataset is close to 100%. Similar observations also exist in other two datasets. Does it mean we already have achieved human-level visual reasoning performance or we need better benchmarks to evaluate the success of methods? I think considering some more challenging benchmarks will make the results more convincing. For example, RAVEN [1] and Bongard-HOI [2] are two challenging benchmarks for testing a model's visual relational reasoning abilities. In particular, Bongard-HOI considers the real-world natural images.   2. In Figure 4, it is a little surprising that OCRA performs worse than ResNet on SVRT - spatial relations with 1000 training examples. Any intuition on this?   3. For the ablation studies, to test the impact of slot attention, it is too naive to do \u201cfeature map divided into a 4x4 grid\u201d. How about comparing slot attention with some standard SSL trained object-centric representation learning methods? Also, from Table 2, we can see that Transformer has a much higher impact than the slot attention and relational bottleneck on both RMTS and ID. Does it mean the most important part of OCRA is the transformer rather than slot attention and relational bottleneck? If so, it downplays the method's significance a little, in my opinion.\n [1] RAVEN: A Dataset for Relational and Analogical Visual rEasoNing, CVPR 2019.\n [2] Bongard-HOI: Benchmarking Few-Shot Visual Reasoning for Human-Object Interactions, CVPR 2022.",
            "Questions": "My major concerns and questions are in how the experiments support the effectiveness and significance of the proposed method. Please see the weaknesses part for more details.",
            "Limitations": "The authors have well addressed the limitations.",
            "Soundness": "2 fair",
            "Presentation": "3 good",
            "Contribution": "2 fair",
            "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations."
        },
        {
            "Summary": "The research topic of this study is the development of a learning machine that achieves systematic generalization in reasoning over complex relations of objects in a visual input (still image). Toward this goal, the authors proposed a new neural network model (OCRA) taking inspirations from the recent results on effective inductive biases for systematic generalization in relational reasoning and methods for obtaining object-centric representations. More concretely, the proposed model comprised of three core components: first component (slot attention mechanism) to extract object-centric representation from a visual input containing multiple objects, the second component to compute pairwise relation embeddings, and the third component (transformer) to provide the final output related to the higher-order relations. The effectiveness of the proposed model was tested with three visual reasoning tasks, two existing and one new, and also compared with various baseline models. As a whole, the proposed model can be said the best in terms of systematic generalization among the compared models. An ablation study was also conducted to evaluate the roles of the components in the proposed model and pretraining.",
            "Strengths": "The top-level idea behind the proposed model, that is, combining the inductive biases for relational reasoning and a method for obtaining object-centric representations is clear and reasonable. How to implement the idea with the three core components are explained fairly well. Although the top-level idea might look somewhat straightforward at first glance given the advancement in the two directions, the concrete implementation is not trivial, and the differences from the existing work are described in the paper.\n The effectiveness of the proposed model was tested with fairly rich experiments. Two existing task (ART and SVRT, both created with 2D shapes) and a new task developed based on the CLEVR (CLEVR-ART, created with 3D shapes) were used and various baseline models including a very recent one (GAMR, accepted at this year's ICLR) are compared with the proposed model. An ablation study gives additional value to this work.\n Development of a learning machine that achieves systematic generalization in complex visual reasoning is an important topic in AI. Although there is still a distance to the real-world applications as stated in Section 6 (Conclusion and Future Directions), the proposed method and the evaluation results will be of interest to the NeurIPS audience.",
            "Weaknesses": "1. A weak point of this submission is lack of the source code of the proposed model as Supplementary Material. It is also unkown whether the source code will be made publicly available if the paper get accepted. These points cast a shadow on the reproducibility.\n   2. A relatively weak point of the proposed model itself seems to be around the number of slots, K. First, as stated in line 117, the proposed model computes all K2 pairwise relations. Second, in the current model, K should be defined in advance. These characteristics can be obstacles in the reasoning over the relations of objects in the real-world visual inputs. Namely, the fist point might affect the applicability (scalability) to complex natural images and there should be some additional mechanism to determine an appropriate K in the first place if the current structure of the proposed model is kept. \n   3. (Related to 2.) Although it is stated that there exists gap between the problems addressed in this study and the real-world vision in Section 6 (Conclusion and Future Directions), the details are not explained.",
            "Questions": "Questions\n   1. Can the source code of the proposed method be provided at the Author Rebuttal period? In addition, will the source code made publicly available if the paper get accepted?\n   2. What are your thoughts on the second point in Weaknesses section above?\n Suggestion\n It would be beneficial if the authors could add detailed descriptions about what kind of differences between the problems treated in this study and the real-world vision should be overcome, and also add explanations about the relation between those differences and self-supervised learning methods mentioned in Section 6 if possible.",
            "Limitations": "The authors stated in Section 6 (Conclusion and Future Directions) that the problems addressed in this study are still simple compared with the the real- world vision. However, currently it is not explained in details what kind of differences between the problems treated in this study and the real-world vision should be overcome. Please also refer to the Weaknesses and Questions sections above.",
            "Soundness": "3 good",
            "Presentation": "3 good",
            "Contribution": "2 fair",
            "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations."
        },
        {
            "Summary": "* The paper seeks to tackle various visual reasoning problems with a focus on systematic generalization.   * The paper argues that we need explicit inductive bias to extract object-object relationships and express these relationships via a low-capacity representation.   * The paper seeks to do this by first extracting object vectors (or slots) using pre-trained slot attention. It then performs a dot-product of these slots to obtain a \u201crelation embedding\u201d \u2014 which is really a scalar number expressed as an embedding (as far as I understand). These relation embeddings are then given to a transformer and the whole model (except the slot attention) is trained to classify whether the given input is conformant to the true pattern or not.   * The performance is then evaluated on a systematically OOD test set and compared with various baselines and model ablations on 3 visual reasoning benchmarks: ART, SVRT, and CLEVR-ART. Here, CLEVR-ART is a novel dataset proposed within this paper.",
            "Strengths": "1. Simple and elegant architecture.   2. Propose a new dataset for visual reasoning and systematic generalization called CLEVR-ART, a sort of visually complex variant of ART. This appears to be a useful contribution to facilitating progress in the community.   3. Good systematic generalization performance compared to baselines.   4. Several useful baseline comparisons. For instance, the paper shows that a standard transformer when applied to slots is not enough to systematically generalize and the proposed relation layer is useful.   5. Useful ablations. For instance, the paper shows that all of the following are useful: relation bottleneck, relation embedding, object-centric inputs, decomposing position and appearance, etc.",
            "Weaknesses": "I have several questions and possible avenues for improvements that I describe in the \u201cQuestions\u201d section.",
            "Questions": "1. Also, what part of the architecture is enforcing the \u201crelational bottleneck\u201d? Is it due to the fact that the dot product of two slots results in a scalar number? If yes, then this should be highlighted somehow both in the text and perhaps also in Figure 1. One may also conduct an experiment in which the \u201cbottleneck\u201d dimension is gradually increased (e.g., 1 to 2 to 5 and so on) and show that this gradually worsens the generalization performance.    2. Line 30: Regarding learning relational abstractions: Is it possible to take a large batch of inputs, extract relation \u201cembedding\u201d and visualize object pairs that have similar relational \u201cembedding\u201d? This would give more credence to the fact that relational abstractions are indeed being inferred.    3. Line 108: Is it necessary to say \u201cshared\u201d here? IMO, I wouldn\u2019t have assumed that the projection matrices were not shared (based on the equations).   4. It should be better highlighted in the introduction section and the abstract that CLEVR-ART is a novel contribution. This should also be discussed in the related work relative to the existing visual reasoning benchmarks. It would also be useful to make a statement about whether this dataset will be released to the research community or not.   5. Table 1: Why are several baselines shown for ART not shown for CLEVR-ART and SVRT? I think these baselines will be useful to show for all datasets. Also, I would suggest using a consistent format for reporting the results of all 3 datasets i.e., picking either the bar-plot format or the tabular format.   6. L263: In the case of inputs involving multiple images, how are they processed by the network? As I understand, the model does not sequentially consume multiple images. Does \u201cinserted\u201d mean programmatically generating the candidate images, each containing multiple objects?   7. L283-298. I find the discussion of the results rather small. For instance, what is the rationale for the comparison with ESBN or GAMR? What is the key distinguishing characteristic of those baselines with respect to the proposed one? What can we learn from the result of this comparison i.e., why does the proposed model outperform?   8. (Minor) Line 34: Would be good to cite the paper(s) that support this statement \u201cBy biasing architectures to process visual inputs in terms of relations between objects, these recent approaches have achieved strong systematic (i.e., out-of-distribution) generalization of learned abstract rules, given only a small number of training examples.\u201d\n I am giving a score of 6 in the hope that the authors will try and address some of my questions and concerns. If addressed to some degree, I will happily increase the score.",
            "Limitations": "Yes, the limitations are discussed in the last line of the conclusion.",
            "Soundness": "4 excellent",
            "Presentation": "4 excellent",
            "Contribution": "4 excellent",
            "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to- excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations."
        },
        {
            "Summary": "The paper proposes to combine an object-centric representation model (Slot Attention) with a relational reasoning module to create the Object-Centric Relational Abstraction (OCRA) model. For this model, Slot Attention is first pre-trained in an unsupervised way to represent objects separately. Then, the relational reasoning module, consisting of a \"relational bottleneck\" and a transformer model, is applied to these object-centric representations. This reasoning model is trained in a supervised way on a subset of possible objects. The experiments on three different datasets show that this approach generalizes better to previously unseen objects than comparable baselines.",
            "Strengths": "The paper is written well and easy to follow. The introduction provides a strong motivation for this line of research. The proposed approach and conducted experiments are described clearly and with sufficient detail, such that it should be possible to reproduce them.\n The proposed approach seems to be novel and achieves strong generalization performance on previously unseen objects.",
            "Weaknesses": "In my eyes, the main weakness of this paper is that its contribution relative to existing work is not entirely clear.\n   1. Most importantly, the paper positions itself as proposing an approach with a stronger inductive bias toward relational abstraction, which ultimately leads to better generalization performance (for example, introduction (l.46) and related work section (l. 135, l. 170). However, the experiments do not compare against many existing approaches. Without such a comparison, it remains unclear whether the existing approaches actually suffer from the problem that the proposed approach claims to solve. Thus, ideally, the paper should provide such a comparison, or alternatively adjust the positioning of the proposed approach relative to existing work. \n   2. Besides this, it remains somewhat unclear which parts of the proposed approach are building on existing work (such as Slot Attention) and which parts are new. For example, do equations (1) and (2) and sections 2.2 and 2.3 describe novel architectural components or have they been used in a similar fashion before?\n * * *\n   3. The related work section fails to cite many relevant papers. Object-centric representation learning has seen growing interest in recent years, with many papers proposing various solutions. I would recommend taking a look at the related works section of [1], which provides a comprehensive overview of papers that are relevant to this work. Besides this, [2] describes a recent model that combines object-centric representation learning with relational reasoning capabilities and [3] describes generalization properties of Slot Attention to previously unseen objects.\n   4. The experimental results could be strengthened by applying all baselines across all datasets. Additionally, why is the CoRelNet not included in the baselines? It seems like one of the most relevant existing approaches.\n * * *\n Minor points:\n   5. Equation (2): What does adding pos to the position embeddings mk add for the relational reasoning module? It is not dependent on the input, and cannot be adjusted by the relational reasoning module as it is part of the pre-trained, frozen SlotAttention model. Thus, I would expect that it doesn't provide much useful information.\n   6. Equation (4): mk will implicitly contain some information on the object shape, since attn is used in Eq (2). Do you think this could allow the model to circumvent the relational bottleneck, if m would be processed by some more powerful non-linearities?\n   7. Line 115: \"endowing OCRA with an explicity variable-binding mechanism\". What do you mean with this statement?\n   8. line 67: what is a \"position-wise fully-connected layer\"? Are you referring to the 1x1 convolutions in Table S2? In general, I think it would be helpful to draw direct connections between the components of the architecture described in Table S2 and the components described in the main text.\n   9. Eq. (1) + (2): what is the \u22c5 symbol referring to here? In Eq. (3), this symbol is used to describe a dot procuct, which would not make much sense here, I think.\n   10. Lines 255-262: I would move most of this description into the method section.\n   11. Table 2: Use the same order for the different tested conditions in the table as is used within the text.\n * * *\n [1] Jiang, J., Deng, F., Singh, G., & Ahn, S. (2023). Object-centric slot diffusion. arXiv preprint arXiv:2303.10834.\n [2] Wu, Z., Dvornik, N., Greff, K., Kipf, T., & Garg, A. (2022). Slotformer: Unsupervised visual dynamics simulation with object-centric models. ICLR 2023\n [3] Dittadi, A., Papa, S., De Vita, M., Sch\u00f6lkopf, B., Winther, O., & Locatello, F. (2021). Generalization and robustness implications in object- centric learning. ICML 2022",
            "Questions": "As described above, I believe the main weakness of this paper is its current positioning relative to the existing research landscape. If the authors could improve this point, or strengthen the current claims by providing additional experiments, I would be happy to adjust my score.",
            "Limitations": "While the relational bottleneck improves the model's ability to generalize to previously unseen objects, I would expect it to also limit the model's applicability to other settings. For example, in the experiments, a separate model is applied for each separate task and thus for each separate relation to be learned. I would expect that the relational bottleneck would harm the model's performance if it had to differentiate several relations at once. Additionally, I would expect it to be more difficult to represent more complex relations between objects, as the slightly worse results on the spatial relations in the SVRT dataset might indicate.",
            "Soundness": "3 good",
            "Presentation": "3 good",
            "Contribution": "2 fair",
            "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations."
        }
    ]
}