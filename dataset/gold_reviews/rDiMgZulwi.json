{
    "Decision": "Accept (poster)",
    "Comment": "The study investigates why training recurrent neural networks (RNNs) with\nexcitatory (E) and inhibitory (I) neurons is harder compared to regular RNNs.\nAuthors demonstrate that the problem is not sign constraints, but rather the\nmultimodal and disperse synaptic weight spectrum in the traditional E-I\nnetwork design. Reviewers and the AC found this result to be important. Most\ncriticism was addressed during the rebuttal period and additional experiments\nstrengthened the paper.",
    "reviews": [
        {
            "Summary": "This paper presents a comparison between the performance of standard RNNs and two classes of models: the ColEI network and the DANN, which incorporate Dale's Law with the constraint that units in a circuit should be excitatory or inhibitory but not both. The DANN achieves similar performance to a non-signed RNN, but ColEI shows inferior performance. The paper demonstrates that the spectral properties of the recurrent weight matrix at initialization have a more significant impact on network performance than sign constraints, which may explain why some forms of EI network learn better than others.",
            "Strengths": "* This paper uses analytical approaches from machine learning to explore network models that adhere to biological principles, which may inspire the development of more biologically realistic models that also have good performance.   * A novel contribution is the introduction of normalised SVD entropy as a measurement of spectrum pathology during the initialization stage which predicts the final performance of a network before training.   * It also includes extensive experiments that test three RNN architecture on three different tasks with progressive difficulty levels.",
            "Weaknesses": "This work builds upon existing research about EI networks with incremental advancements, offering interesting insights into how the spectral properties of the recurrent weight matrix at initialization may impact network performance. However, the practical application for designing EI networks that perform well requires further clarification. It is unclear to me whether DANNs can be effectively improved with this insight, and even with a more appropriate spectrum, ColEI falls short of standard RNN or DANN performance.",
            "Questions": "Considering the biological motivation of having dedicated excitatory and inhibitory units, it would be valuable to provide a deeper validation or interpretation of the results in the context of neurobiology. For example, could the finding about the different effects of changing the ratio of E/I units on ColEI networks and DANNs offer insights into the biological relevance of these two models to the neural circuit in the brain?",
            "Limitations": "While the focus on RNNs is relevant to the paper's objectives, it would be helpful to briefly acknowledge potential implications for other types of networks.",
            "Soundness": "3 good",
            "Presentation": "3 good",
            "Contribution": "2 fair",
            "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly."
        },
        {
            "Summary": "The paper investigated the problem of why columnEI networks have impaired learning, and they experimentally found that instead of sign constraint, the spectral property of weight at initialization contributed the most; they further experimentally showed that E/I ratio and network size change the spectral properties thus lead to different learning performances. Additionally, they showed DANN in the RNN form show similar performance as normal RNN in 3 different tasks.",
            "Strengths": "**Originality** This is a follow-up work on applying DANN to RNN. I appreciate the detailed discussion on why it is hard to train E-I separated RNNs.\n **Quality** The effectiveness of DRNN is tested in three different tasks which is great! And all hyperparameter selections are listed in the appe ndix. The discussion on initialization spectral property contain proper ablation experiments and extended discussion on E-I ratio and network size.\n **Clarity** The paper is clearly written, with details in the appendix. Some part of the result explanation can be confusing (see second question)\n **Significance** I believe the paper will be of interest to the computational neuroscience community.",
            "Weaknesses": "* The discussion of initialization spectral property is only done for sequential MNIST. Does the observation on SVD entropy hold across data distributions? I'm a bit concerned on how generalizable the results are (details see question).    * For the sign constrained training, how are the gradients rectified? Set to zero? If set to zero, it may leads to silent unit problem. Did the authors exclude the possibility that sign constrained RNN learn worse due to increased number of silent units?    * Typo: line 110 citation",
            "Questions": "My main concern is on the spectral discussion\n   * Does it extend to other tasks with different data distribution?   * Why clusterness of singular values matter for learning? The intuition currently given in the paper seems to mainly pertain to large singular values; yet it is shown large singular value ColEI can learn well. Then what is the intuition behind SVD entropy tracking performance? This lack of intuition is what prompted me to ask the first question as it is not immediately clear to me how generalizable the current results are. And thus a current score of 5.",
            "Limitations": "See questions",
            "Soundness": "3 good",
            "Presentation": "4 excellent",
            "Contribution": "3 good",
            "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations."
        },
        {
            "Summary": "The authors apply Dale's law (that neurons provide exclusively excitatory or inhibitory outputs) to RNNs with two different architectures: ColEIs which are the \u201cstraightforward\u201d way of applying sign constraints per neuron, and recurrent DANNs based on an architecture with two layers per recurrent step. They compare singular value spectrums, network sizes and Excitation/Inhibition ratios in all three architectures and analyze how they affect performance. They conclude that the reason why DANNs perform as well as RNNs, while ColEIs perform worse is largely due to differences in the SVD distribution (as measured by Normalised SVD Entropy).",
            "Strengths": "Dale\u2019s law is an important and ubiquitous property of biological neural networks, but its consequences have not been thoroughly explored. It is interesting that a simple architecture can enforce Dale\u2019s law while remaining trainable, and while keeping many properties of unconstrained RNNs. This architecture features feedforward inhibition, a biologically plausible motif. Understanding consequences of such biological structure is a key topic of Neuro-AI.\n The work offers some nice empirical results, both in performance and in spectral properties.\n The writing and figures are clear, and good efforts are made to provide explanations and interpretations.",
            "Weaknesses": "While being advertised as a biological neural network, the architectural constraints that make the recurrent DANN trainable may be the very same ones that make it biologically unrealistic. For instance, there is no direct recurrent inhibition (I to I), and there cannot be direct reciprocal connectivity between E and I units.\n There is not much mathematical analysis of the results, so the insights are somewhat limited. Clearly there are differences in the spectral distributions, but why these appear and most importantly how these are \u201cdirectly responsible\u201d for decreased performance is not deeply discussed. There is some discussion of the low-rank nilpotent component of ColEI matrices but there is more related literature to connect to, most notably from the Ostoijc group (no, this reviewer is not from that group). For example, Mastrogiuseppe and Ostojic 2018, Schuessler et al 2022, in addition to the Shao and Ostoijc 2022 paper the authors do cite (now evidently published in PLoS comp bio).\n Many of the analyses are done only on the sequential MNIST task, which is not particularly natural. Claims are being made on the basis of small differences in errors, and some qualitative analysis. The small differences suggest that the networks are not being pushed very far to demonstrate their inductive biases.\n Where did the \u03c1=1.5 and \u03c1 ~= 1/sqrt(3) come from in Section 3.1?\n How were the sign constraints implemented?\n Minor: watch out for punctuation errors and typos.",
            "Questions": "Are the inhibitory units in a DANN strictly linear? This seems necessary if the DANN weight matrix is actually an exact reparameterization of the RNN weight matrix, as advertised (L95). Either way, this is unclear. And this has important implications for the story: if the DANN is an exact reparameterization, then isn\u2019t it trivial that RNN and DANN spectra are identical? Why the variance of line 115? Why \u03c1=1.5 and \u03c1 ~= 1/\u221a3 in Section 3.1? Can you explain the 3-layer architectures used in the Sequential MNIST figures? Do the eigenvalues and singular value visualizations of Figures 5,6 include values from weights from all layers? If so, are there any differences between the eigen/singular values between layers? Line 200: Is initialization the only difference between a ColEI network without sign constraints and a standard RNNs?",
            "Limitations": "Adequately addressed",
            "Soundness": "3 good",
            "Presentation": "3 good",
            "Contribution": "3 good",
            "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly."
        },
        {
            "Summary": "The author present a simulation study that investigates gradient-based optimisation of RNNs that obey Dale\u2019s Law, i.e. networks with neurons that are strictly excitatory or inhibitory at initialisation and during training. In particular, the authors disentangle the effect of enforcing Dale\u2019s Law during training (synaptic weights can not flip sign) and the initial spectral properties that result from initialisation with separate excitatory and inhibitory populations of neurons.",
            "Strengths": "The paper investigates an important open question: What are the origins of the performance gap between RNNs that do / do not obey Dale\u2019s Law. Through a large set of simulation studies and numerical analysis, the authors show in a convincing way that the performance gap does not solely stem from enforcing Dale\u2019s Law during training (and thus restricting the solution space by enforcing signs of weights) but also significantly depends on how networks are initialised and parametrised. Initialising RNNs with columns of positive / negative weights to create populations of excitatory / inhibitory neurons (\u201cColEI networks\u201d) causes a skewed and multi-modal singular value spectrum \u2013 leading to the well known effect of exploding neural activations / gradients that hamper training and performance. The authors further provide empirical evidence that the Normalised SVD Entropy thus provides an easy to compute predictor of network performance before the onset of training. Further, the authors provide analytical intuition for their simulation results in the discussion. The paper is well structured, written and accessible. The simulation details are explained in great detail; which is very helpful for understanding the research question, results and potential limitations. The figures are generally clear and accessible.",
            "Weaknesses": "* My main concern is, that as written in appendix 5.3, the learning rate of DANNs is scaled independently for E and I weights to balance the impact and updates of E and I populations. As ColEI networks seem not to be trained with a similar scaling scheme, this has the potential to explain away or confound results and observations. I am happy to revise my score if this is adequately addressed.   * The authors base their analysis on ColEI networks that are initialised following [5], however, the authors do not provide insight (through simulations or analytically) if there generally can or cannot exist a weight initialisation scheme for ColEI networks which does not lead to a skewed and multimodal spectrum of singular values. As thus, the results seem to be limited to a specific initialisation scheme and not to ColEI networks in general.   * The authors apply gradient clipping during network training. This may significantly reduce the effects of skewed, multimodal singular value spectra and outliers in the singular value spectrum. As the authors try to disentangle the effects of enforcing Dale\u2019s Law and the spectral properties of initial recurrent weight matrices, gradient clipping may confound results and conclusions.   * If I understand correctly, recurrent weight matrices in DANNs are parametrised by a linear combination of three weight matrices. As such, it seems like DANNs have three times more free parameters than ColEI networks. If true, this would pose the question if comparisons between DANNs and ColEIs as presented in figure 6 are fair.\n Minor:\n   * In figure 2D it is difficult to see what is going on \u2013 maybe log-axis and a higher alpha value for the scatter point\u2019s colour would help?   * In figure 2B it looks like the networks haven\u2019t been trained until convergence   * Missing \u201cin\u201d in line 94   * Broken reference in line 110",
            "Questions": "1. As written in appendix 5.3, the learning rate of DANNs are scaled independently for E and I weights to balance the impact of E and I and their updates. As ColEI networks seem not to be trained with a similar scaling scheme: How does the IE weight scaling influence simulation results and conclusions; in particular with respect to changes in EI ratio and network size?\n   2. In line 109 the authors write \u201c[\u2026] the activation variance did not scale with depth [\u2026]\u201d. Did the authors control for mean and variance shift across layers and increasing depth? It would help to better understand the three different training regimes if there would be a plot that is visualising the mean and variance shift at initialisation across layers and depth for random data for RNNs, DANNs and ColEIs for varying EI ratios.\n   3. Related to 2 \u2013 In order to better understand the learning dynamics and in order to detect anomalies, a plot that visualises the mean and variance of synaptic weights and biases and how they evolve during training would be helpful. Do you expect the mean and variance of the weight matrices and biases within the E and I population to evolve similarly for RNNs, DANNs and ColEIs?\n   4. Related to 2 \u2013 Judging from the learning trajectories (e.g. in Figure 2B/C), to me, it looks like that ColEI networks have a significantly higher initial error (at t=0) \u2013 however, since the y-axis is cut \u2013 I might be wrong? If the initial errors are different, why are they different?\n   5. In line 116 the authors write \u201c[\u2026] each row of W^IE was initialised as the mean row of W^EE [\u2026]\u201d. What does that mean? Do all entries in the row have the same value?\n   6. In Figure 3 it looks like ColEI networks have a large variance in performance. Do you have an explanation or intuition why some of the initialisations fail and others succeed?\n   7. From equation 3, I conclude that DANNs have 3x more free parameters in the recurrent part of the network than ColEIs. This makes comparison tricky, especially when it comes to network size. How does performance look like as a function of free parameters (instead of number of neurons in the hidden layer)?\n   8. I would assume that spectrum transplants alter the EI balance. Did you correct for that effect?",
            "Limitations": "The authors have adequately addressed limitations of their work",
            "Soundness": "3 good",
            "Presentation": "3 good",
            "Contribution": "2 fair",
            "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations."
        }
    ]
}