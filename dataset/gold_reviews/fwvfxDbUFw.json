{
    "Decision": "Accept (poster)",
    "Comment": "The paper proposes a novel approach to fuse machine learning of motor skills\nwith human input through tele-operation.\n\nThe reviewers found the method sound and novel, and the experimental results\nvery convincing. They initially had questions about some details in the\nsetting, the method, and assumptions/limitations. Some shortcomings in the\npresentation were pointed out.\n\nAfter the rebuttal the main concerns of the reviewers have been successfully\naddressed and they are all vote in favor of accepting the paper.",
    "reviews": [
        {
            "Summary": "This paper proposes a new task called assisting grasping. The main difference between this task and classical dexterous grasping is the wrist movement is controlled by a human instead of by the grasping algorithm. The authors propose a two stage method to solve this problem. First, they learn the grasping skill using a successful grasping dataset via score-matching loss. Then, they fine-tune this policy using RL in simulation. They show the proposed method is better than pure RL and score-matching is useful compared to imitation learning algorithms.",
            "Strengths": "(+) The authors formulate the learning from a set of successful grasps as a denoising problem, which is quite interesting and novel. I think this is an effective design choice.\n (+) This paper proposes to separate finger target position and finger movement velocities as two stage problem. This design makes learning more efficient.\n (+) The experiments are comprehensive. The authors shows how each of the component affects the final performance of the policy.\n (+) It also demonstrates the method in the real-world.",
            "Weaknesses": "(-) My major concern of this paper is whether the proposed task is more challenging than classical grasping, as claimed by the authors. From my perspective, the grasping process can be roughly divided to 1) hand approaches the object and 2) finger closes. The proposed task use human teleoperation / predefined wrist trajectory for the approaching phase and only learn how / when the finger should grasp the object. In this sense, in terms of task difficulty, what is the difference from firstly moving the wrist to a close- enough position, and then grasp the object under a stationary wrist? Intuitively, I think this is an easier task.\n (-) As motivated by my previous argument, there should be more logical arguments on the task difficulty if the author want to emphasize this task \u201cpresents a more complex challenge\u201d.\n (-) There are formatting issues in particular Table 2.\n (-) It relies on perfect point-cloud model.",
            "Questions": "As shown in Table 2, stage 1 results are already good if there is no collision. I\u2019m curious if it\u2019s possible to add a collision penalty loss in stage 1 training (similar to the \\delta h in RL training) to improve the stage 1 policy?\n Is there a more elaborated arguments or evidences that why the proposed task is harder than grasping? On the website, the simulation results look like a classical grasping algorithm while the hand poses are almost the same for all real-world results.",
            "Limitations": "This paper is unlikely to have potential negative societal impact.",
            "Soundness": "3 good",
            "Presentation": "3 good",
            "Contribution": "3 good",
            "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations."
        },
        {
            "Summary": "This paper focuses on addressing a task called human-assisting dexterous grasping. The aim is to create a finger controller to grasp objects with the robot's wrist conditioned on a human user's wrist. The authors propose 1) a Grasping Gradient Field (GraspGF) which estimates the gradient of a synthetic grasping example, and 2) a residual policy achieved through reinforcement learning. Experimental results demonstrate the superiority of the proposed method over previous ones.",
            "Strengths": "The authors are tackling an interesting problem - guiding a robot hand to follow human wrist trajectories and utilizing a learnt finger controller to manipulate objects. This bears resemblance to teleoperation but only provides wrist information. I would appreciate further discussion on this aspect.\n The authors introduce a score-matching-based method for learning a primitive policy and a residual policy to aid the primitive policy. This combines synthetic data with reinforcement learning to accelerate training and achieve better performance.\n Authors have conducted a large number of real-world robotic experiments, showcasing the practical applicability of the proposed method.",
            "Weaknesses": "While I agree that human-assisting dexterous manipulation holds potential, it is concerning if this work only addresses the grasping task without considering other dexterous manipulation problems. What are the specific differences and motivations between an automatic dexterous grasping method and user-provided wrist? What is the practical application? If, as the authors suggest, grasping different parts meets varying needs, could the authors conduct experiments to demonstrate this? Or, stepping back, could the proposed method grasp the part that the user intends to grasp? Would it be possible to conduct experiments on it?\n In Table 2, 'ap w/o coll' seems to achieve similar performance, and considering the increment from 55.6% to 56.5%, the residual policy seems not necessary.\n The authors should continue to polish the paper. For instance, the subscript 't' in 'a' on lines 161, 163, and 165 lacks consistency. The formatting of Table 2 could also be improved.",
            "Questions": "What are the outputs of GraspGF when the hand is at different stages, such as when the hand is far from the object at t_0 and close to the object at t_n? What actions are produced in these instances?\n Given the same initial state and wrist trajectory, can we achieve diversified results?\n Observing Figure 4 and Table 1, there is not much difference between the seen and unseen conditions. Could the authors attempt to analyze this?\n Other datasets, such as DexYCB, could provide human wrist trajectory and thus increase the current 200 trajectories.",
            "Limitations": "What is the tolerance for errors in wrist estimation? Often, people cannot carefully move their wrists or do not have a precise estimation tool like Leap Motion. Further, Leap Motion has a requirement for a complete hand without occlusion, which make me doubt about the algorithm's ability to help people with hand disabilities. It might be beneficial to consider alternative wearable sensors for wrist SE3 estimation or additional vision algorithm for wrist pose estimation based on RGB input.",
            "Soundness": "3 good",
            "Presentation": "2 fair",
            "Contribution": "3 good",
            "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly."
        },
        {
            "Summary": "This paper introduces a novel task called human-assisting dexterous grasping, which aims to train a policy for controlling a robotic hand's fingers to assist users in grasping objects. Unlike conventional dexterous grasping, this task is more complex as the policy must adapt to diverse user intentions and the object's geometry. The proposed approach consists of two sub-modules: Grasping Gradient Field (GraspGF) and a history-conditional residual policy. GraspGF learns 'how' to grasp by estimating the gradient of a synthesized success grasping example set, while the residual policy determines 'when' and at what speed the grasping action should be executed based on the trajectory history. Experimental results show that the proposed method outperforms baselines in terms of user-awareness and practicality in real-world applications.",
            "Strengths": "This paper's strengths can be outlined as follows:\n   1. Introduction of a unique dexterous grasp task involving shared autonomy between humans and robots, a topic not extensively explored in prior research.   2. Application of the Denoising Score Matching method to the grasping task.   3. Explicit representation of robot finger velocity.   4. A thorough acknowledgment of the system's limitations, including the requirement for a complete point cloud.",
            "Weaknesses": "However, the paper also has some drawbacks:\n   1. The proposed method is better suited for teleoperation settings compared to the reinforcement learning (RL) baselines used in the experiments. It is essential to include comparisons to teleoperation methods without assisted grasping, both qualitatively and quantitatively.   2. The paper's presentation could be enhanced. For instance, the individual images in Figure 2 could be better explained, as it is currently difficult to comprehend and not highly informative.   3. The residual policy, which corrects the primitive policy's action, does not consider the primitive policy action as input. This seems illogical for predicting velocity and bias terms without knowing the direction.",
            "Questions": "Regarding rsim in Equation 7, more clarification on its functionality would be helpful. Additionally, it would be beneficial to know the inference speed for each module. For human-assistance, quick response times are crucial for seamless human interaction. Since visual modules are utilized, a profiling analysis may be necessary. I am happy to raise the score if the concerned are addressed adequately.\n ## After Rebuttal\n * * *\n The author response looks great to me. Some of the presentation issues are also addressed during the rebuttal phase. I agree with the author that this is more focus on assisting upper limb amputees with prosthetic hands instead of assisting normal persons. I would like to raise the score and glad to see it is accepted.",
            "Limitations": "To address the weaknesses, the paper's authors could improve the presentation by creating more self-contained figures. Furthermore, the hand/object in several images, such as Figure 3, is too small to clearly discern the interaction patterns.",
            "Soundness": "3 good",
            "Presentation": "3 good",
            "Contribution": "3 good",
            "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations."
        },
        {
            "Summary": "This paper introduced a novel and challenging task that performs dexterous grasping according to human wrist movements. This task is potentially useful for applications with prosthetic hands.\n The paper further proposed a novel two-stage framework that solves the two challenging aspects of the proposed task and demonstrated strong performance in both simulated and real-world experiments.",
            "Strengths": "The proposed task is novel and potentially helpful to social welfare. The proposed framework is intuitive and is properly designed for the challenges of its task. The authors have also conducted extensive experiments to show the capacities of the proposed method.\n The paper is well-structured and written.",
            "Weaknesses": "From the qualitative results in the supplementary video, I noticed that for most objects, the graspings are from the same angle relative to the object. For example, with the chips can, all demonstrated graspings are from the side of the cylinder regardless of how the can is placed. This makes me wonder if the proposed method can truly adapt to different approach angles and different _user intentions_. Please correct me if I missed anything from the videos.",
            "Questions": "1. For the baseline methods, are all baselines re-trained to take the wrist pose as a condition? I didn\u2019t find this piece of information in the paper.    2. In figure 5, why do w/o ar and w/o as success rates drop as more samples are seen after 5e6 samples?",
            "Limitations": "1. The method assumes full point cloud observation which may limit its application in the real world.    2. The qualitative results did not show how the proposed method adapts to different wrist poses relative to the object.",
            "Soundness": "4 excellent",
            "Presentation": "4 excellent",
            "Contribution": "4 excellent",
            "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "Rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to- excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations."
        }
    ]
}