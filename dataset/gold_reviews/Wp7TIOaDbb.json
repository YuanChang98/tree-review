{
    "Decision": "Reject",
    "Comment": "The paper has received mildly positive reviews. While your reviews appreciate\nthe innovative insights, clear presentation, and potential scalability of the\nmethod, concerns are raised about the strong assumption of an interior Nash\nequilibrium, clarity on the paper's motivation, comparison with existing\nalgorithms like Lemke\u2013Howson, and the need for clearer experimental benchmarks\nand real-world applicability.\n\nBased on my reading of your reviews, here is the summary of positive and\nnegative aspects of the paper:\n\nPositive Aspects:\n\n  * The paper tackles an important problem in game theory regarding estimating Nash equilibria using optimization.\n  * The paper proposes a potentially scalable solution for which the authors provide theoretical guarantees. The approach appears to be novel.\n\nNegative Aspects:\n\n  * There are questions about the practical applicability of the proposed method and how it compares with existing methods.\n  * There is a concern regarding the underlying assumptions or conditions of the paper's methods, particularly regarding the existence of an interior Nash equilibrium.\n  * The proposed optimization problem is non-convex, and as a result it is not clear if it can be solved efficiently with SGD. The proposed method has no theoretical finite-time guarantees of reaching a Nash equilibrium.\n  * There are some questions about the motivation for the work.\n  * The assumption of an interior Nash equilibrium is very strong and can be computed in polynomial time via linear programming, weakening the motivation.\n  * There are issues about the experiment.\n\nAfter the discussion a number of issues remain. The first main issue is the\ntheoretical soundness of the approach --- there are no finite-time guarantees\nof convergence to Nash equilibria, and there are considerable gaps between the\ntheory provided and the experimental evaluation. The theoretical results are\nnot convincing. Main results, such as Theorem 1, crucially depend on notions\nof dimension not justified at all from a game-theoretic standpoint. The\nreviewers has issues with the notion of \"well-isolated equilibria,\" which is\noverly restrictive and artificial. The empirical success of the proposed\nmethod also relies on whether algorithms such as SGD find \"good\" local optima;\nthe fact that this is the case is many single-agent deep learning applications\ndoes not mean that the same should hold for the problem of computing Nash\nequilibria. It is not clear that the paper currently provides enough evidence\nto support this claim. Finally, it is also unclear if the paper will have\npractical impact because it applies solely on normal-form games, which is\nunlike most literature on computational game solving that focuses on\nextensive-form games.",
    "reviews": [
        {
            "Summary": "This paper proposes a loss function (optimization problem) for normal-form games to estimate Nash equilibria which can be solved via unbiased stochastic optimization. They do this by relating their proposed loss function with exploitability. They also provide theoretical guarantees (under some technical conditions) of using bandit stochastic gradient algorithms to solve their proposed problem. They show the applicability of their method by conducting some numerical experiments.",
            "Strengths": "The paper tackles an important problem in the game theory of estimating Nash equilibria using optimization. It proposes a potentially scalable solution and provides theoretical guarantees for the same. The paper is well-written (albeit a bit notation-heavy) and the content is easy to follow.",
            "Weaknesses": "The authors propose an optimization problem with possible unbiased estimators. However, the proposed problem is still non-convex and it is not clear to me whether it can be solved efficiently with SGD with a potentially large number of saddle points. I understand the analogy to deep learning problems but recent work ([1] and related papers) have shown that those problems carry some interesting structure. Similar properties are unknown (and are perhaps more difficult to establish) for the proposed function.\n Du, S., Lee, J., Li, H., Wang, L., & Zhai, X. (2019, May). Gradient descent finds global minima of deep neural networks. In International conference on machine learning (pp. 1675-1685).",
            "Questions": "Could authors comment on the applicability of their methods on real problems in the context of my comments in the \"Weaknesses\" section?",
            "Limitations": "The limitations are addressed adequately by the authors.",
            "Soundness": "3 good",
            "Presentation": "4 excellent",
            "Contribution": "3 good",
            "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "Rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly."
        },
        {
            "Summary": "This work studies solving Nash Equilibria (NE) by stochastic unbiased optimization. The main contribution is providing a new loss function based on the gradient norm of the utility function, and finding the NE by using standard stochastic optimization methods (like Lipschitz bandit algorithms and stochastic gradient descent (SGD)). The authors also carried our experiment results on several games to show the scalability of their proposed methods.",
            "Strengths": "The presentation of this work is very clear. The experiment results are comprehensive and back up the main claims of this work. The results are also significant as they point out a new way to solve the NE problem in general.",
            "Weaknesses": "More remarks are supposed to be added to the main text. For example,\n   * What does 's' mean in the legend of Figure 3? \n   * In Table 1, why the obstacle of NI method is 'max of random variable'? I did not see any max operator in the definition of the loss function of NI. \n   * In Table 1, for the unconstrained method, can the authors show one concrete example to show why it 'lose the ability to sample from strategies when iterates are no longer proper distributions', as stated in line 113?",
            "Questions": "The same to the 'Weaknesses' section.",
            "Limitations": "This work aims to solve an open problem about the algorithmic game theory, thus it does not need to address the potential negative societal impacts of their work.",
            "Soundness": "3 good",
            "Presentation": "3 good",
            "Contribution": "3 good",
            "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations."
        },
        {
            "Summary": "This work studies the computation of Nash equilibria (NE) of normal-form games and proposes a new loss function: the (weighted) sum of the squared norms of the projections of each player gradient onto the tangent space of the unit simplex. The authors show that this loss function is a meaningful surrogate of exploitability when the game has an interior equilibria. Then, the authors provide methods to efficiently construct unbiased estimators of the loss function via unbiased estimation of each player gradients. To extend these results to handle games with only pure equilibria, the authors propose surrogate player utility functions via entropy regularization (with coefficient \u03c4, the \"temperature\") and show how the modified loss function (based on the modified game with surrogate player utility functions) captures the exploitability of the original game. Next, the authors derive gradient and Hessian expressions for the modified loss function. Leveraging a recent bandit optimization method BLiN, and assuming a sufficiently large temperature (which degrades the convergence rate), the authors provide a high-probability convergence guarantee for computing NE using this approach (loss function + BLiN). Experiments on SGD and BLiN show the effectiveness of the proposed approaches.",
            "Strengths": "* Novel observation of the connection between projection of player gradient to simplex tangent space and best response, which lead to the loss function proposed in this paper.   * Extensive studies of the newly proposed loss function in terms of its gradient, Hessian, and other properties.",
            "Weaknesses": "Some technical details seem to require further clarification. See",
            "Questions": "* Since BLiN is technically a zeroth order method (pulling an arm <==> sampling a function value), can you elaborate/repeat, somewhere around Theorem 1, what is the oracle passed into BLiN? I believe it should be a Monte-Carlo approximation through (6) but with the player gradients being the ones with temperatures (entropy regularization). In other words, please point out what needs to be computed in each step of BLiN.   * As stated in 229-231, if a NFG has a unique equilibrium which is also mixed, then L is strongly convex. Based on earlier results in this paper, are there other conditions that ensure strong or non-strong convexity of L (or L\u03c4)? It would be helpful to state them explicitly, as many stochastic optimization methods can exploit (strong) convexity.",
            "Limitations": "This is a methodological work that does not have immediate or potential negative societal impact. The limitations are on the technical contributions and are discussed above.",
            "Soundness": "3 good",
            "Presentation": "2 fair",
            "Contribution": "3 good",
            "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations."
        },
        {
            "Summary": "This paper presents a novel approach for determining the Nash equilibrium of normal form games, utilizing a solution to a non-convex stochastic optimization problem. It defines the Nash equilibria in normal form games as the global minima of a specifically cunstructed loss function. Moreover, a randomized algorithm is developed to resolve this newly proposed loss function. Finally, empirical results further verify the theoretical analysis.",
            "Strengths": "Though the idea of loss function has been proposed before, this paper contributes to the discourse with several innovative insights that enhance the understanding and applicability of loss functions. For example, this paper restricts the parameter to the simplex, which is the key of making stochastic gradient unbiased.\n Regarding the quality and clarity, this paper is sufficiently complete. It also provides clear backgrounds, which make it easy to understand how this loss function comes from. It is not completely new but it has something new.",
            "Weaknesses": "The motivation of this work is not sufficiently clear. I could understand solving a Nash equilibrium may not be efficient but I don't think proposing a NE solver via unbiased stochastic optimization will make it better.\n It is unclear how this method is better than some existing NE solver such as Lemke\u2013Howson algorithm.",
            "Questions": "1. I agree that there is a gap between the success of using SGD solving non-convex optimization problem and the failure of efficiently computing Nash equilibria. Why does this motivate the goal: \"Can we solve for Nash equilibria via unbiased stochastic optimization\"? To my understanding, solving a non-convex optimization problem is still very hard. \n   2. Solving a non-convex optimization problem may lead to a stationary point instead of the global minima. Why does this proposed method is better than using an existing NE solver such as Lemke\u2013Howson algorithm to ensure obtaining a NE?",
            "Limitations": "This is a theoretical work so there is no negative impact.",
            "Soundness": "3 good",
            "Presentation": "3 good",
            "Contribution": "3 good",
            "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "Rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations."
        },
        {
            "Summary": "This paper formulates a Lipschitz loss function that makes computing approximate interior Nash equilibria in normal-form games amenable to unbiased Monte Carlo estimation, opening the door to using a number of scalable stochastic optimization techniques. They also provide a loss function with similar properties but under the notion of quantal-response equilibrium (QRE). The authors also provide certain illustrative experiments to support their claims.",
            "Strengths": "This paper provides a novel approach to computing equilibria in multi-player games. In particular, the authors derive loss functions that make equilibrium computation amenable to scalable methods from stochastic optimization. Given the lack of scalable algorithms for computing solutions concepts such as the Nash equilibrium, this is a promising approach, and has the potential to bring many new insights to equilibrium computation. In particular, the idea proposed for deriving an unbiased estimator (Section 4.4) is interesting, and addresses many of the pitfalls of other commonly used loss functions in the more challenging constrained setting. Furthermore, the presentation and the writing are overall clear, and the authors accurately place their results into the existing literature.",
            "Weaknesses": "There are a number of issues that weaken the contribution of the paper. First, the underlying assumption that there is an interior Nash equilibrium is very strong. For one, if there is an interior NE it is known that it can be computed in polynomial time via linear programming, which significantly weakens the motivation regarding the hardness of NE. There appears to be some confusion regarding this point. For example, Corollary 3 in the Appendix claims a new FPTAS for computing interior NE in polymatrix games, which I believe is known (beyond polymatrix games); there is perhaps still some benefit in using the proposed methodology in practice, but no evidence of that is provided in the paper. (As an aside, it would be helpful to clarify in the prelimaries that by interior you mean relative interior.) Beyond the very restrictive assumption of having an interior Nash equilibrium, the authors provide similar results for QRE, but that is a significantly weaker equilibrium concept. I would also strongly recommend clarifying in the abstract that your results apply for interior NE; as it is written currently it is very misleading.\n Besides the issue mentioned above, there is an underlying premise in the proposed methodology which I find unconvincing: Why should we expect local optima in the formulated loss functions to give meaningful guarantees? The fact that this turned out to be the case in many ML applications is not enough to justify this proposition. It is a significant weakness that the proposed method has no theoretical finite-time guarantees of reaching a Nash equilibrium.\n And unfortunately the experiments do not offer enough evidence to support this approach. Indeed, there are many issues in the experiments that can be significantly improved. First, the games experimented on are overly small; for example, Shapley's game is completely toy, no meaningful conclusions can be drawn from it. Since the main message of this paper is about scalability, I expected to see experiments on much bigger games. It would be helpful if the proposed theory applied in extensive-form games for which there are many large benchmark games in the literature, but the current method is tailored to normal-form games. Besides this issue, I am very confused regarding the compared benchmarks. It is claimed in the last sentence of the abstract that the method often outperforms prior state of the art, but the main algorithms compared against are RM and FTRL. These algorithms will not even find an NE in finite-time, how can you claim that those are the state of the art? In particular, in Lines 966-969 it is claimed that those are the two most popular scalable stochastic algorithms for approximating NE; I strongly disagree with this claim. I would suggest trying some other benchmarks, such as the Lemke- Howson algorithm; a mixed-integer programming approach; or the algorithm presented in \"Exclusion Method for Finding Nash Equilibrium in Multiplayer Games.\"\n Another issue is on the proof of Corollary 1. For a constant \u03f5, it is claimed that you have a poly-time algorithm (since it is a PRAS), but you also say that the temperature parameter has to be exponentially small to achieve that. So it seems that even for a constant \u03f5 you need an exponential number of iterations to converge.\n Overall, although the approach proposed is promising, there are a number of issues that have to be addressed before the paper is ready for publication.",
            "Questions": "Some minor issues:\n   1. There are many missing punctuation marks in the equations throughout the paper   2. There are many overfull equations in the Appendix; I would recommend fixing those in the revised version",
            "Limitations": "The authors have addressed the limitations.",
            "Soundness": "2 fair",
            "Presentation": "3 good",
            "Contribution": "2 fair",
            "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "Rating": "4: Borderline reject: Technically solid paper where reasons to reject, e.g., limited evaluation, outweigh reasons to accept, e.g., good evaluation. Please use sparingly."
        }
    ]
}