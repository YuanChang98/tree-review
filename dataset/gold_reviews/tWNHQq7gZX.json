{
    "Decision": "Reject",
    "Meta review": {
        "Metareview": "This paper presents a new dataset and first results on semantic sleep segmentation. The dataset is unique, collected for this study, and contains annotated EEG across sleep and awake subjects. The authors demonstrate the ability of their universal sleep decoder to align across subjects and improve sleep accuracy. The reviewers noted these strengths, and in the review process a number of factors were discussed, including lack of baselines, incomplete data availability, mismatch of conclusions with the study capabilities, and general clarity issues related to the details, e.g., of model training and annotation. These points were addressed to varying degrees by the reviewers, however there remains some clarity issues, as well as the incomplete data availability and ambiguity on overall conclusions. Therefore, while the study holds promise, it is likely that a future submission that better addresses these points will fare better.",
        "Justification For Why Not Higher Score": "Primary reasons are the the incomplete data availability and ambiguity on overall conclusions. From the discussion with reviewers it seems that the exact phenomenon being studied is not clear, which makes the full assessment of the paper difficult (i.e., how hard is this problem and is the reviewer concerns on low accuracy justified?).",
        "Justification For Why Not Lower Score": "N/A"
    },
    "reviews": [
        {
            "Summary": "This paper introduces an approach for decoding memory content from brain activity during sleep. To be more specific, the authors show an experimental setup to extract memory reactivation during NREM sleep, along with the ground truth timing and content during the neural replay episode. Using the dataset from 52 subjects, they train a model capable of generalizing across subjects in a zero-shot manner.",
            "Strengths": "The data collected for the paper could be useful for researchers in biosignals/sleep community.",
            "Weaknesses": "* The data is not released. Without the data it's difficult to verify the claims, since one of the main claims of the paper seems to be the unique data collected. Since this appears to be a dataset paper, it is essential that the data is released and verified before this can be accepted.   * There is no comparison with other works. Without the dataset, this paper does not contribute much else.   * With such low accuracy as shown in Figure 3, the efficacy of the method is put into doubt.   * What are the asterisks in Figure 3?   * Even if the data is released, other venues (more focused on health/physiological signals) would be suitable for this paper.",
            "Questions": "Please address the weaknesses.",
            "Soundness": "2 fair",
            "Presentation": "2 fair",
            "Contribution": "2 fair",
            "Confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
            "Rating": "3: reject, not good enough"
        },
        {
            "Summary": "The paper reports on a novel EEG dataset with both sleeping and awake participants designed for memory reactivation decoding during sleep. In addition, it provides a comprehensive set of competitive baselines and ablations on this data demonstrating within-participant and cross-participant generalization.",
            "Strengths": "The paper is clearly written, and the contributions are clearly detailed and (mostly) well supported. Furthermore the paper promises to release a novel dataset (in the supplementary material) and provides clean and reasonably well-annotated code for its contributions. The set of experiments is comprehensive.",
            "Weaknesses": "My primary concern in reading the paper is that a core contribution regarding the relative performance of the various models is not supported as well as it could be. In particular, I think we should expect something like performance on awake+sleep+contrastive > awake+sleep > [awake or sleep in whatever order]. This data is all available in plots (Fig 3) but from just eyeballing those plots it's hard to tell whether the sleep->sleep CNN is better or worse than the awake+sleep->sleep CNN, for example. These should ideally be on the same plot. Similarly sections 4.2.2 and 4.2.3 report some statistics but no comparison to support the core claim above, and there's no results table for these experiments either, unless I have missed something.\n Separately, I have some notation concerns:\n   * Is it really that $y \\in \\mathbb{R}^K$, i.e. each label is a vector of real numbers the length of the number of classes? I would think it's $y \\in \\\\{1 \\ldots K\\\\}$ or similar.    * The $\\mathcal{X}$s aren't explicitly defined.    * If $\\mathcal{P}(i) = \\\\{k|k\\in \\mathcal{A}(i), y_k = y_i\\\\}$ and $\\mathcal{A}(i)$ is a set of instances $\\\\{x_i, y_i\\\\}$ then $k$ is such an instance and $y_k$ seems overloaded or poorly defined.\n These are just the ones I immediately caught -- another careful proofread of the math might be useful.\n Finally, some more unordered comments:\n   * I think describing a dataset as \"open set\" is a bit odd (section 2.2) -- a dataset has a fixed number of classes, i.e. it is \"closed set\". In my understanding \"open set\" is a notion w.r.t models / tasks rather than datasets (i.e. ability to classify unseen classes, often by composition of seen classes, the use of a language model, or something else).    * Kostas et al. 2021 (doi:10.3389/fnhum.2021.653659) is likely worth mentioning in discussion of larger-scale SSL pretraining for EEG.   * I found Figure 2 more confusing than illustrative -- the caption is doing a lot of explanation and I'm not sure how much the figure adds. For example, the arrows and colors are not used consistently -- it's not obvious what the arrow colors mean, and the arrows seem to indicate data flow in the top part of the figure and an ordering of experiments in the bottom part.",
            "Questions": "* The two plots in Figure 4 have the same y axis (which should facilitate comparison) but if I understand things correctly, the x axes indicate percentages of different amounts of data (even though each batch is balanced). Is that right? If so, maybe this plot's x axis should be the number of instances / hours etc to facilitate direct comparison.    * The paper takes care to describe its paradigm as \"TMR related\" instead of \"TMR evoked\" because the paradigm is different from TMR -- how is it different?",
            "Soundness": "2 fair",
            "Presentation": "4 excellent",
            "Contribution": "3 good",
            "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "Rating": "6: marginally above the acceptance threshold"
        },
        {
            "Summary": "The authors present a dataset and a deep learning pipeline to decode evoked semantic categories during sleep. They collect a dataset of 64-channel EEG recorded while participants (n=52) were exposed to image and sound stimuli from 15 semantic categories while awake. Following this, participants were re- exposed to a subset of the previous sound stimuli while they were in N2/3 sleep. Deep learning pipelines based on CNNs or Transformers and combining a classification objective and a domain (i.e. awake-image, awake-sound, sleep- sound) adaptation objective were then trained to predict the category of a presented stimulus from the corresponding EEG. Different training and evaluation settings are investigated. Results suggest semantic categories can be decoded significantly above chance performance even during NREM sleep.",
            "Strengths": "Originality: The proposed dataset, research question and decoding approach (combining classification and contrastive objectives for domain adaptation) appear to be novel.\n Quality: The paper is of overall good quality and presents a complete picture of the research question, data and deep learning pipeline.\n Clarity: The paper is overall clear, with the different components of the study and results exposed and mostly clearly described. See Weaknesses for proposed clarifications.\n Significance: The study appears like an important step towards the understanding and improvement of semantic decoding during sleep. Along with the dataset (when released) this has the potential to effectively become a baseline framework for studying semantic decoding during sleep.",
            "Weaknesses": "A core claim of the paper is that the experimental paradigm allows probing memory reactivation during sleep. However, I am not convinced the presented analyses actually allow studying memory reactivation. Rather, the trained neural encoders likely picked up on evoked activity related to the audio stimuli presented during sleep. First, the EEG recordings were epoched from -0.2 to 0.8 s around the stimulus onset (Section 4.1). The paper does not describe the distribution of audio stimuli duration, but it is likely that the audio clips lasted a few hundreds of milliseconds. In that case, the EEG windows likely contained evoked responses to these auditory stimuli rather than an associated memory. To assess that, an analysis of the evoked response that also takes into account the spatial dimension would be important (see Q1). On a related note, details of how auditory cues impacted sleep would be important to provide (Q2). Second, I believe the data that was collected during sleep could be used to clarify this point. What kind of decoding performance can be achieved when only looking at auditory cues of mismatched pairs? If semantic category classification performance remains high for cues for which the evoked response should be different from the \u201cmemory-evoked\u201d response (i.e. mismatched pairs), this could support the authors\u2019 claim (see Q3). Finally, to further support the claim that the paradigm tests memory reactivation, an analysis of the behavioral responses during the post-sleep session for presented vs. non-presented stimuli could be carried out. A significant increase in performance for stimuli presented during sleep could support the effect of the TMR-like protocol. Overall, I believe these questions should be answered for the memory-related claims to be kept in the manuscript.\n The description of the models in the Appendix is a bit confusing (see Q4). Summarizing the entire architecture (i.e. including more than just the Conv layers in the table) would be helpful. Also, a single description of the \u201cSubject block\u201d might be clearer (instead of having two separate tables that appear to contain the same information).",
            "Questions": "1. What do the evoked responses look like? It would be important to provide descriptive analyses of the time-locked response to images, auditory cues and auditory cues during N2/3 to confirm the validity of the collected data. Importantly, do time-locked responses during sleep follow a different temporal pattern that maybe spans a longer window (as memory reactivation might happen after the stimulus presentation)? Moreover, considering the spatial dimension of the evoked response (i.e. how it is distributed across the different EEG channels, e.g. with topomaps) might help confirm the responses collected during sleep are actually closer to (awake) auditory or visual responses.\n   2. Is there a chance the audio cues during N2/3 woke up the participants? Showing examples and/or a summary of sleep staging (e.g. hypnograms showing how N2/3 stages were not interrupted by the cues) would be useful.\n   3. How does decoding performance during sleep differ for auditory cues coming from matched vs. mismatched pairs? My understanding from Section A2 is that the sleep auditory cues were randomly selected from the whole audio set, meaning there should be examples from both matched and mismatched pairs available. A supplementary figure like Figure 3 could then be used to report the results for both categories. If performance remains as high for auditory cues of mismatched pairs, then the \u201cmemory-replay\u201d hypothesis might be validated.\n   4. In Section 2.3: \u201cSince there are fewer publicly available EEG recordings during sleep compared to those during wakefulness, applying unsupervised pretraining methods for sleep decoding is not feasible.\u201d I believe that is not true, as there are a lot of openly available sleep datasets (SHHS, MASS, SleepEDF, Physionet Challenge 2018, etc.). My understanding is the limiting factor might be the spatial coverage for those datasets though, which often include a few channels only whereas the presented dataset contains 64 channels.\n   5. What is the impact of the hyperparameter $\\lambda$ in Equation 2, and how was the value of 0.5 selected in Section 4.2.3?\n   6. The performance of the Lasso GLM is about the same as the neural decoders in Figure 3c. How does the Lasso GLM fare in the Awake+Sleep \u2192 Sleep setting (Figure 3d)?\n   7. In Section 4.2.1: \u201cWe take the test accuracy according to the maximum validation accuracy as its performance.\u201d I am not sure I understand what this means.\n   8. Use of the word \u201cmigration\u201d (e.g. Section 4.2.2): maybe \u201ctransfer\u201d would be clearer and more connected with the literature?",
            "Soundness": "2 fair",
            "Presentation": "2 fair",
            "Contribution": "3 good",
            "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "Rating": "6: marginally above the acceptance threshold"
        }
    ]
}