{
    "Decision": "Accept (poster)",
    "Meta review": {
        "Metareview": "This paper proposes to model counterfactual distributions by minimizing kernel Stein discrepancies. The idea consider how to deal with troubles of manipulating energy-based models by using those kernel Stein discrepancies. They propose estimators for a parametric class of distributions, some theoretical analyses, and empirical results. The process is a typical sound one: propose an estimator, prove some properties, experimentally study the approach. The committee is overall positive about the submission.",
        "Justification For Why Not Higher Score": "It remains to be seen how much of impact this may have.",
        "Justification For Why Not Lower Score": "The work is well thought, designed and performed. The topic matches the\nconference well."
    },
    "reviews": [
        {
            "Summary": "Under the assumption of conditional ignorability of a dichotomous treatment, this paper studies counterfactual densities. The densities are estimated within parametric classes and are only estimated up to a constant. The procedure involves doubly robust estimation, cross fitting, and kernel Stein discrepancies. The authors prove asymptotic normality for the finite density parameter with product rate conditions on nuisances.",
            "Strengths": "Originality: It appears that the estimator is a new combination of known tools, namely doubly robust estimation, cross fitting, and kernel Stein discrepancies, for a different task than previous work that combined these tools (Lam and Zhang 2023). The closest pieces of work are Fawkes et al. (2022) and Martinez-Taboada et al. (2023), which use kernel mean embeddings instead of kernel Stein discrepancies. All of these papers are well cited.\n Quality: The results are generally high quality, though some aspects seemed incomplete; see my comments below.\n Clarity: The paper is written very well.\n Significance: I would like the authors to provide further discussion in this regard; see my comments and questions below.",
            "Weaknesses": "1. In my evaluation, the analysis is a direct extension of Martinez-Taboada et al. (2023), replacing features of Y with the xi object evaluated at Y.\n   2. I would like to see more discussion of how good the optimization of the parameter must be for these results to be applicable.\n   3. The paragraph beginning with \u201cwe underscore that\u2026\u201d was confusing.",
            "Questions": "1. Many doubly robust methods exist for counterfactual distributions. When is it a prohibitively difficult problem to transform a counterfactual distribution to a counterfactual density? This seems central to the paper\u2019s motivation.\n   2. What are use cases in which we care to recover the parameter of the counterfactual density (up to a constant in some sense) rather than the counterfactual density? This seems central to the paper\u2019s motivation.\n   3. How do the results provided for the parameter translate to results for the counterfactual density?\n   4. How is the asymptotic variance estimated?\n   5. Do the corresponding confidence intervals have the desired coverage in Monte Carlo experiments?\n   6. Is not Hd the sum kernel rather than the product kernel? I believe the sum kernel is not characteristic, and wonder if that is an issue.\n I will improve my score if these items are addressed.",
            "Soundness": "3 good",
            "Presentation": "3 good",
            "Contribution": "2 fair",
            "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "Rating": "6: marginally above the acceptance threshold"
        },
        {
            "Summary": "Inference causal effect is an important question among many domains. The paper introduces an estimator for modeling counterfactual distributions given a flexible set of distributions that only need to be known up to their normalizing constants. The procedure is based on minimizing the kernel Stein discrepancy between this flexible set and the counterfactual distribution. Simultaneously, it accounts for sampling bias in a doubly robust manner. Besides, the paper provides theoretical foundation for the consistency and asymptotic normality of the estimator, ensuring its reliability and statistical soundness.",
            "Strengths": "* MKSD estimators have primarily been employed for conducting goodness-of-fit tests and sample quality analysis. Nevertheless, in the counterfactual context of this study, the MKSD estimator had not been previously proposed.\n   * Conversely, under certain assumptions, the distribution of either counterfactual can be expressed in terms of observational data. This opens the possibility of using MKSD as the primary tool to address the counterfactual distribution estimation problem.\n   * The paper is well-organized and maintains a clear, logical flow throughout. The structure makes it easy for readers to follow the research from start to finish.\n   * The paper incorporates an abundance of related work. This comprehensive overview of prior research provides valuable context for the study and underscores the authors' deep understanding of the field.\n   * The abstract and introduction effectively set the stage for the paper's major content. They provide a consistent and coherent overview of the research objectives, making it clear to the reader what to expect in the subsequent sections.",
            "Weaknesses": "Numerous other studies have explored semiparametric estimators within the debiased machine learning framework for counterfactual density estimation, such as:\n [1] Mou, Wenlong, Martin J. Wainwright, and Peter L. Bartlett. \"Off-policy estimation of linear functionals: Non-asymptotic theory for semi-parametric efficiency.\" _arXiv preprint arXiv:2209.13075_ (2022).\n [2] Mou, Wenlong, et al. \"Kernel-based off-policy estimation without overlap: Instance optimality beyond semiparametric efficiency.\" _arXiv preprint arXiv:2301.06240_ (2023).\n [3] Kennedy, Edward H., Sivaraman Balakrishnan, and Larry Wasserman. \"Semiparametric counterfactual density estimation.\" _arXiv preprint arXiv:2102.12034_ (2021).\n   * How do you compare the MKSD estimator with other estimators?   * What are the advantages of using MKSD estimators in comparison to other methods?",
            "Questions": "See above \"weaknesses\" section.",
            "Soundness": "3 good",
            "Presentation": "3 good",
            "Contribution": "3 good",
            "Confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "Rating": "5: marginally below the acceptance threshold"
        },
        {
            "Summary": "This paper presents a method for estimating the counterfactual density using Kernel Stein's method. The estimated method exhibits doubly robustness w.r.t. nuisance paraeter estimation.",
            "Strengths": "1. This paper is technically strong. It presents a complicated theory on semiparametric inference in a comprehensive manner, which is well-written.   2. Related works provide a comprehensive summary of the relevant literature.",
            "Weaknesses": "1. This paper could be improved by adding a discussion on the comparison between the KSD-based method and the projecting-based method (e.g., Kennedy et al., 2021). Readers may be interested in understanding the reasons or practical guidelines for choosing the KSD-based method over other methods.   2. I am concerned about the sample complexity of the KSD-based method, as it appears to have a time complexity of $O(n^2)$. Could you please discuss how the time complexity of this method compares to other competitive methods (e.g., Kennedy et al., 2021 or Kim et al., 2018)?   3. In the experiment, it would be interesting to compare it with other competitive methods.   4. It would be great if there were some fixed working examples by specifying $Q_{\\theta}$ for better comprehensibility.",
            "Questions": "1. Is $w_i(x)$ is known? If so, is it dependent on $A$? I am asking this because I think the quantity in Equation 5 should be dependent on $A$ too.    2. Need more explanation on Equation 6 from Equation 5. Specifically, in Equation 6, what\u2019s the meaning of $[\\hat{\\beta}_{\\theta}(\\hat{\\beta})]$?",
            "Soundness": "4 excellent",
            "Presentation": "3 good",
            "Contribution": "3 good",
            "Confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
            "Rating": "8: accept, good paper"
        },
        {
            "Summary": "This paper proposes a method for estimating counterfactual densities by minimizing a Kernel Stein Discrepancy. It describes an estimator and algorithm, and conducts statistical analysis proving the consistency and asymptotic normality under certain conditions. Experiments on synthetic data are done illustrating the theoretical results and an experiment on MNIST shows that the results are intuitively reasonable and realistic.",
            "Strengths": "# Originality and significance\n As far as I know, this is this first work applying Stein kernel discrepancies to counterfactual estimation. It has moderate novelty, transferring previous work on Kernel Stein discrepancies to the causal estimation framework. Causal inference has become a popular research topic, with applications in healthcare, reinforcement learning, and others.\n # Quality\n The proposed estimator is intuitive, simple, and has good theoretical properties without overly strong assumptions. Experiments on synthetic data confirm the theory.\n # Clarity\n The estimator, algorithm, and theoretical results are presented clearly and thoroughly.",
            "Weaknesses": "# Quality\n The number of baselines that the algorithm is compared to is fairly limited, they only include kernel-based estimators. It would strengthen the work to include more categories of counterfactuals, and discuss the pros and cons of all, such as the computation burden.\n # Clarity\n The experimental set-up is a bit unclear (see my question below).\n # Significance\n The experimental baselines are fairly limited, making it difficult to gauge the performance of the algorithm compared to SOTA.",
            "Questions": "1. If the minimizer is unique, then is the estimate consistent?   2. Can the distribution of $Y^0$ affect the experimental results? It is not mentioned in Section 5.   3. In figure 3, what happens if $\\theta_1$ and $\\theta_2$ are of different signs and magnitudes?",
            "Soundness": "2 fair",
            "Presentation": "2 fair",
            "Contribution": "3 good",
            "Confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
            "Rating": "6: marginally above the acceptance threshold"
        }
    ]
}